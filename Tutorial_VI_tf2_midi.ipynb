{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Tutorial_VI_tf2_midi.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PCKy-0EotsrX",
        "y7-p8ClctsrY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbpit0_rtspv"
      },
      "source": [
        "# Tutorial VI: Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Fr8e3Ltspx"
      },
      "source": [
        "<p>\n",
        "Bern Winter School on Machine Learning, 2021<br>\n",
        "Prepared by Mykhailo Vladymyrov.\n",
        "</p>\n",
        "\n",
        "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Upuaj8tspy"
      },
      "source": [
        "In this session we will see what RNN is. We will use it to predict/generate text sequence, but same approach can be applied to any sequential data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QUO3V3Stspz"
      },
      "source": [
        "So far we looked at the data available altogether. In many cases the data is sequential (weather, speach, sensor signals etc).\n",
        "RNNs are specifically designed for such tasks.\n",
        "\n",
        "<img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/rnn.png\" alt=\"drawing\" width=\"90%\"/><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGyY2JPXtsq7"
      },
      "source": [
        "## 1. Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkz4sJrWTQRi"
      },
      "source": [
        "colab = True # set to True is using google colab"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jKCF9MpKWdF"
      },
      "source": [
        "if colab:\n",
        "    %tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpRETZFNtsq7"
      },
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipyd\n",
        "import tensorflow as tf\n",
        "import collections\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "# We'll tell matplotlib to inline any drawn figures like so:\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"<style> .rendered_html code { \n",
        "    padding: 2px 5px;\n",
        "    color: #0000aa;\n",
        "    background-color: #cccccc;\n",
        "} </style>\"\"\")\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH0SSbAftsq1"
      },
      "source": [
        "## unpack libraries\n",
        "if using colab, run the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grv04xmitsq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f122c467-bab8-42e7-d526-ef8c767cbdc5"
      },
      "source": [
        "if colab:\n",
        "    p = tf.keras.utils.get_file('./material.tgz', 'https://github.com/neworldemancer/BMLWS/raw/main/tut_files/tpub0320.tgz')\n",
        "    !mv {p} .\n",
        "    !tar -xvzf material.tgz > /dev/null 2>&1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/neworldemancer/BMLWS/raw/main/tut_files/tpub0320.tgz\n",
            "81215488/81207979 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLWt72gnKj4M"
      },
      "source": [
        "from utils import gr_disp"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF9vrtHFTQR9"
      },
      "source": [
        "def show_graph(g=None, gd=None):\n",
        "    gr_disp.show_graph_eager(g, gd)\n",
        "    %tensorboard --logdir logs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7FnR5Kwtsq9"
      },
      "source": [
        "## 2. Load the convered midi data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3cmvKeatsq-"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4KJQxKqtsrA"
      },
      "source": [
        "training_datasets = []\r\n",
        "for i in range(26):\r\n",
        "  training_file = f'RNN/{i:03d}.npy'\r\n",
        "  training_data = np.load(training_file)\r\n",
        "  training_datasets.append(training_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMumjsH8tsrD"
      },
      "source": [
        "training_data = training_datasets[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_GMc64ptsrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026e413e-f8d1-4a78-a8d4-ae4df16e179e"
      },
      "source": [
        "print(training_data[:100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         1.         0.         ... 0.         0.5078125  0.        ]\n",
            " [1.         0.         0.         ... 0.         0.5078125  0.01171875]\n",
            " [0.         1.         0.         ... 0.         0.5078125  0.36328125]\n",
            " ...\n",
            " [0.         1.         0.         ... 0.         0.640625   0.        ]\n",
            " [0.         1.         0.         ... 0.         0.6875     0.        ]\n",
            " [1.         0.         0.         ... 0.         0.640625   0.046875  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWqevYLh2d7I"
      },
      "source": [
        "n_pars = training_data.shape[1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O8vyel12kZj",
        "outputId": "674effc4-ea5e-41ff-dbb5-7352b909d437"
      },
      "source": [
        "n_pars"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHSCevnwtsrQ"
      },
      "source": [
        "## 4. Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sCYq9dtGpdh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phW3ru-dUSyv"
      },
      "source": [
        "We will build the model in TF2.\n",
        "It will contain an embedding layer, and three LSTM layers.\n",
        "Dense layer on top is used to output probability of the next word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1wxIibuKMdp"
      },
      "source": [
        "class MidiNet:\r\n",
        "  n_hidden = [256, 512, 128]\r\n",
        "  n_input = 512  # word sequence to predict the following word\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def common_branch(inputs):\r\n",
        "    #print(inputs)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Dense(32, activation='relu', name='embedding')(inputs)\r\n",
        "    #print(x)\r\n",
        "    for i, n_h in enumerate(MidiNet.n_hidden):\r\n",
        "        x = LSTM(n_h, return_sequences=True, name=f'l_{i}_lstm{n_h}')(x)\r\n",
        "\r\n",
        "    x = tf.keras.layers.Dense(64, activation='relu', name='features')(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def onoff_head(features):\r\n",
        "    x = Dense(2, name='onoff_head')(features)\r\n",
        "    x = Activation('softmax', name=\"onoff\")(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def note_head(features):\r\n",
        "    x = Dense(128, name='note_head')(features)\r\n",
        "    x = Activation('softmax', name=\"note\")(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def vel_head(features):\r\n",
        "    x = Dense(1, name='vel_head')(features)\r\n",
        "    x = Activation('sigmoid', name=\"vel\")(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def time_head(features):\r\n",
        "    x = Dense(1, name='time_head')(features)\r\n",
        "    x = Activation('sigmoid', name=\"time\")(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def build(n_pars):\r\n",
        "    inputShape = (None, n_pars)  # MidiNet.n_input\r\n",
        "    inputs = Input(shape=inputShape, name='input')\r\n",
        "    \r\n",
        "    features = MidiNet.common_branch(inputs)\r\n",
        "    \r\n",
        "    onoff = MidiNet.onoff_head(features)\r\n",
        "    note = MidiNet.note_head(features)\r\n",
        "    vel = MidiNet.vel_head(features)\r\n",
        "    time = MidiNet.time_head(features)\r\n",
        "\r\n",
        "    model = Model(\r\n",
        "        inputs=inputs,\r\n",
        "        outputs=[onoff, note, vel, time],\r\n",
        "        name=\"midinet\")\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkv-jIFSHBC6",
        "outputId": "6c7a5fc4-e81c-45e3-91f1-0797b223c693"
      },
      "source": [
        "# initialize our FashionNet multi-output network\r\n",
        "model = MidiNet.build(n_pars)\r\n",
        "\r\n",
        "# define two dictionaries: one that specifies the loss method for\r\n",
        "# each output of the network along with a second dictionary that\r\n",
        "# specifies the weight per loss\r\n",
        "losses = {\r\n",
        "\t\"onoff\": \"categorical_crossentropy\",\r\n",
        "\t\"note\": \"categorical_crossentropy\",\r\n",
        "\t\"vel\": \"mse\",\r\n",
        "\t\"time\": \"mse\",\r\n",
        "}\r\n",
        "\r\n",
        "lossWeights = {\r\n",
        "\t\"onoff\": 1.,\r\n",
        "\t\"note\": 1.,\r\n",
        "\t\"vel\": 1.,\r\n",
        "\t\"time\": 1000.,\r\n",
        "}\r\n",
        "# initialize the optimizer and compile the model\r\n",
        "print(\"[INFO] compiling model...\")\r\n",
        "opt = tf.keras.optimizers.RMSprop()\r\n",
        "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,\r\n",
        "\tmetrics=[\"accuracy\"])\r\n",
        "W0 = model.get_weights()\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "Model: \"midinet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, 132)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Dense)               (None, None, 32)     4256        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "l_0_lstm256 (LSTM)              (None, None, 256)    295936      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "l_1_lstm512 (LSTM)              (None, None, 512)    1574912     l_0_lstm256[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "l_2_lstm128 (LSTM)              (None, None, 128)    328192      l_1_lstm512[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "features (Dense)                (None, None, 64)     8256        l_2_lstm128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "onoff_head (Dense)              (None, None, 2)      130         features[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "note_head (Dense)               (None, None, 128)    8320        features[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "vel_head (Dense)                (None, None, 1)      65          features[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_head (Dense)               (None, None, 1)      65          features[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "onoff (Activation)              (None, None, 2)      0           onoff_head[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "note (Activation)               (None, None, 128)    0           note_head[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "vel (Activation)                (None, None, 1)      0           vel_head[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time (Activation)               (None, None, 1)      0           time_head[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,220,132\n",
            "Trainable params: 2,220,132\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsWKJq4JEedX"
      },
      "source": [
        "model.load_weights('trained_midi_512.h5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ojvV71pHJ6"
      },
      "source": [
        "## 5. Data streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_EYsL_TVaBz"
      },
      "source": [
        "Here we will see how to feed a dataset for model training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oo1JJZczAIc",
        "outputId": "313d4766-b2ee-44b8-98b8-76cebdddc678"
      },
      "source": [
        "training_data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10590, 132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1wbWwXHxL6B"
      },
      "source": [
        "def gen_sample():\r\n",
        "  sz_smpl = MidiNet.n_input + 1\r\n",
        "  sz_all = len(training_data)\r\n",
        "\r\n",
        "  sz_starts = sz_all - sz_smpl\r\n",
        "\r\n",
        "  n_samples = int(np.ceil(sz_all/sz_smpl))\r\n",
        "  print(f'n_samples ={n_samples}')\r\n",
        "\r\n",
        "  for i in range(n_samples):\r\n",
        "    ofs = np.random.randint(0, high=sz_starts)\r\n",
        "    sample = training_data[ofs:ofs+sz_smpl]\r\n",
        "    yield sample"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciA7ScVGWTK5"
      },
      "source": [
        "def gen_sample_mult():\r\n",
        "  n_ds = len(training_datasets)\r\n",
        "\r\n",
        "  info = {}\r\n",
        "  for i, training_data in enumerate(training_datasets):\r\n",
        "    sz_smpl = MidiNet.n_input + 1\r\n",
        "    sz_all = len(training_data)\r\n",
        "\r\n",
        "    sz_starts = sz_all - sz_smpl\r\n",
        "\r\n",
        "    n_samples = int(np.ceil(sz_all/sz_smpl))\r\n",
        "  \r\n",
        "\r\n",
        "    info[i] = [n_samples, sz_starts]\r\n",
        "\r\n",
        "  n_samples = np.sum([n for n,sz in info.values()])\r\n",
        "\r\n",
        "  print(f'n_samples ={n_samples}')\r\n",
        "\r\n",
        "  for i in range(n_samples):\r\n",
        "    while True:\r\n",
        "      ds_idx = np.random.randint(0, high=n_ds)\r\n",
        "      if info[ds_idx][0] > 0:\r\n",
        "        info[ds_idx][0] -= 1 \r\n",
        "        break\r\n",
        "\r\n",
        "    training_data = training_datasets[ds_idx]\r\n",
        "    ofs = np.random.randint(0, high=info[ds_idx][1])\r\n",
        "    sample = training_data[ofs:ofs+sz_smpl]\r\n",
        "    yield sample"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muEoZW05nFQt"
      },
      "source": [
        "# create tf.data.Dataset object\n",
        "#samples_dataset = tf.data.Dataset.from_tensor_slices(training_data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfSyUC6CnlZ8"
      },
      "source": [
        "# take metod generates elements:\n",
        "#for i in samples_dataset.take(5):\n",
        "#  print(i.shape)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBK7FWPFVwSP"
      },
      "source": [
        "The `batch` method creates dataset, that generates sequences of elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtGgHXkPnc7P"
      },
      "source": [
        "#sequences = samples_dataset.batch(MidiNet.n_input+1, drop_remainder=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHsYKeUUyDIW"
      },
      "source": [
        "#sequences = tf.data.Dataset.from_generator(gen_sample, \r\n",
        "#                                           output_signature=(tf.TensorSpec(shape=(MidiNet.n_input + 1, n_pars), dtype=tf.float32))\r\n",
        "#                                           )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUTWeBUnZHWi"
      },
      "source": [
        "sequences = tf.data.Dataset.from_generator(gen_sample_mult, \r\n",
        "                                           output_signature=(tf.TensorSpec(shape=(MidiNet.n_input + 1, n_pars), dtype=tf.float32))\r\n",
        "                                           )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0DYh6wNnuJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c89b0a-25f9-4aa0-bff7-4142e7b9978d"
      },
      "source": [
        "for item in sequences.take(5):\n",
        "  print(item.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_samples =168\n",
            "(513, 132)\n",
            "(513, 132)\n",
            "(513, 132)\n",
            "(513, 132)\n",
            "(513, 132)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe6o55hyWnyX"
      },
      "source": [
        " The `map` method allows to use any function to preprocess the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mFJ4jNloJk7"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_data = chunk[:-1]\n",
        "    target_all = chunk[1:]\n",
        "\n",
        "    target_data = {\n",
        "      \"onoff\": target_all[..., :2],\n",
        "      \"note\": target_all[..., 2:-2],\n",
        "      \"vel\": target_all[..., -2:-1],\n",
        "      \"time\": target_all[..., -1:],\n",
        "    }\n",
        "\n",
        "    return input_data, target_data\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbhGQ5k_XE5f"
      },
      "source": [
        "The model will predict input_text -> target_text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6erRolZ-omdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40da832-1105-4897-cfd8-59c920036975"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', input_example.shape)\n",
        "  for k, v in target_example.items():\n",
        "    print (f'Target data {k}:', v.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_samples =168\n",
            "Input data:  (512, 132)\n",
            "Target data onoff: (512, 2)\n",
            "Target data note: (512, 128)\n",
            "Target data vel: (512, 1)\n",
            "Target data time: (512, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74eDk9K_XXQ0"
      },
      "source": [
        "Finally we will shuffle the items, and produce minibatches of 16 elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcDexYkspBa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bacf38-c0de-46c3-e9ea-a626eb93c9ad"
      },
      "source": [
        "dataset = dataset.shuffle(10000).batch(16, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((16, 512, 132), {onoff: (16, 512, 2), note: (16, 512, 128), vel: (16, 512, 1), time: (16, 512, 1)}), types: (tf.float32, {onoff: tf.float32, note: tf.float32, vel: tf.float32, time: tf.float32})>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX7Fdz3PXzxY"
      },
      "source": [
        "Let's test not trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3IkTjm8N_QT"
      },
      "source": [
        "def concat_pred(pred_tf):\r\n",
        "  return np.concatenate([v.numpy() for v in pred_tf], axis = -1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNa3Ysj3qOEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0a81cf-8635-49a1-ebfd-5af408c2a106"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  example_batch_predictions = concat_pred(example_batch_predictions)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vector size)\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_samples =168\n",
            "(16, 512, 132) # (batch_size, sequence_length, vector size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV13OaTQqcVU"
      },
      "source": [
        "#print('input: ', to_text(input_example_batch.numpy()[0]))\n",
        "#print('output:', to_text(target_example_batch.numpy()[0]))\n",
        "#print('pred:  ', to_text(example_batch_predictions.numpy()[0].argmax(axis=1)))\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aqxQ_X-tsrV"
      },
      "source": [
        "## 5. Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-UIyiNWnEx5"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7wT782Hrq-R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7bdabf1-b2fa-4f13-b093-1404a1ccb6ce"
      },
      "source": [
        "#model.set_weights(W0)\n",
        "\n",
        "\n",
        "logdir=\"logs/fit/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "history = model.fit(dataset, epochs=int(1024*2.5), verbose=1, callbacks=[tensorboard_callback])\n",
        "\n",
        "model.save(f'trained_midi_{MidiNet.n_input}.h5', save_format=\"h5\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 7.5824 - onoff_loss: 0.6941 - note_loss: 4.0310 - vel_loss: 0.0226 - time_loss: 0.0028 - onoff_accuracy: 0.4998 - note_accuracy: 0.0351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1838\n",
            "Epoch 14/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 8.5715 - onoff_loss: 0.6936 - note_loss: 4.0221 - vel_loss: 0.0245 - time_loss: 0.0038 - onoff_accuracy: 0.4992 - note_accuracy: 0.0359 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1875\n",
            "Epoch 15/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 8.1617 - onoff_loss: 0.6934 - note_loss: 3.9991 - vel_loss: 0.0216 - time_loss: 0.0034 - onoff_accuracy: 0.4998 - note_accuracy: 0.0341 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1534\n",
            "Epoch 16/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 8.2460 - onoff_loss: 0.6936 - note_loss: 4.0104 - vel_loss: 0.0235 - time_loss: 0.0035 - onoff_accuracy: 0.4994 - note_accuracy: 0.0355 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1907\n",
            "Epoch 17/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.4605 - onoff_loss: 0.6937 - note_loss: 3.9962 - vel_loss: 0.0219 - time_loss: 0.0027 - onoff_accuracy: 0.4996 - note_accuracy: 0.0352 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1586\n",
            "Epoch 18/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.6133 - onoff_loss: 0.6939 - note_loss: 4.0446 - vel_loss: 0.0218 - time_loss: 0.0029 - onoff_accuracy: 0.5001 - note_accuracy: 0.0300 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1640\n",
            "Epoch 19/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 8.1261 - onoff_loss: 0.6933 - note_loss: 4.0428 - vel_loss: 0.0223 - time_loss: 0.0034 - onoff_accuracy: 0.4996 - note_accuracy: 0.0308 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1614\n",
            "Epoch 20/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 8.1372 - onoff_loss: 0.6939 - note_loss: 4.0356 - vel_loss: 0.0239 - time_loss: 0.0034 - onoff_accuracy: 0.5003 - note_accuracy: 0.0332 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 21/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 8.0399 - onoff_loss: 0.6935 - note_loss: 3.9992 - vel_loss: 0.0224 - time_loss: 0.0033 - onoff_accuracy: 0.5001 - note_accuracy: 0.0344 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 22/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.4646 - onoff_loss: 0.6934 - note_loss: 4.0561 - vel_loss: 0.0202 - time_loss: 0.0027 - onoff_accuracy: 0.4998 - note_accuracy: 0.0332 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1638\n",
            "Epoch 23/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.9964 - onoff_loss: 0.6935 - note_loss: 4.0023 - vel_loss: 0.0217 - time_loss: 0.0033 - onoff_accuracy: 0.4997 - note_accuracy: 0.0315 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1577\n",
            "Epoch 24/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.9840 - onoff_loss: 0.6932 - note_loss: 4.0306 - vel_loss: 0.0228 - time_loss: 0.0032 - onoff_accuracy: 0.5003 - note_accuracy: 0.0355 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1884\n",
            "Epoch 25/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.5790 - onoff_loss: 0.6935 - note_loss: 3.9895 - vel_loss: 0.0231 - time_loss: 0.0029 - onoff_accuracy: 0.5003 - note_accuracy: 0.0404 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1899\n",
            "Epoch 26/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 8.0359 - onoff_loss: 0.6938 - note_loss: 4.0089 - vel_loss: 0.0214 - time_loss: 0.0033 - onoff_accuracy: 0.4999 - note_accuracy: 0.0354 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1741\n",
            "Epoch 27/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 8.0224 - onoff_loss: 0.6934 - note_loss: 4.0171 - vel_loss: 0.0241 - time_loss: 0.0033 - onoff_accuracy: 0.4999 - note_accuracy: 0.0413 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1814\n",
            "Epoch 28/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 7.9263 - onoff_loss: 0.6935 - note_loss: 4.0145 - vel_loss: 0.0221 - time_loss: 0.0032 - onoff_accuracy: 0.4996 - note_accuracy: 0.0370 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 29/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.9951 - onoff_loss: 0.6934 - note_loss: 4.0374 - vel_loss: 0.0218 - time_loss: 0.0032 - onoff_accuracy: 0.5003 - note_accuracy: 0.0354 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 30/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 8.5870 - onoff_loss: 0.6934 - note_loss: 3.9578 - vel_loss: 0.0241 - time_loss: 0.0039 - onoff_accuracy: 0.5003 - note_accuracy: 0.0399 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1711\n",
            "Epoch 31/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 7.7220 - onoff_loss: 0.6936 - note_loss: 4.0166 - vel_loss: 0.0225 - time_loss: 0.0030 - onoff_accuracy: 0.4995 - note_accuracy: 0.0364 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1842\n",
            "Epoch 32/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.8697 - onoff_loss: 0.6937 - note_loss: 4.0269 - vel_loss: 0.0221 - time_loss: 0.0031 - onoff_accuracy: 0.5003 - note_accuracy: 0.0368 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1780\n",
            "Epoch 33/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.9885 - onoff_loss: 0.6933 - note_loss: 3.9937 - vel_loss: 0.0226 - time_loss: 0.0033 - onoff_accuracy: 0.4999 - note_accuracy: 0.0373 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1667\n",
            "Epoch 34/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.7081 - onoff_loss: 0.6933 - note_loss: 4.0223 - vel_loss: 0.0234 - time_loss: 0.0030 - onoff_accuracy: 0.5005 - note_accuracy: 0.0313 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 35/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.8365 - onoff_loss: 0.6934 - note_loss: 4.0118 - vel_loss: 0.0212 - time_loss: 0.0031 - onoff_accuracy: 0.4998 - note_accuracy: 0.0382 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1569\n",
            "Epoch 36/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.9983 - onoff_loss: 0.6935 - note_loss: 4.0020 - vel_loss: 0.0230 - time_loss: 0.0033 - onoff_accuracy: 0.4997 - note_accuracy: 0.0366 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1803\n",
            "Epoch 37/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.4467 - onoff_loss: 0.6936 - note_loss: 4.0065 - vel_loss: 0.0241 - time_loss: 0.0027 - onoff_accuracy: 0.4999 - note_accuracy: 0.0394 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2058\n",
            "Epoch 38/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.9102 - onoff_loss: 0.6934 - note_loss: 4.0314 - vel_loss: 0.0236 - time_loss: 0.0032 - onoff_accuracy: 0.4999 - note_accuracy: 0.0381 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1744\n",
            "Epoch 39/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 7.7377 - onoff_loss: 0.6932 - note_loss: 4.0082 - vel_loss: 0.0221 - time_loss: 0.0030 - onoff_accuracy: 0.4999 - note_accuracy: 0.0338 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1561\n",
            "Epoch 40/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.7889 - onoff_loss: 0.6938 - note_loss: 3.9985 - vel_loss: 0.0227 - time_loss: 0.0031 - onoff_accuracy: 0.4997 - note_accuracy: 0.0336 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 41/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.8134 - onoff_loss: 0.6934 - note_loss: 4.0426 - vel_loss: 0.0211 - time_loss: 0.0031 - onoff_accuracy: 0.4998 - note_accuracy: 0.0321 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1717\n",
            "Epoch 42/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.7959 - onoff_loss: 0.6933 - note_loss: 4.0242 - vel_loss: 0.0230 - time_loss: 0.0031 - onoff_accuracy: 0.4997 - note_accuracy: 0.0323 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 43/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.3652 - onoff_loss: 0.6934 - note_loss: 4.0112 - vel_loss: 0.0231 - time_loss: 0.0036 - onoff_accuracy: 0.4995 - note_accuracy: 0.0357 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1884\n",
            "Epoch 44/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.5676 - onoff_loss: 0.6933 - note_loss: 4.0136 - vel_loss: 0.0207 - time_loss: 0.0028 - onoff_accuracy: 0.5002 - note_accuracy: 0.0306 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1569\n",
            "Epoch 45/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.5241 - onoff_loss: 0.6935 - note_loss: 4.0542 - vel_loss: 0.0203 - time_loss: 0.0028 - onoff_accuracy: 0.5000 - note_accuracy: 0.0273 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1618\n",
            "Epoch 46/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.6466 - onoff_loss: 0.6935 - note_loss: 4.0292 - vel_loss: 0.0228 - time_loss: 0.0029 - onoff_accuracy: 0.5001 - note_accuracy: 0.0361 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1723\n",
            "Epoch 47/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.8726 - onoff_loss: 0.6933 - note_loss: 4.0036 - vel_loss: 0.0213 - time_loss: 0.0032 - onoff_accuracy: 0.4997 - note_accuracy: 0.0325 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1621\n",
            "Epoch 48/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.9926 - onoff_loss: 0.6935 - note_loss: 3.9593 - vel_loss: 0.0231 - time_loss: 0.0033 - onoff_accuracy: 0.5002 - note_accuracy: 0.0385 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1858\n",
            "Epoch 49/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.8362 - onoff_loss: 0.6938 - note_loss: 4.0456 - vel_loss: 0.0227 - time_loss: 0.0031 - onoff_accuracy: 0.5000 - note_accuracy: 0.0404 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1800\n",
            "Epoch 50/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.0828 - onoff_loss: 0.6932 - note_loss: 4.0320 - vel_loss: 0.0212 - time_loss: 0.0033 - onoff_accuracy: 0.5005 - note_accuracy: 0.0276 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1535\n",
            "Epoch 51/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 8.3956 - onoff_loss: 0.6936 - note_loss: 3.9985 - vel_loss: 0.0228 - time_loss: 0.0037 - onoff_accuracy: 0.5000 - note_accuracy: 0.0412 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 52/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.7339 - onoff_loss: 0.6933 - note_loss: 4.0127 - vel_loss: 0.0215 - time_loss: 0.0030 - onoff_accuracy: 0.4998 - note_accuracy: 0.0386 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 53/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.6514 - onoff_loss: 0.6933 - note_loss: 4.0066 - vel_loss: 0.0227 - time_loss: 0.0029 - onoff_accuracy: 0.5002 - note_accuracy: 0.0409 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 54/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.7713 - onoff_loss: 0.6937 - note_loss: 4.0027 - vel_loss: 0.0220 - time_loss: 0.0031 - onoff_accuracy: 0.4999 - note_accuracy: 0.0360 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 55/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.7889 - onoff_loss: 0.6936 - note_loss: 4.0515 - vel_loss: 0.0223 - time_loss: 0.0030 - onoff_accuracy: 0.4999 - note_accuracy: 0.0297 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 56/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 8.1577 - onoff_loss: 0.6934 - note_loss: 3.9916 - vel_loss: 0.0236 - time_loss: 0.0034 - onoff_accuracy: 0.4999 - note_accuracy: 0.0353 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 57/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.7632 - onoff_loss: 0.6933 - note_loss: 4.0567 - vel_loss: 0.0241 - time_loss: 0.0030 - onoff_accuracy: 0.5001 - note_accuracy: 0.0328 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1889\n",
            "Epoch 58/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.6548 - onoff_loss: 0.6935 - note_loss: 3.9979 - vel_loss: 0.0231 - time_loss: 0.0029 - onoff_accuracy: 0.4997 - note_accuracy: 0.0438 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1905\n",
            "Epoch 59/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.8248 - onoff_loss: 0.6933 - note_loss: 4.0113 - vel_loss: 0.0229 - time_loss: 0.0031 - onoff_accuracy: 0.5003 - note_accuracy: 0.0379 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1851\n",
            "Epoch 60/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 8.2512 - onoff_loss: 0.6935 - note_loss: 4.0116 - vel_loss: 0.0233 - time_loss: 0.0035 - onoff_accuracy: 0.4998 - note_accuracy: 0.0340 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 61/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.7317 - onoff_loss: 0.6934 - note_loss: 3.9990 - vel_loss: 0.0218 - time_loss: 0.0030 - onoff_accuracy: 0.5000 - note_accuracy: 0.0335 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 62/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.9296 - onoff_loss: 0.6932 - note_loss: 4.0066 - vel_loss: 0.0236 - time_loss: 0.0032 - onoff_accuracy: 0.5004 - note_accuracy: 0.0448 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2025\n",
            "Epoch 63/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 8.2738 - onoff_loss: 0.6934 - note_loss: 3.9804 - vel_loss: 0.0241 - time_loss: 0.0036 - onoff_accuracy: 0.5003 - note_accuracy: 0.0355 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1878\n",
            "Epoch 64/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.7418 - onoff_loss: 0.6933 - note_loss: 4.0184 - vel_loss: 0.0235 - time_loss: 0.0030 - onoff_accuracy: 0.5000 - note_accuracy: 0.0359 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 65/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.1224 - onoff_loss: 0.6933 - note_loss: 4.0460 - vel_loss: 0.0230 - time_loss: 0.0034 - onoff_accuracy: 0.5000 - note_accuracy: 0.0299 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 66/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 8.1908 - onoff_loss: 0.6932 - note_loss: 4.0261 - vel_loss: 0.0242 - time_loss: 0.0034 - onoff_accuracy: 0.5002 - note_accuracy: 0.0329 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1919\n",
            "Epoch 67/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.0030 - onoff_loss: 0.6934 - note_loss: 4.0248 - vel_loss: 0.0223 - time_loss: 0.0033 - onoff_accuracy: 0.4996 - note_accuracy: 0.0359 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 68/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 8.1945 - onoff_loss: 0.6935 - note_loss: 4.0076 - vel_loss: 0.0230 - time_loss: 0.0035 - onoff_accuracy: 0.5002 - note_accuracy: 0.0378 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1774\n",
            "Epoch 69/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.9350 - onoff_loss: 0.6932 - note_loss: 4.0019 - vel_loss: 0.0221 - time_loss: 0.0032 - onoff_accuracy: 0.5002 - note_accuracy: 0.0368 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1661\n",
            "Epoch 70/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.6450 - onoff_loss: 0.6933 - note_loss: 3.9802 - vel_loss: 0.0231 - time_loss: 0.0029 - onoff_accuracy: 0.4999 - note_accuracy: 0.0399 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 71/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.0453 - onoff_loss: 0.6932 - note_loss: 4.0115 - vel_loss: 0.0224 - time_loss: 0.0033 - onoff_accuracy: 0.5000 - note_accuracy: 0.0335 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1667\n",
            "Epoch 72/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 8.1138 - onoff_loss: 0.6934 - note_loss: 3.9938 - vel_loss: 0.0229 - time_loss: 0.0034 - onoff_accuracy: 0.5002 - note_accuracy: 0.0358 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 73/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 8.1876 - onoff_loss: 0.6933 - note_loss: 4.0006 - vel_loss: 0.0210 - time_loss: 0.0035 - onoff_accuracy: 0.5001 - note_accuracy: 0.0309 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1723\n",
            "Epoch 74/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.8741 - onoff_loss: 0.6938 - note_loss: 4.0614 - vel_loss: 0.0233 - time_loss: 0.0031 - onoff_accuracy: 0.4999 - note_accuracy: 0.0352 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 75/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 8.2766 - onoff_loss: 0.6932 - note_loss: 4.0173 - vel_loss: 0.0215 - time_loss: 0.0035 - onoff_accuracy: 0.5000 - note_accuracy: 0.0383 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1615\n",
            "Epoch 76/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 8.1655 - onoff_loss: 0.6932 - note_loss: 3.9833 - vel_loss: 0.0227 - time_loss: 0.0035 - onoff_accuracy: 0.4998 - note_accuracy: 0.0304 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1732\n",
            "Epoch 77/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.5089 - onoff_loss: 0.6935 - note_loss: 4.0472 - vel_loss: 0.0230 - time_loss: 0.0027 - onoff_accuracy: 0.4996 - note_accuracy: 0.0307 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1860\n",
            "Epoch 78/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.6306 - onoff_loss: 0.6933 - note_loss: 4.0024 - vel_loss: 0.0222 - time_loss: 0.0029 - onoff_accuracy: 0.4998 - note_accuracy: 0.0432 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1895\n",
            "Epoch 79/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 8.0281 - onoff_loss: 0.6934 - note_loss: 4.0098 - vel_loss: 0.0215 - time_loss: 0.0033 - onoff_accuracy: 0.5001 - note_accuracy: 0.0340 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 80/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.9213 - onoff_loss: 0.6933 - note_loss: 3.9985 - vel_loss: 0.0236 - time_loss: 0.0032 - onoff_accuracy: 0.4999 - note_accuracy: 0.0396 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1840\n",
            "Epoch 81/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.6634 - onoff_loss: 0.6932 - note_loss: 3.9956 - vel_loss: 0.0229 - time_loss: 0.0030 - onoff_accuracy: 0.5004 - note_accuracy: 0.0430 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1837\n",
            "Epoch 82/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.9436 - onoff_loss: 0.6936 - note_loss: 3.9932 - vel_loss: 0.0244 - time_loss: 0.0032 - onoff_accuracy: 0.4996 - note_accuracy: 0.0422 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1923\n",
            "Epoch 83/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.7065 - onoff_loss: 0.6933 - note_loss: 3.9656 - vel_loss: 0.0216 - time_loss: 0.0030 - onoff_accuracy: 0.5097 - note_accuracy: 0.0340 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 84/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.4234 - onoff_loss: 0.6934 - note_loss: 3.9857 - vel_loss: 0.0242 - time_loss: 0.0037 - onoff_accuracy: 0.4992 - note_accuracy: 0.0437 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 85/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.1077 - onoff_loss: 0.6933 - note_loss: 4.0131 - vel_loss: 0.0223 - time_loss: 0.0034 - onoff_accuracy: 0.5003 - note_accuracy: 0.0307 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1688\n",
            "Epoch 86/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.8923 - onoff_loss: 0.6932 - note_loss: 3.9948 - vel_loss: 0.0211 - time_loss: 0.0032 - onoff_accuracy: 0.5005 - note_accuracy: 0.0269 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1521\n",
            "Epoch 87/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.7271 - onoff_loss: 0.6934 - note_loss: 4.0186 - vel_loss: 0.0225 - time_loss: 0.0030 - onoff_accuracy: 0.5002 - note_accuracy: 0.0324 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 88/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 8.1966 - onoff_loss: 0.6933 - note_loss: 4.0133 - vel_loss: 0.0228 - time_loss: 0.0035 - onoff_accuracy: 0.5008 - note_accuracy: 0.0379 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 89/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 8.0201 - onoff_loss: 0.6932 - note_loss: 4.0150 - vel_loss: 0.0225 - time_loss: 0.0033 - onoff_accuracy: 0.5003 - note_accuracy: 0.0377 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 90/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 8.2523 - onoff_loss: 0.6933 - note_loss: 4.0357 - vel_loss: 0.0230 - time_loss: 0.0035 - onoff_accuracy: 0.5005 - note_accuracy: 0.0295 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 91/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.7435 - onoff_loss: 0.6931 - note_loss: 4.0018 - vel_loss: 0.0218 - time_loss: 0.0030 - onoff_accuracy: 0.5034 - note_accuracy: 0.0366 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 92/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.7936 - onoff_loss: 0.6934 - note_loss: 4.0307 - vel_loss: 0.0219 - time_loss: 0.0030 - onoff_accuracy: 0.5005 - note_accuracy: 0.0362 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 93/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.5102 - onoff_loss: 0.6931 - note_loss: 3.9895 - vel_loss: 0.0224 - time_loss: 0.0028 - onoff_accuracy: 0.5068 - note_accuracy: 0.0401 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 94/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.7438 - onoff_loss: 0.7030 - note_loss: 4.0111 - vel_loss: 0.0238 - time_loss: 0.0030 - onoff_accuracy: 0.4997 - note_accuracy: 0.0351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1700\n",
            "Epoch 95/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.7427 - onoff_loss: 0.6931 - note_loss: 4.0462 - vel_loss: 0.0226 - time_loss: 0.0030 - onoff_accuracy: 0.5030 - note_accuracy: 0.0338 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 96/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 7.7792 - onoff_loss: 0.6932 - note_loss: 4.0211 - vel_loss: 0.0225 - time_loss: 0.0030 - onoff_accuracy: 0.4961 - note_accuracy: 0.0376 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1680\n",
            "Epoch 97/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.9735 - onoff_loss: 0.6932 - note_loss: 4.0333 - vel_loss: 0.0215 - time_loss: 0.0032 - onoff_accuracy: 0.4964 - note_accuracy: 0.0381 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1655\n",
            "Epoch 98/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.9658 - onoff_loss: 0.6937 - note_loss: 4.0180 - vel_loss: 0.0234 - time_loss: 0.0032 - onoff_accuracy: 0.5101 - note_accuracy: 0.0405 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1793\n",
            "Epoch 99/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.9744 - onoff_loss: 0.6917 - note_loss: 3.9839 - vel_loss: 0.0214 - time_loss: 0.0033 - onoff_accuracy: 0.5316 - note_accuracy: 0.0311 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1512\n",
            "Epoch 100/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 8.0846 - onoff_loss: 0.6936 - note_loss: 3.9691 - vel_loss: 0.0241 - time_loss: 0.0034 - onoff_accuracy: 0.5223 - note_accuracy: 0.0351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 101/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.2591 - onoff_loss: 0.6881 - note_loss: 4.0427 - vel_loss: 0.0223 - time_loss: 0.0035 - onoff_accuracy: 0.5457 - note_accuracy: 0.0308 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1753\n",
            "Epoch 102/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.8439 - onoff_loss: 0.6839 - note_loss: 3.9666 - vel_loss: 0.0230 - time_loss: 0.0032 - onoff_accuracy: 0.5636 - note_accuracy: 0.0343 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 103/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 7.7489 - onoff_loss: 0.6834 - note_loss: 4.0066 - vel_loss: 0.0246 - time_loss: 0.0030 - onoff_accuracy: 0.5567 - note_accuracy: 0.0327 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1822\n",
            "Epoch 104/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.7387 - onoff_loss: 0.6810 - note_loss: 3.9825 - vel_loss: 0.0234 - time_loss: 0.0031 - onoff_accuracy: 0.5658 - note_accuracy: 0.0364 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1897\n",
            "Epoch 105/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.6084 - onoff_loss: 0.6855 - note_loss: 3.9954 - vel_loss: 0.0230 - time_loss: 0.0029 - onoff_accuracy: 0.5601 - note_accuracy: 0.0365 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1691\n",
            "Epoch 106/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.1240 - onoff_loss: 0.6836 - note_loss: 4.0207 - vel_loss: 0.0236 - time_loss: 0.0034 - onoff_accuracy: 0.5538 - note_accuracy: 0.0312 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 107/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.7741 - onoff_loss: 0.6831 - note_loss: 3.9852 - vel_loss: 0.0239 - time_loss: 0.0031 - onoff_accuracy: 0.5617 - note_accuracy: 0.0340 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 108/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.7491 - onoff_loss: 0.6862 - note_loss: 3.9956 - vel_loss: 0.0227 - time_loss: 0.0030 - onoff_accuracy: 0.5560 - note_accuracy: 0.0313 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 109/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 8.1425 - onoff_loss: 0.6780 - note_loss: 4.0046 - vel_loss: 0.0249 - time_loss: 0.0034 - onoff_accuracy: 0.5691 - note_accuracy: 0.0299 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1808\n",
            "Epoch 110/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.2941 - onoff_loss: 0.6834 - note_loss: 4.0145 - vel_loss: 0.0242 - time_loss: 0.0036 - onoff_accuracy: 0.5647 - note_accuracy: 0.0370 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 111/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 7.9519 - onoff_loss: 0.6705 - note_loss: 3.9903 - vel_loss: 0.0240 - time_loss: 0.0033 - onoff_accuracy: 0.5947 - note_accuracy: 0.0398 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1836\n",
            "Epoch 112/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.3579 - onoff_loss: 0.6847 - note_loss: 4.0163 - vel_loss: 0.0210 - time_loss: 0.0026 - onoff_accuracy: 0.5547 - note_accuracy: 0.0380 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 113/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.7834 - onoff_loss: 0.6750 - note_loss: 4.0442 - vel_loss: 0.0238 - time_loss: 0.0030 - onoff_accuracy: 0.5803 - note_accuracy: 0.0378 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1790\n",
            "Epoch 114/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.6810 - onoff_loss: 0.6676 - note_loss: 4.0200 - vel_loss: 0.0234 - time_loss: 0.0030 - onoff_accuracy: 0.5952 - note_accuracy: 0.0426 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1874\n",
            "Epoch 115/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.6968 - onoff_loss: 0.6733 - note_loss: 3.9844 - vel_loss: 0.0227 - time_loss: 0.0030 - onoff_accuracy: 0.5835 - note_accuracy: 0.0340 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1807\n",
            "Epoch 116/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 8.1409 - onoff_loss: 0.6702 - note_loss: 3.9799 - vel_loss: 0.0233 - time_loss: 0.0035 - onoff_accuracy: 0.5904 - note_accuracy: 0.0448 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 117/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 8.2035 - onoff_loss: 0.6633 - note_loss: 3.9841 - vel_loss: 0.0238 - time_loss: 0.0035 - onoff_accuracy: 0.6043 - note_accuracy: 0.0421 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 118/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.0879 - onoff_loss: 0.6693 - note_loss: 3.9919 - vel_loss: 0.0211 - time_loss: 0.0024 - onoff_accuracy: 0.5881 - note_accuracy: 0.0414 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1559\n",
            "Epoch 119/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.9891 - onoff_loss: 0.6890 - note_loss: 3.9962 - vel_loss: 0.0222 - time_loss: 0.0033 - onoff_accuracy: 0.5624 - note_accuracy: 0.0319 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 120/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.0771 - onoff_loss: 0.6700 - note_loss: 3.9697 - vel_loss: 0.0224 - time_loss: 0.0024 - onoff_accuracy: 0.5909 - note_accuracy: 0.0429 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1831\n",
            "Epoch 121/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 7.7820 - onoff_loss: 0.6634 - note_loss: 3.9937 - vel_loss: 0.0223 - time_loss: 0.0031 - onoff_accuracy: 0.6036 - note_accuracy: 0.0481 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 122/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 8.0917 - onoff_loss: 0.6765 - note_loss: 4.0018 - vel_loss: 0.0234 - time_loss: 0.0034 - onoff_accuracy: 0.5735 - note_accuracy: 0.0421 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1739\n",
            "Epoch 123/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 8.1143 - onoff_loss: 0.6616 - note_loss: 3.9976 - vel_loss: 0.0233 - time_loss: 0.0034 - onoff_accuracy: 0.6018 - note_accuracy: 0.0453 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 124/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.6921 - onoff_loss: 0.6584 - note_loss: 3.9394 - vel_loss: 0.0225 - time_loss: 0.0031 - onoff_accuracy: 0.6139 - note_accuracy: 0.0501 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 125/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.5711 - onoff_loss: 0.6521 - note_loss: 3.9522 - vel_loss: 0.0225 - time_loss: 0.0029 - onoff_accuracy: 0.6182 - note_accuracy: 0.0505 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 126/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.1643 - onoff_loss: 0.6590 - note_loss: 3.9149 - vel_loss: 0.0219 - time_loss: 0.0026 - onoff_accuracy: 0.6018 - note_accuracy: 0.0573 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1764\n",
            "Epoch 127/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.5653 - onoff_loss: 0.6373 - note_loss: 3.9478 - vel_loss: 0.0216 - time_loss: 0.0030 - onoff_accuracy: 0.6325 - note_accuracy: 0.0443 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1656\n",
            "Epoch 128/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.0268 - onoff_loss: 0.6293 - note_loss: 3.9386 - vel_loss: 0.0218 - time_loss: 0.0024 - onoff_accuracy: 0.6458 - note_accuracy: 0.0543 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1908\n",
            "Epoch 129/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.5788 - onoff_loss: 0.6425 - note_loss: 3.9474 - vel_loss: 0.0238 - time_loss: 0.0030 - onoff_accuracy: 0.6283 - note_accuracy: 0.0502 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1872\n",
            "Epoch 130/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.3410 - onoff_loss: 0.6381 - note_loss: 3.9877 - vel_loss: 0.0226 - time_loss: 0.0027 - onoff_accuracy: 0.6319 - note_accuracy: 0.0513 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1890\n",
            "Epoch 131/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.4116 - onoff_loss: 0.6379 - note_loss: 3.9628 - vel_loss: 0.0220 - time_loss: 0.0028 - onoff_accuracy: 0.6339 - note_accuracy: 0.0462 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1740\n",
            "Epoch 132/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.2548 - onoff_loss: 0.6225 - note_loss: 3.9306 - vel_loss: 0.0223 - time_loss: 0.0027 - onoff_accuracy: 0.6512 - note_accuracy: 0.0535 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1889\n",
            "Epoch 133/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.4353 - onoff_loss: 0.6299 - note_loss: 3.9218 - vel_loss: 0.0213 - time_loss: 0.0029 - onoff_accuracy: 0.6391 - note_accuracy: 0.0495 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1540\n",
            "Epoch 134/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.3147 - onoff_loss: 0.6433 - note_loss: 3.9558 - vel_loss: 0.0215 - time_loss: 0.0027 - onoff_accuracy: 0.6187 - note_accuracy: 0.0429 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1586\n",
            "Epoch 135/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.0797 - onoff_loss: 0.6103 - note_loss: 3.9483 - vel_loss: 0.0214 - time_loss: 0.0025 - onoff_accuracy: 0.6602 - note_accuracy: 0.0475 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1602\n",
            "Epoch 136/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.4948 - onoff_loss: 0.6044 - note_loss: 3.8627 - vel_loss: 0.0228 - time_loss: 0.0030 - onoff_accuracy: 0.6699 - note_accuracy: 0.0534 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1782\n",
            "Epoch 137/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.5577 - onoff_loss: 0.6056 - note_loss: 3.9684 - vel_loss: 0.0230 - time_loss: 0.0030 - onoff_accuracy: 0.6679 - note_accuracy: 0.0506 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1925\n",
            "Epoch 138/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.6816 - onoff_loss: 0.6049 - note_loss: 3.8756 - vel_loss: 0.0229 - time_loss: 0.0032 - onoff_accuracy: 0.6677 - note_accuracy: 0.0592 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 139/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.5028 - onoff_loss: 0.6103 - note_loss: 3.9078 - vel_loss: 0.0218 - time_loss: 0.0030 - onoff_accuracy: 0.6564 - note_accuracy: 0.0546 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1479\n",
            "Epoch 140/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.1907 - onoff_loss: 0.5924 - note_loss: 3.8691 - vel_loss: 0.0234 - time_loss: 0.0027 - onoff_accuracy: 0.6775 - note_accuracy: 0.0605 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1893\n",
            "Epoch 141/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.9742 - onoff_loss: 0.5932 - note_loss: 3.8883 - vel_loss: 0.0217 - time_loss: 0.0025 - onoff_accuracy: 0.6786 - note_accuracy: 0.0572 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1700\n",
            "Epoch 142/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.1635 - onoff_loss: 0.5885 - note_loss: 3.9295 - vel_loss: 0.0236 - time_loss: 0.0026 - onoff_accuracy: 0.6850 - note_accuracy: 0.0556 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1896\n",
            "Epoch 143/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.6795 - onoff_loss: 0.5877 - note_loss: 3.9256 - vel_loss: 0.0222 - time_loss: 0.0031 - onoff_accuracy: 0.6910 - note_accuracy: 0.0556 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1594\n",
            "Epoch 144/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.9785 - onoff_loss: 0.5785 - note_loss: 3.8725 - vel_loss: 0.0231 - time_loss: 0.0025 - onoff_accuracy: 0.6932 - note_accuracy: 0.0615 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2023\n",
            "Epoch 145/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.2058 - onoff_loss: 0.5781 - note_loss: 3.8642 - vel_loss: 0.0216 - time_loss: 0.0027 - onoff_accuracy: 0.6949 - note_accuracy: 0.0593 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1739\n",
            "Epoch 146/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 8.2108 - onoff_loss: 0.5928 - note_loss: 3.9071 - vel_loss: 0.0217 - time_loss: 0.0037 - onoff_accuracy: 0.6882 - note_accuracy: 0.0527 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 147/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.8708 - onoff_loss: 0.5560 - note_loss: 3.8895 - vel_loss: 0.0225 - time_loss: 0.0024 - onoff_accuracy: 0.7140 - note_accuracy: 0.0635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1889\n",
            "Epoch 148/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.4676 - onoff_loss: 0.5760 - note_loss: 3.8765 - vel_loss: 0.0226 - time_loss: 0.0030 - onoff_accuracy: 0.6977 - note_accuracy: 0.0525 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1664\n",
            "Epoch 149/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.6867 - onoff_loss: 0.5677 - note_loss: 3.8791 - vel_loss: 0.0211 - time_loss: 0.0022 - onoff_accuracy: 0.7017 - note_accuracy: 0.0579 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 150/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.3048 - onoff_loss: 0.5560 - note_loss: 3.8714 - vel_loss: 0.0213 - time_loss: 0.0029 - onoff_accuracy: 0.7141 - note_accuracy: 0.0595 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 151/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.3077 - onoff_loss: 0.5526 - note_loss: 3.8671 - vel_loss: 0.0213 - time_loss: 0.0029 - onoff_accuracy: 0.7172 - note_accuracy: 0.0555 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 152/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 7.1519 - onoff_loss: 0.5689 - note_loss: 3.8823 - vel_loss: 0.0219 - time_loss: 0.0027 - onoff_accuracy: 0.7092 - note_accuracy: 0.0562 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 153/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.1733 - onoff_loss: 0.5617 - note_loss: 3.8642 - vel_loss: 0.0228 - time_loss: 0.0027 - onoff_accuracy: 0.7144 - note_accuracy: 0.0602 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1867\n",
            "Epoch 154/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.0955 - onoff_loss: 0.5587 - note_loss: 3.8373 - vel_loss: 0.0222 - time_loss: 0.0027 - onoff_accuracy: 0.7160 - note_accuracy: 0.0644 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1841\n",
            "Epoch 155/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.0579 - onoff_loss: 0.5589 - note_loss: 3.8540 - vel_loss: 0.0222 - time_loss: 0.0026 - onoff_accuracy: 0.7097 - note_accuracy: 0.0598 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 156/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 7.0233 - onoff_loss: 0.5574 - note_loss: 3.8610 - vel_loss: 0.0197 - time_loss: 0.0026 - onoff_accuracy: 0.7117 - note_accuracy: 0.0537 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1601\n",
            "Epoch 157/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.0681 - onoff_loss: 0.5572 - note_loss: 3.8815 - vel_loss: 0.0208 - time_loss: 0.0026 - onoff_accuracy: 0.7129 - note_accuracy: 0.0572 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1562\n",
            "Epoch 158/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.7575 - onoff_loss: 0.5492 - note_loss: 3.7693 - vel_loss: 0.0212 - time_loss: 0.0024 - onoff_accuracy: 0.7198 - note_accuracy: 0.0662 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1622\n",
            "Epoch 159/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.9022 - onoff_loss: 0.5446 - note_loss: 3.8572 - vel_loss: 0.0222 - time_loss: 0.0025 - onoff_accuracy: 0.7202 - note_accuracy: 0.0648 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1937\n",
            "Epoch 160/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.2362 - onoff_loss: 0.5536 - note_loss: 3.8491 - vel_loss: 0.0206 - time_loss: 0.0028 - onoff_accuracy: 0.7180 - note_accuracy: 0.0532 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1563\n",
            "Epoch 161/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.8600 - onoff_loss: 0.5273 - note_loss: 3.8403 - vel_loss: 0.0207 - time_loss: 0.0025 - onoff_accuracy: 0.7389 - note_accuracy: 0.0609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1643\n",
            "Epoch 162/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.9868 - onoff_loss: 0.5546 - note_loss: 3.7917 - vel_loss: 0.0228 - time_loss: 0.0026 - onoff_accuracy: 0.7132 - note_accuracy: 0.0693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 163/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.7827 - onoff_loss: 0.5568 - note_loss: 3.7876 - vel_loss: 0.0213 - time_loss: 0.0024 - onoff_accuracy: 0.7133 - note_accuracy: 0.0671 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 164/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.7833 - onoff_loss: 0.5359 - note_loss: 3.7948 - vel_loss: 0.0214 - time_loss: 0.0024 - onoff_accuracy: 0.7295 - note_accuracy: 0.0681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1872\n",
            "Epoch 165/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 6.8633 - onoff_loss: 0.5442 - note_loss: 3.7678 - vel_loss: 0.0212 - time_loss: 0.0025 - onoff_accuracy: 0.7245 - note_accuracy: 0.0680 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1878\n",
            "Epoch 166/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.9359 - onoff_loss: 0.5404 - note_loss: 3.8181 - vel_loss: 0.0207 - time_loss: 0.0026 - onoff_accuracy: 0.7246 - note_accuracy: 0.0641 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1593\n",
            "Epoch 167/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 7.1694 - onoff_loss: 0.5245 - note_loss: 3.8209 - vel_loss: 0.0217 - time_loss: 0.0028 - onoff_accuracy: 0.7383 - note_accuracy: 0.0626 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 168/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.1397 - onoff_loss: 0.5318 - note_loss: 3.7301 - vel_loss: 0.0210 - time_loss: 0.0019 - onoff_accuracy: 0.7308 - note_accuracy: 0.0793 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 169/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 7.3401 - onoff_loss: 0.5355 - note_loss: 3.8097 - vel_loss: 0.0217 - time_loss: 0.0030 - onoff_accuracy: 0.7255 - note_accuracy: 0.0587 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1637\n",
            "Epoch 170/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.8077 - onoff_loss: 0.5191 - note_loss: 3.7494 - vel_loss: 0.0229 - time_loss: 0.0025 - onoff_accuracy: 0.7387 - note_accuracy: 0.0700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1953\n",
            "Epoch 171/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.7818 - onoff_loss: 0.5359 - note_loss: 3.7772 - vel_loss: 0.0216 - time_loss: 0.0024 - onoff_accuracy: 0.7304 - note_accuracy: 0.0705 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1620\n",
            "Epoch 172/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.5978 - onoff_loss: 0.5266 - note_loss: 3.7894 - vel_loss: 0.0205 - time_loss: 0.0023 - onoff_accuracy: 0.7369 - note_accuracy: 0.0618 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1629\n",
            "Epoch 173/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.6719 - onoff_loss: 0.5198 - note_loss: 3.8037 - vel_loss: 0.0221 - time_loss: 0.0023 - onoff_accuracy: 0.7401 - note_accuracy: 0.0617 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1739\n",
            "Epoch 174/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 6.7546 - onoff_loss: 0.5216 - note_loss: 3.7979 - vel_loss: 0.0199 - time_loss: 0.0024 - onoff_accuracy: 0.7380 - note_accuracy: 0.0621 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1680\n",
            "Epoch 175/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 6.5480 - onoff_loss: 0.5265 - note_loss: 3.7670 - vel_loss: 0.0217 - time_loss: 0.0022 - onoff_accuracy: 0.7308 - note_accuracy: 0.0625 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 176/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.4238 - onoff_loss: 0.5209 - note_loss: 3.7653 - vel_loss: 0.0212 - time_loss: 0.0021 - onoff_accuracy: 0.7384 - note_accuracy: 0.0733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1786\n",
            "Epoch 177/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.7736 - onoff_loss: 0.5321 - note_loss: 3.7903 - vel_loss: 0.0204 - time_loss: 0.0024 - onoff_accuracy: 0.7267 - note_accuracy: 0.0611 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 178/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.2012 - onoff_loss: 0.5053 - note_loss: 3.7517 - vel_loss: 0.0201 - time_loss: 0.0019 - onoff_accuracy: 0.7496 - note_accuracy: 0.0681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1664\n",
            "Epoch 179/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 6.5504 - onoff_loss: 0.5299 - note_loss: 3.7466 - vel_loss: 0.0212 - time_loss: 0.0023 - onoff_accuracy: 0.7308 - note_accuracy: 0.0660 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 180/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.2591 - onoff_loss: 0.4984 - note_loss: 3.7628 - vel_loss: 0.0210 - time_loss: 0.0020 - onoff_accuracy: 0.7502 - note_accuracy: 0.0694 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 181/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.4660 - onoff_loss: 0.5169 - note_loss: 3.7653 - vel_loss: 0.0211 - time_loss: 0.0022 - onoff_accuracy: 0.7414 - note_accuracy: 0.0718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 182/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.6366 - onoff_loss: 0.5216 - note_loss: 3.7657 - vel_loss: 0.0215 - time_loss: 0.0023 - onoff_accuracy: 0.7355 - note_accuracy: 0.0665 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 183/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.4581 - onoff_loss: 0.5153 - note_loss: 3.7085 - vel_loss: 0.0206 - time_loss: 0.0022 - onoff_accuracy: 0.7415 - note_accuracy: 0.0726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 184/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.6190 - onoff_loss: 0.5157 - note_loss: 3.7232 - vel_loss: 0.0211 - time_loss: 0.0024 - onoff_accuracy: 0.7394 - note_accuracy: 0.0718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1740\n",
            "Epoch 185/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.3513 - onoff_loss: 0.5119 - note_loss: 3.7503 - vel_loss: 0.0215 - time_loss: 0.0021 - onoff_accuracy: 0.7423 - note_accuracy: 0.0716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 186/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.3793 - onoff_loss: 0.5085 - note_loss: 3.7001 - vel_loss: 0.0226 - time_loss: 0.0021 - onoff_accuracy: 0.7454 - note_accuracy: 0.0807 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1912\n",
            "Epoch 187/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.5249 - onoff_loss: 0.5054 - note_loss: 3.7274 - vel_loss: 0.0218 - time_loss: 0.0023 - onoff_accuracy: 0.7471 - note_accuracy: 0.0705 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1849\n",
            "Epoch 188/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.2250 - onoff_loss: 0.5049 - note_loss: 3.7252 - vel_loss: 0.0206 - time_loss: 0.0020 - onoff_accuracy: 0.7504 - note_accuracy: 0.0706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1784\n",
            "Epoch 189/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.4169 - onoff_loss: 0.5130 - note_loss: 3.7482 - vel_loss: 0.0201 - time_loss: 0.0021 - onoff_accuracy: 0.7428 - note_accuracy: 0.0736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 190/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.6004 - onoff_loss: 0.5145 - note_loss: 3.7284 - vel_loss: 0.0207 - time_loss: 0.0023 - onoff_accuracy: 0.7426 - note_accuracy: 0.0701 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1651\n",
            "Epoch 191/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.3655 - onoff_loss: 0.4976 - note_loss: 3.7191 - vel_loss: 0.0205 - time_loss: 0.0021 - onoff_accuracy: 0.7544 - note_accuracy: 0.0703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1649\n",
            "Epoch 192/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.1258 - onoff_loss: 0.4972 - note_loss: 3.6878 - vel_loss: 0.0209 - time_loss: 0.0019 - onoff_accuracy: 0.7529 - note_accuracy: 0.0847 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1860\n",
            "Epoch 193/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 6.2807 - onoff_loss: 0.4892 - note_loss: 3.6586 - vel_loss: 0.0223 - time_loss: 0.0021 - onoff_accuracy: 0.7573 - note_accuracy: 0.0780 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1957\n",
            "Epoch 194/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.0167 - onoff_loss: 0.5083 - note_loss: 3.6980 - vel_loss: 0.0204 - time_loss: 0.0018 - onoff_accuracy: 0.7424 - note_accuracy: 0.0772 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1705\n",
            "Epoch 195/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 5.8858 - onoff_loss: 0.5019 - note_loss: 3.6606 - vel_loss: 0.0212 - time_loss: 0.0017 - onoff_accuracy: 0.7496 - note_accuracy: 0.0803 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 196/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 6.4730 - onoff_loss: 0.4989 - note_loss: 3.6825 - vel_loss: 0.0213 - time_loss: 0.0023 - onoff_accuracy: 0.7512 - note_accuracy: 0.0824 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1885\n",
            "Epoch 197/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 5.9929 - onoff_loss: 0.4915 - note_loss: 3.6649 - vel_loss: 0.0225 - time_loss: 0.0018 - onoff_accuracy: 0.7594 - note_accuracy: 0.0786 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 198/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.9000 - onoff_loss: 0.4949 - note_loss: 3.6425 - vel_loss: 0.0199 - time_loss: 0.0017 - onoff_accuracy: 0.7558 - note_accuracy: 0.0842 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1671\n",
            "Epoch 199/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.0356 - onoff_loss: 0.4882 - note_loss: 3.6554 - vel_loss: 0.0214 - time_loss: 0.0019 - onoff_accuracy: 0.7595 - note_accuracy: 0.0802 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1867\n",
            "Epoch 200/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 5.9471 - onoff_loss: 0.5125 - note_loss: 3.6336 - vel_loss: 0.0191 - time_loss: 0.0018 - onoff_accuracy: 0.7413 - note_accuracy: 0.0860 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1564\n",
            "Epoch 201/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 6.0689 - onoff_loss: 0.4964 - note_loss: 3.6970 - vel_loss: 0.0202 - time_loss: 0.0019 - onoff_accuracy: 0.7543 - note_accuracy: 0.0796 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1856\n",
            "Epoch 202/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 5.8908 - onoff_loss: 0.5002 - note_loss: 3.6848 - vel_loss: 0.0190 - time_loss: 0.0017 - onoff_accuracy: 0.7514 - note_accuracy: 0.0795 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1445\n",
            "Epoch 203/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.9435 - onoff_loss: 0.4964 - note_loss: 3.6697 - vel_loss: 0.0205 - time_loss: 0.0018 - onoff_accuracy: 0.7513 - note_accuracy: 0.0839 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 204/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.9261 - onoff_loss: 0.4761 - note_loss: 3.6544 - vel_loss: 0.0207 - time_loss: 0.0018 - onoff_accuracy: 0.7708 - note_accuracy: 0.0767 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 205/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.8550 - onoff_loss: 0.4848 - note_loss: 3.5761 - vel_loss: 0.0214 - time_loss: 0.0018 - onoff_accuracy: 0.7596 - note_accuracy: 0.0928 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1784\n",
            "Epoch 206/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.1924 - onoff_loss: 0.4980 - note_loss: 3.6136 - vel_loss: 0.0207 - time_loss: 0.0021 - onoff_accuracy: 0.7524 - note_accuracy: 0.0886 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 207/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 6.2616 - onoff_loss: 0.4823 - note_loss: 3.6432 - vel_loss: 0.0208 - time_loss: 0.0021 - onoff_accuracy: 0.7642 - note_accuracy: 0.0901 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1749\n",
            "Epoch 208/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.5346 - onoff_loss: 0.4765 - note_loss: 3.5395 - vel_loss: 0.0206 - time_loss: 0.0015 - onoff_accuracy: 0.7658 - note_accuracy: 0.1009 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1861\n",
            "Epoch 209/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 5.8240 - onoff_loss: 0.5062 - note_loss: 3.6011 - vel_loss: 0.0205 - time_loss: 0.0017 - onoff_accuracy: 0.7459 - note_accuracy: 0.0887 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 210/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.8616 - onoff_loss: 0.4849 - note_loss: 3.6537 - vel_loss: 0.0213 - time_loss: 0.0017 - onoff_accuracy: 0.7629 - note_accuracy: 0.0819 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 211/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 5.7946 - onoff_loss: 0.4921 - note_loss: 3.5516 - vel_loss: 0.0212 - time_loss: 0.0017 - onoff_accuracy: 0.7572 - note_accuracy: 0.0965 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1806\n",
            "Epoch 212/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.7871 - onoff_loss: 0.4764 - note_loss: 3.6322 - vel_loss: 0.0208 - time_loss: 0.0017 - onoff_accuracy: 0.7683 - note_accuracy: 0.0865 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1671\n",
            "Epoch 213/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.9114 - onoff_loss: 0.4908 - note_loss: 3.5847 - vel_loss: 0.0211 - time_loss: 0.0018 - onoff_accuracy: 0.7586 - note_accuracy: 0.0915 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1884\n",
            "Epoch 214/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.8243 - onoff_loss: 0.4830 - note_loss: 3.5827 - vel_loss: 0.0199 - time_loss: 0.0017 - onoff_accuracy: 0.7633 - note_accuracy: 0.0911 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 215/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 5.7517 - onoff_loss: 0.4800 - note_loss: 3.5513 - vel_loss: 0.0217 - time_loss: 0.0017 - onoff_accuracy: 0.7687 - note_accuracy: 0.0949 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1637\n",
            "Epoch 216/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.7179 - onoff_loss: 0.4860 - note_loss: 3.6078 - vel_loss: 0.0207 - time_loss: 0.0016 - onoff_accuracy: 0.7605 - note_accuracy: 0.0913 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 217/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.5034 - onoff_loss: 0.4687 - note_loss: 3.5525 - vel_loss: 0.0198 - time_loss: 0.0015 - onoff_accuracy: 0.7735 - note_accuracy: 0.0930 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 218/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.6173 - onoff_loss: 0.4733 - note_loss: 3.5871 - vel_loss: 0.0202 - time_loss: 0.0015 - onoff_accuracy: 0.7700 - note_accuracy: 0.0930 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1779\n",
            "Epoch 219/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 5.7260 - onoff_loss: 0.4740 - note_loss: 3.5758 - vel_loss: 0.0216 - time_loss: 0.0017 - onoff_accuracy: 0.7693 - note_accuracy: 0.0944 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1758\n",
            "Epoch 220/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.4651 - onoff_loss: 0.4697 - note_loss: 3.5275 - vel_loss: 0.0214 - time_loss: 0.0014 - onoff_accuracy: 0.7713 - note_accuracy: 0.0994 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1929\n",
            "Epoch 221/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.6641 - onoff_loss: 0.4725 - note_loss: 3.5468 - vel_loss: 0.0205 - time_loss: 0.0016 - onoff_accuracy: 0.7737 - note_accuracy: 0.0935 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 222/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.4116 - onoff_loss: 0.4609 - note_loss: 3.5571 - vel_loss: 0.0202 - time_loss: 0.0014 - onoff_accuracy: 0.7767 - note_accuracy: 0.0986 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1841\n",
            "Epoch 223/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.9637 - onoff_loss: 0.4677 - note_loss: 3.5869 - vel_loss: 0.0208 - time_loss: 0.0019 - onoff_accuracy: 0.7747 - note_accuracy: 0.0933 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1837\n",
            "Epoch 224/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.3231 - onoff_loss: 0.4651 - note_loss: 3.5104 - vel_loss: 0.0201 - time_loss: 0.0013 - onoff_accuracy: 0.7751 - note_accuracy: 0.1003 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1742\n",
            "Epoch 225/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.3476 - onoff_loss: 0.4634 - note_loss: 3.5210 - vel_loss: 0.0191 - time_loss: 0.0013 - onoff_accuracy: 0.7759 - note_accuracy: 0.1003 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 226/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.3097 - onoff_loss: 0.4709 - note_loss: 3.5207 - vel_loss: 0.0204 - time_loss: 0.0013 - onoff_accuracy: 0.7708 - note_accuracy: 0.1003 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1917\n",
            "Epoch 227/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.9670 - onoff_loss: 0.4620 - note_loss: 3.5214 - vel_loss: 0.0211 - time_loss: 0.0020 - onoff_accuracy: 0.7775 - note_accuracy: 0.1027 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1849\n",
            "Epoch 228/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 5.3057 - onoff_loss: 0.4713 - note_loss: 3.5409 - vel_loss: 0.0198 - time_loss: 0.0013 - onoff_accuracy: 0.7723 - note_accuracy: 0.0970 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 229/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.3974 - onoff_loss: 0.4725 - note_loss: 3.5005 - vel_loss: 0.0203 - time_loss: 0.0014 - onoff_accuracy: 0.7667 - note_accuracy: 0.1123 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1821\n",
            "Epoch 230/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.3181 - onoff_loss: 0.4853 - note_loss: 3.5391 - vel_loss: 0.0196 - time_loss: 0.0013 - onoff_accuracy: 0.7604 - note_accuracy: 0.0907 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 231/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 5.4058 - onoff_loss: 0.4766 - note_loss: 3.4479 - vel_loss: 0.0198 - time_loss: 0.0015 - onoff_accuracy: 0.7644 - note_accuracy: 0.1072 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 232/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.1505 - onoff_loss: 0.4587 - note_loss: 3.4455 - vel_loss: 0.0208 - time_loss: 0.0012 - onoff_accuracy: 0.7778 - note_accuracy: 0.1120 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1822\n",
            "Epoch 233/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.3289 - onoff_loss: 0.4880 - note_loss: 3.4890 - vel_loss: 0.0188 - time_loss: 0.0013 - onoff_accuracy: 0.7585 - note_accuracy: 0.1026 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 234/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.1628 - onoff_loss: 0.4683 - note_loss: 3.4711 - vel_loss: 0.0196 - time_loss: 0.0012 - onoff_accuracy: 0.7743 - note_accuracy: 0.1015 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1668\n",
            "Epoch 235/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.3973 - onoff_loss: 0.4636 - note_loss: 3.4828 - vel_loss: 0.0202 - time_loss: 0.0014 - onoff_accuracy: 0.7746 - note_accuracy: 0.1072 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 236/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.3357 - onoff_loss: 0.4671 - note_loss: 3.4942 - vel_loss: 0.0198 - time_loss: 0.0014 - onoff_accuracy: 0.7732 - note_accuracy: 0.1040 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1836\n",
            "Epoch 237/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.0474 - onoff_loss: 0.4873 - note_loss: 3.4614 - vel_loss: 0.0186 - time_loss: 0.0011 - onoff_accuracy: 0.7576 - note_accuracy: 0.1054 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1631\n",
            "Epoch 238/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.1993 - onoff_loss: 0.4563 - note_loss: 3.4484 - vel_loss: 0.0190 - time_loss: 0.0013 - onoff_accuracy: 0.7819 - note_accuracy: 0.1100 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1711\n",
            "Epoch 239/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.1716 - onoff_loss: 0.4714 - note_loss: 3.4989 - vel_loss: 0.0195 - time_loss: 0.0012 - onoff_accuracy: 0.7676 - note_accuracy: 0.1043 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 240/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.0536 - onoff_loss: 0.4652 - note_loss: 3.3952 - vel_loss: 0.0218 - time_loss: 0.0012 - onoff_accuracy: 0.7764 - note_accuracy: 0.1243 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1962\n",
            "Epoch 241/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.1278 - onoff_loss: 0.4662 - note_loss: 3.4283 - vel_loss: 0.0193 - time_loss: 0.0012 - onoff_accuracy: 0.7735 - note_accuracy: 0.1159 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1744\n",
            "Epoch 242/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.9080 - onoff_loss: 0.4578 - note_loss: 3.4199 - vel_loss: 0.0194 - time_loss: 0.0010 - onoff_accuracy: 0.7792 - note_accuracy: 0.1115 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1885\n",
            "Epoch 243/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.9922 - onoff_loss: 0.4477 - note_loss: 3.4151 - vel_loss: 0.0194 - time_loss: 0.0011 - onoff_accuracy: 0.7864 - note_accuracy: 0.1153 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 244/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.2791 - onoff_loss: 0.4784 - note_loss: 3.4802 - vel_loss: 0.0190 - time_loss: 0.0013 - onoff_accuracy: 0.7644 - note_accuracy: 0.1015 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1516\n",
            "Epoch 245/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.1172 - onoff_loss: 0.4466 - note_loss: 3.4257 - vel_loss: 0.0191 - time_loss: 0.0012 - onoff_accuracy: 0.7842 - note_accuracy: 0.1148 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 246/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.0439 - onoff_loss: 0.4624 - note_loss: 3.4005 - vel_loss: 0.0199 - time_loss: 0.0012 - onoff_accuracy: 0.7775 - note_accuracy: 0.1141 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1667\n",
            "Epoch 247/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.9235 - onoff_loss: 0.4563 - note_loss: 3.4653 - vel_loss: 0.0185 - time_loss: 9.8337e-04 - onoff_accuracy: 0.7788 - note_accuracy: 0.1085 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 248/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 5.0801 - onoff_loss: 0.4396 - note_loss: 3.3931 - vel_loss: 0.0194 - time_loss: 0.0012 - onoff_accuracy: 0.7928 - note_accuracy: 0.1187 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 249/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 5.0038 - onoff_loss: 0.4598 - note_loss: 3.4113 - vel_loss: 0.0184 - time_loss: 0.0011 - onoff_accuracy: 0.7765 - note_accuracy: 0.1149 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 250/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 5.0209 - onoff_loss: 0.4617 - note_loss: 3.4331 - vel_loss: 0.0197 - time_loss: 0.0011 - onoff_accuracy: 0.7762 - note_accuracy: 0.1091 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1685\n",
            "Epoch 251/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.7645 - onoff_loss: 0.4374 - note_loss: 3.3336 - vel_loss: 0.0195 - time_loss: 9.7401e-04 - onoff_accuracy: 0.7913 - note_accuracy: 0.1275 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1770\n",
            "Epoch 252/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.9844 - onoff_loss: 0.4602 - note_loss: 3.4114 - vel_loss: 0.0200 - time_loss: 0.0011 - onoff_accuracy: 0.7786 - note_accuracy: 0.1183 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1880\n",
            "Epoch 253/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 4.9320 - onoff_loss: 0.4466 - note_loss: 3.3622 - vel_loss: 0.0208 - time_loss: 0.0011 - onoff_accuracy: 0.7865 - note_accuracy: 0.1238 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1850\n",
            "Epoch 254/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.8497 - onoff_loss: 0.4350 - note_loss: 3.3382 - vel_loss: 0.0203 - time_loss: 0.0011 - onoff_accuracy: 0.7939 - note_accuracy: 0.1284 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2038\n",
            "Epoch 255/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.8271 - onoff_loss: 0.4330 - note_loss: 3.3337 - vel_loss: 0.0203 - time_loss: 0.0010 - onoff_accuracy: 0.7952 - note_accuracy: 0.1314 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1815\n",
            "Epoch 256/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.7231 - onoff_loss: 0.4330 - note_loss: 3.3026 - vel_loss: 0.0198 - time_loss: 9.6776e-04 - onoff_accuracy: 0.7926 - note_accuracy: 0.1377 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1921\n",
            "Epoch 257/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.9565 - onoff_loss: 0.4518 - note_loss: 3.3852 - vel_loss: 0.0188 - time_loss: 0.0011 - onoff_accuracy: 0.7822 - note_accuracy: 0.1137 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 258/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.7976 - onoff_loss: 0.4473 - note_loss: 3.3567 - vel_loss: 0.0184 - time_loss: 9.7523e-04 - onoff_accuracy: 0.7844 - note_accuracy: 0.1207 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1609\n",
            "Epoch 259/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.8144 - onoff_loss: 0.4245 - note_loss: 3.3683 - vel_loss: 0.0192 - time_loss: 0.0010 - onoff_accuracy: 0.7972 - note_accuracy: 0.1261 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1980\n",
            "Epoch 260/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.8549 - onoff_loss: 0.4517 - note_loss: 3.3583 - vel_loss: 0.0188 - time_loss: 0.0010 - onoff_accuracy: 0.7839 - note_accuracy: 0.1213 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1571\n",
            "Epoch 261/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.7709 - onoff_loss: 0.4458 - note_loss: 3.3300 - vel_loss: 0.0193 - time_loss: 9.7576e-04 - onoff_accuracy: 0.7862 - note_accuracy: 0.1272 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 262/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.7700 - onoff_loss: 0.4404 - note_loss: 3.3601 - vel_loss: 0.0186 - time_loss: 9.5094e-04 - onoff_accuracy: 0.7899 - note_accuracy: 0.1180 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 263/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.8941 - onoff_loss: 0.4457 - note_loss: 3.3761 - vel_loss: 0.0186 - time_loss: 0.0011 - onoff_accuracy: 0.7858 - note_accuracy: 0.1172 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1678\n",
            "Epoch 264/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.5692 - onoff_loss: 0.4115 - note_loss: 3.3044 - vel_loss: 0.0195 - time_loss: 8.3388e-04 - onoff_accuracy: 0.8082 - note_accuracy: 0.1351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1899\n",
            "Epoch 265/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.8657 - onoff_loss: 0.4392 - note_loss: 3.3118 - vel_loss: 0.0197 - time_loss: 0.0011 - onoff_accuracy: 0.7922 - note_accuracy: 0.1340 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 266/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.6467 - onoff_loss: 0.4318 - note_loss: 3.3292 - vel_loss: 0.0200 - time_loss: 8.6568e-04 - onoff_accuracy: 0.7916 - note_accuracy: 0.1290 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1937\n",
            "Epoch 267/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.6827 - onoff_loss: 0.4323 - note_loss: 3.2985 - vel_loss: 0.0190 - time_loss: 9.3289e-04 - onoff_accuracy: 0.7954 - note_accuracy: 0.1351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 268/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.6352 - onoff_loss: 0.4307 - note_loss: 3.2637 - vel_loss: 0.0188 - time_loss: 9.2202e-04 - onoff_accuracy: 0.7959 - note_accuracy: 0.1387 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 269/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.6365 - onoff_loss: 0.4308 - note_loss: 3.2842 - vel_loss: 0.0191 - time_loss: 9.0238e-04 - onoff_accuracy: 0.7959 - note_accuracy: 0.1359 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1756\n",
            "Epoch 270/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.7640 - onoff_loss: 0.4470 - note_loss: 3.3035 - vel_loss: 0.0199 - time_loss: 9.9363e-04 - onoff_accuracy: 0.7826 - note_accuracy: 0.1323 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1600\n",
            "Epoch 271/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 4.6545 - onoff_loss: 0.4098 - note_loss: 3.2642 - vel_loss: 0.0194 - time_loss: 9.6112e-04 - onoff_accuracy: 0.8110 - note_accuracy: 0.1366 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1862\n",
            "Epoch 272/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.5247 - onoff_loss: 0.4149 - note_loss: 3.3159 - vel_loss: 0.0199 - time_loss: 7.7403e-04 - onoff_accuracy: 0.8047 - note_accuracy: 0.1348 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1843\n",
            "Epoch 273/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 4.5852 - onoff_loss: 0.4446 - note_loss: 3.2713 - vel_loss: 0.0184 - time_loss: 8.5096e-04 - onoff_accuracy: 0.7852 - note_accuracy: 0.1337 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1587\n",
            "Epoch 274/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.6735 - onoff_loss: 0.4288 - note_loss: 3.2887 - vel_loss: 0.0182 - time_loss: 9.3781e-04 - onoff_accuracy: 0.7957 - note_accuracy: 0.1302 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1540\n",
            "Epoch 275/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.4609 - onoff_loss: 0.4254 - note_loss: 3.2615 - vel_loss: 0.0182 - time_loss: 7.5582e-04 - onoff_accuracy: 0.7970 - note_accuracy: 0.1342 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 276/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.5273 - onoff_loss: 0.4259 - note_loss: 3.2413 - vel_loss: 0.0189 - time_loss: 8.4111e-04 - onoff_accuracy: 0.7982 - note_accuracy: 0.1400 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 277/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.4022 - onoff_loss: 0.4084 - note_loss: 3.2156 - vel_loss: 0.0183 - time_loss: 7.5993e-04 - onoff_accuracy: 0.8086 - note_accuracy: 0.1462 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1717\n",
            "Epoch 278/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.4222 - onoff_loss: 0.4195 - note_loss: 3.1957 - vel_loss: 0.0189 - time_loss: 7.8813e-04 - onoff_accuracy: 0.7992 - note_accuracy: 0.1496 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1725\n",
            "Epoch 279/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.5446 - onoff_loss: 0.4247 - note_loss: 3.2439 - vel_loss: 0.0193 - time_loss: 8.5674e-04 - onoff_accuracy: 0.7982 - note_accuracy: 0.1383 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1557\n",
            "Epoch 280/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.2735 - onoff_loss: 0.4031 - note_loss: 3.1828 - vel_loss: 0.0173 - time_loss: 6.7020e-04 - onoff_accuracy: 0.8115 - note_accuracy: 0.1465 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1641\n",
            "Epoch 281/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.5731 - onoff_loss: 0.4246 - note_loss: 3.2423 - vel_loss: 0.0190 - time_loss: 8.8716e-04 - onoff_accuracy: 0.7982 - note_accuracy: 0.1330 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1741\n",
            "Epoch 282/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.3353 - onoff_loss: 0.4169 - note_loss: 3.1853 - vel_loss: 0.0185 - time_loss: 7.1466e-04 - onoff_accuracy: 0.8025 - note_accuracy: 0.1508 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1732\n",
            "Epoch 283/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.4717 - onoff_loss: 0.4211 - note_loss: 3.2693 - vel_loss: 0.0175 - time_loss: 7.6381e-04 - onoff_accuracy: 0.8016 - note_accuracy: 0.1316 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1690\n",
            "Epoch 284/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.3650 - onoff_loss: 0.4044 - note_loss: 3.1994 - vel_loss: 0.0184 - time_loss: 7.4290e-04 - onoff_accuracy: 0.8102 - note_accuracy: 0.1497 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 285/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.3100 - onoff_loss: 0.3975 - note_loss: 3.1396 - vel_loss: 0.0189 - time_loss: 7.5407e-04 - onoff_accuracy: 0.8146 - note_accuracy: 0.1620 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1727\n",
            "Epoch 286/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.2864 - onoff_loss: 0.4138 - note_loss: 3.1730 - vel_loss: 0.0185 - time_loss: 6.8099e-04 - onoff_accuracy: 0.8038 - note_accuracy: 0.1454 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 287/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.4520 - onoff_loss: 0.4132 - note_loss: 3.1628 - vel_loss: 0.0193 - time_loss: 8.5680e-04 - onoff_accuracy: 0.8032 - note_accuracy: 0.1528 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1890\n",
            "Epoch 288/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.1970 - onoff_loss: 0.3908 - note_loss: 3.1694 - vel_loss: 0.0179 - time_loss: 6.1884e-04 - onoff_accuracy: 0.8182 - note_accuracy: 0.1565 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1838\n",
            "Epoch 289/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.3624 - onoff_loss: 0.3995 - note_loss: 3.1807 - vel_loss: 0.0184 - time_loss: 7.6383e-04 - onoff_accuracy: 0.8152 - note_accuracy: 0.1457 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1972\n",
            "Epoch 290/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.1778 - onoff_loss: 0.3895 - note_loss: 3.1217 - vel_loss: 0.0187 - time_loss: 6.4791e-04 - onoff_accuracy: 0.8209 - note_accuracy: 0.1552 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1756\n",
            "Epoch 291/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.2748 - onoff_loss: 0.4149 - note_loss: 3.1507 - vel_loss: 0.0194 - time_loss: 6.8979e-04 - onoff_accuracy: 0.8045 - note_accuracy: 0.1527 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1859\n",
            "Epoch 292/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 4.2809 - onoff_loss: 0.3908 - note_loss: 3.1688 - vel_loss: 0.0191 - time_loss: 7.0220e-04 - onoff_accuracy: 0.8185 - note_accuracy: 0.1532 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 293/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.2632 - onoff_loss: 0.4008 - note_loss: 3.1432 - vel_loss: 0.0197 - time_loss: 6.9948e-04 - onoff_accuracy: 0.8120 - note_accuracy: 0.1633 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1905\n",
            "Epoch 294/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.1521 - onoff_loss: 0.3866 - note_loss: 3.1275 - vel_loss: 0.0177 - time_loss: 6.2030e-04 - onoff_accuracy: 0.8189 - note_accuracy: 0.1619 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 295/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.2582 - onoff_loss: 0.4172 - note_loss: 3.1121 - vel_loss: 0.0184 - time_loss: 7.1059e-04 - onoff_accuracy: 0.8029 - note_accuracy: 0.1590 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1570\n",
            "Epoch 296/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 4.2168 - onoff_loss: 0.3870 - note_loss: 3.0857 - vel_loss: 0.0195 - time_loss: 7.2461e-04 - onoff_accuracy: 0.8206 - note_accuracy: 0.1660 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1835\n",
            "Epoch 297/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 4.2536 - onoff_loss: 0.3839 - note_loss: 3.1886 - vel_loss: 0.0183 - time_loss: 6.6286e-04 - onoff_accuracy: 0.8239 - note_accuracy: 0.1501 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1510\n",
            "Epoch 298/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.1643 - onoff_loss: 0.4016 - note_loss: 3.1068 - vel_loss: 0.0183 - time_loss: 6.3762e-04 - onoff_accuracy: 0.8130 - note_accuracy: 0.1622 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1678\n",
            "Epoch 299/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.1196 - onoff_loss: 0.3940 - note_loss: 3.0700 - vel_loss: 0.0187 - time_loss: 6.3701e-04 - onoff_accuracy: 0.8165 - note_accuracy: 0.1628 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1578\n",
            "Epoch 300/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.0151 - onoff_loss: 0.3805 - note_loss: 3.0633 - vel_loss: 0.0179 - time_loss: 5.5338e-04 - onoff_accuracy: 0.8238 - note_accuracy: 0.1682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1670\n",
            "Epoch 301/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 4.1322 - onoff_loss: 0.3941 - note_loss: 3.0820 - vel_loss: 0.0185 - time_loss: 6.3756e-04 - onoff_accuracy: 0.8158 - note_accuracy: 0.1698 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 302/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.0675 - onoff_loss: 0.3849 - note_loss: 3.0571 - vel_loss: 0.0182 - time_loss: 6.0739e-04 - onoff_accuracy: 0.8223 - note_accuracy: 0.1730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1817\n",
            "Epoch 303/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 4.1761 - onoff_loss: 0.3941 - note_loss: 3.1126 - vel_loss: 0.0185 - time_loss: 6.5088e-04 - onoff_accuracy: 0.8163 - note_accuracy: 0.1634 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1592\n",
            "Epoch 304/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.0854 - onoff_loss: 0.3962 - note_loss: 3.0978 - vel_loss: 0.0171 - time_loss: 5.7437e-04 - onoff_accuracy: 0.8145 - note_accuracy: 0.1645 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1572\n",
            "Epoch 305/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.0715 - onoff_loss: 0.3721 - note_loss: 3.0291 - vel_loss: 0.0184 - time_loss: 6.5192e-04 - onoff_accuracy: 0.8297 - note_accuracy: 0.1758 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1888\n",
            "Epoch 306/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 4.0644 - onoff_loss: 0.3965 - note_loss: 3.0689 - vel_loss: 0.0179 - time_loss: 5.8102e-04 - onoff_accuracy: 0.8148 - note_accuracy: 0.1633 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1590\n",
            "Epoch 307/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.1534 - onoff_loss: 0.3805 - note_loss: 3.1032 - vel_loss: 0.0181 - time_loss: 6.5158e-04 - onoff_accuracy: 0.8262 - note_accuracy: 0.1650 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1766\n",
            "Epoch 308/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.9918 - onoff_loss: 0.3895 - note_loss: 3.0438 - vel_loss: 0.0176 - time_loss: 5.4100e-04 - onoff_accuracy: 0.8195 - note_accuracy: 0.1693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1583\n",
            "Epoch 309/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 4.0995 - onoff_loss: 0.3597 - note_loss: 3.0684 - vel_loss: 0.0190 - time_loss: 6.5241e-04 - onoff_accuracy: 0.8369 - note_accuracy: 0.1724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1870\n",
            "Epoch 310/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.9514 - onoff_loss: 0.3881 - note_loss: 3.0240 - vel_loss: 0.0168 - time_loss: 5.2247e-04 - onoff_accuracy: 0.8176 - note_accuracy: 0.1745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1627\n",
            "Epoch 311/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 4.0716 - onoff_loss: 0.3701 - note_loss: 3.0136 - vel_loss: 0.0172 - time_loss: 6.7063e-04 - onoff_accuracy: 0.8301 - note_accuracy: 0.1777 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1546\n",
            "Epoch 312/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.8777 - onoff_loss: 0.3574 - note_loss: 2.9638 - vel_loss: 0.0183 - time_loss: 5.3812e-04 - onoff_accuracy: 0.8368 - note_accuracy: 0.1917 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 313/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.9018 - onoff_loss: 0.3807 - note_loss: 2.9764 - vel_loss: 0.0172 - time_loss: 5.2749e-04 - onoff_accuracy: 0.8226 - note_accuracy: 0.1857 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 314/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.9456 - onoff_loss: 0.3573 - note_loss: 2.9843 - vel_loss: 0.0184 - time_loss: 5.8549e-04 - onoff_accuracy: 0.8359 - note_accuracy: 0.1859 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 315/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.9522 - onoff_loss: 0.3613 - note_loss: 2.9680 - vel_loss: 0.0188 - time_loss: 6.0411e-04 - onoff_accuracy: 0.8341 - note_accuracy: 0.1899 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 316/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.8435 - onoff_loss: 0.3387 - note_loss: 2.9303 - vel_loss: 0.0192 - time_loss: 5.5532e-04 - onoff_accuracy: 0.8477 - note_accuracy: 0.1975 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1988\n",
            "Epoch 317/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.9176 - onoff_loss: 0.3700 - note_loss: 3.0164 - vel_loss: 0.0184 - time_loss: 5.1282e-04 - onoff_accuracy: 0.8320 - note_accuracy: 0.1806 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 318/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.9662 - onoff_loss: 0.3660 - note_loss: 2.9197 - vel_loss: 0.0188 - time_loss: 6.6163e-04 - onoff_accuracy: 0.8304 - note_accuracy: 0.2033 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1903\n",
            "Epoch 319/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.7555 - onoff_loss: 0.3423 - note_loss: 2.8976 - vel_loss: 0.0180 - time_loss: 4.9769e-04 - onoff_accuracy: 0.8476 - note_accuracy: 0.2013 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 320/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.9395 - onoff_loss: 0.3670 - note_loss: 3.0250 - vel_loss: 0.0182 - time_loss: 5.2941e-04 - onoff_accuracy: 0.8330 - note_accuracy: 0.1824 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1627\n",
            "Epoch 321/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.8429 - onoff_loss: 0.3466 - note_loss: 2.9781 - vel_loss: 0.0181 - time_loss: 5.0015e-04 - onoff_accuracy: 0.8417 - note_accuracy: 0.1935 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 322/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.9262 - onoff_loss: 0.3776 - note_loss: 2.9772 - vel_loss: 0.0172 - time_loss: 5.5416e-04 - onoff_accuracy: 0.8231 - note_accuracy: 0.1876 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1565\n",
            "Epoch 323/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.7969 - onoff_loss: 0.3321 - note_loss: 2.9322 - vel_loss: 0.0191 - time_loss: 5.1349e-04 - onoff_accuracy: 0.8516 - note_accuracy: 0.2037 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 324/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.8277 - onoff_loss: 0.3661 - note_loss: 2.9495 - vel_loss: 0.0177 - time_loss: 4.9445e-04 - onoff_accuracy: 0.8297 - note_accuracy: 0.1949 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 325/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.6745 - onoff_loss: 0.3430 - note_loss: 2.8573 - vel_loss: 0.0174 - time_loss: 4.5680e-04 - onoff_accuracy: 0.8435 - note_accuracy: 0.2123 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1822\n",
            "Epoch 326/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.9547 - onoff_loss: 0.3504 - note_loss: 2.9559 - vel_loss: 0.0178 - time_loss: 6.3067e-04 - onoff_accuracy: 0.8409 - note_accuracy: 0.1868 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1661\n",
            "Epoch 327/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.8594 - onoff_loss: 0.3293 - note_loss: 2.9166 - vel_loss: 0.0176 - time_loss: 5.9593e-04 - onoff_accuracy: 0.8550 - note_accuracy: 0.1937 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1649\n",
            "Epoch 328/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.7199 - onoff_loss: 0.3264 - note_loss: 2.8921 - vel_loss: 0.0186 - time_loss: 4.8276e-04 - onoff_accuracy: 0.8532 - note_accuracy: 0.2092 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1949\n",
            "Epoch 329/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.7037 - onoff_loss: 0.3317 - note_loss: 2.8752 - vel_loss: 0.0176 - time_loss: 4.7911e-04 - onoff_accuracy: 0.8516 - note_accuracy: 0.2082 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1628\n",
            "Epoch 330/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.8496 - onoff_loss: 0.3474 - note_loss: 2.9159 - vel_loss: 0.0183 - time_loss: 5.6803e-04 - onoff_accuracy: 0.8426 - note_accuracy: 0.2056 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 331/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.7170 - onoff_loss: 0.3329 - note_loss: 2.8996 - vel_loss: 0.0175 - time_loss: 4.6702e-04 - onoff_accuracy: 0.8507 - note_accuracy: 0.2057 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1751\n",
            "Epoch 332/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.7939 - onoff_loss: 0.3300 - note_loss: 2.8752 - vel_loss: 0.0178 - time_loss: 5.7092e-04 - onoff_accuracy: 0.8520 - note_accuracy: 0.2031 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 333/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.5700 - onoff_loss: 0.3223 - note_loss: 2.7856 - vel_loss: 0.0180 - time_loss: 4.4412e-04 - onoff_accuracy: 0.8572 - note_accuracy: 0.2282 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1994\n",
            "Epoch 334/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.7067 - onoff_loss: 0.3388 - note_loss: 2.8515 - vel_loss: 0.0179 - time_loss: 4.9847e-04 - onoff_accuracy: 0.8451 - note_accuracy: 0.2140 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1594\n",
            "Epoch 335/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.5743 - onoff_loss: 0.3133 - note_loss: 2.7866 - vel_loss: 0.0174 - time_loss: 4.5702e-04 - onoff_accuracy: 0.8624 - note_accuracy: 0.2252 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1727\n",
            "Epoch 336/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.6269 - onoff_loss: 0.3381 - note_loss: 2.8083 - vel_loss: 0.0177 - time_loss: 4.6279e-04 - onoff_accuracy: 0.8479 - note_accuracy: 0.2186 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1668\n",
            "Epoch 337/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.6302 - onoff_loss: 0.3471 - note_loss: 2.7891 - vel_loss: 0.0173 - time_loss: 4.7669e-04 - onoff_accuracy: 0.8397 - note_accuracy: 0.2248 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1800\n",
            "Epoch 338/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.6806 - onoff_loss: 0.3284 - note_loss: 2.8769 - vel_loss: 0.0186 - time_loss: 4.5671e-04 - onoff_accuracy: 0.8526 - note_accuracy: 0.2125 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1827\n",
            "Epoch 339/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.5867 - onoff_loss: 0.3292 - note_loss: 2.8048 - vel_loss: 0.0183 - time_loss: 4.3432e-04 - onoff_accuracy: 0.8522 - note_accuracy: 0.2250 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 340/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.6026 - onoff_loss: 0.3350 - note_loss: 2.7849 - vel_loss: 0.0176 - time_loss: 4.6512e-04 - onoff_accuracy: 0.8478 - note_accuracy: 0.2256 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1744\n",
            "Epoch 341/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.6549 - onoff_loss: 0.3089 - note_loss: 2.8187 - vel_loss: 0.0174 - time_loss: 5.0994e-04 - onoff_accuracy: 0.8662 - note_accuracy: 0.2180 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1782\n",
            "Epoch 342/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.5751 - onoff_loss: 0.2957 - note_loss: 2.7980 - vel_loss: 0.0183 - time_loss: 4.6319e-04 - onoff_accuracy: 0.8702 - note_accuracy: 0.2264 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1789\n",
            "Epoch 343/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.4243 - onoff_loss: 0.3078 - note_loss: 2.7244 - vel_loss: 0.0179 - time_loss: 3.7413e-04 - onoff_accuracy: 0.8642 - note_accuracy: 0.2354 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1791\n",
            "Epoch 344/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.5846 - onoff_loss: 0.3130 - note_loss: 2.8110 - vel_loss: 0.0185 - time_loss: 4.4207e-04 - onoff_accuracy: 0.8622 - note_accuracy: 0.2197 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1744\n",
            "Epoch 345/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.5551 - onoff_loss: 0.2946 - note_loss: 2.7155 - vel_loss: 0.0187 - time_loss: 5.2631e-04 - onoff_accuracy: 0.8732 - note_accuracy: 0.2389 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 346/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.5304 - onoff_loss: 0.3316 - note_loss: 2.7506 - vel_loss: 0.0179 - time_loss: 4.3040e-04 - onoff_accuracy: 0.8502 - note_accuracy: 0.2347 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 347/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.5827 - onoff_loss: 0.3210 - note_loss: 2.7315 - vel_loss: 0.0176 - time_loss: 5.1261e-04 - onoff_accuracy: 0.8558 - note_accuracy: 0.2391 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1773\n",
            "Epoch 348/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.3379 - onoff_loss: 0.2939 - note_loss: 2.6594 - vel_loss: 0.0178 - time_loss: 3.6675e-04 - onoff_accuracy: 0.8697 - note_accuracy: 0.2467 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1857\n",
            "Epoch 349/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.4638 - onoff_loss: 0.3022 - note_loss: 2.7292 - vel_loss: 0.0171 - time_loss: 4.1529e-04 - onoff_accuracy: 0.8663 - note_accuracy: 0.2400 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 350/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.4462 - onoff_loss: 0.2885 - note_loss: 2.6798 - vel_loss: 0.0166 - time_loss: 4.6128e-04 - onoff_accuracy: 0.8730 - note_accuracy: 0.2480 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1797\n",
            "Epoch 351/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.3434 - onoff_loss: 0.2785 - note_loss: 2.6655 - vel_loss: 0.0176 - time_loss: 3.8172e-04 - onoff_accuracy: 0.8797 - note_accuracy: 0.2500 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 352/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.2912 - onoff_loss: 0.2831 - note_loss: 2.6506 - vel_loss: 0.0178 - time_loss: 3.3981e-04 - onoff_accuracy: 0.8760 - note_accuracy: 0.2503 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1683\n",
            "Epoch 353/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.4331 - onoff_loss: 0.3038 - note_loss: 2.6915 - vel_loss: 0.0174 - time_loss: 4.2039e-04 - onoff_accuracy: 0.8665 - note_accuracy: 0.2442 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1580\n",
            "Epoch 354/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.4108 - onoff_loss: 0.2787 - note_loss: 2.6442 - vel_loss: 0.0177 - time_loss: 4.7015e-04 - onoff_accuracy: 0.8790 - note_accuracy: 0.2529 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 355/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 3.3580 - onoff_loss: 0.2903 - note_loss: 2.6535 - vel_loss: 0.0177 - time_loss: 3.9651e-04 - onoff_accuracy: 0.8715 - note_accuracy: 0.2577 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1808\n",
            "Epoch 356/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.4014 - onoff_loss: 0.2779 - note_loss: 2.6485 - vel_loss: 0.0175 - time_loss: 4.5751e-04 - onoff_accuracy: 0.8814 - note_accuracy: 0.2596 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 357/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 3.3899 - onoff_loss: 0.3383 - note_loss: 2.6418 - vel_loss: 0.0177 - time_loss: 3.9202e-04 - onoff_accuracy: 0.8470 - note_accuracy: 0.2569 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1659\n",
            "Epoch 358/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.3370 - onoff_loss: 0.2902 - note_loss: 2.5946 - vel_loss: 0.0184 - time_loss: 4.3376e-04 - onoff_accuracy: 0.8737 - note_accuracy: 0.2686 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1761\n",
            "Epoch 359/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.2254 - onoff_loss: 0.2718 - note_loss: 2.5824 - vel_loss: 0.0177 - time_loss: 3.5350e-04 - onoff_accuracy: 0.8820 - note_accuracy: 0.2702 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1947\n",
            "Epoch 360/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 3.3719 - onoff_loss: 0.2796 - note_loss: 2.5696 - vel_loss: 0.0181 - time_loss: 5.0458e-04 - onoff_accuracy: 0.8781 - note_accuracy: 0.2718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1637\n",
            "Epoch 361/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.2919 - onoff_loss: 0.2695 - note_loss: 2.6083 - vel_loss: 0.0190 - time_loss: 3.9519e-04 - onoff_accuracy: 0.8841 - note_accuracy: 0.2711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1810\n",
            "Epoch 362/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.2809 - onoff_loss: 0.2701 - note_loss: 2.6252 - vel_loss: 0.0176 - time_loss: 3.6797e-04 - onoff_accuracy: 0.8840 - note_accuracy: 0.2697 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 363/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.4602 - onoff_loss: 0.2637 - note_loss: 2.5618 - vel_loss: 0.0186 - time_loss: 6.1609e-04 - onoff_accuracy: 0.8869 - note_accuracy: 0.2752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 364/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.2373 - onoff_loss: 0.2750 - note_loss: 2.5697 - vel_loss: 0.0177 - time_loss: 3.7483e-04 - onoff_accuracy: 0.8795 - note_accuracy: 0.2752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1546\n",
            "Epoch 365/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.3820 - onoff_loss: 0.2706 - note_loss: 2.6131 - vel_loss: 0.0183 - time_loss: 4.8005e-04 - onoff_accuracy: 0.8831 - note_accuracy: 0.2649 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 366/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.1244 - onoff_loss: 0.2527 - note_loss: 2.5335 - vel_loss: 0.0176 - time_loss: 3.2058e-04 - onoff_accuracy: 0.8924 - note_accuracy: 0.2798 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 367/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 3.1945 - onoff_loss: 0.2576 - note_loss: 2.5016 - vel_loss: 0.0177 - time_loss: 4.1762e-04 - onoff_accuracy: 0.8897 - note_accuracy: 0.2859 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1629\n",
            "Epoch 368/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.2791 - onoff_loss: 0.2735 - note_loss: 2.6167 - vel_loss: 0.0175 - time_loss: 3.7137e-04 - onoff_accuracy: 0.8812 - note_accuracy: 0.2688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1825\n",
            "Epoch 369/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.0924 - onoff_loss: 0.2424 - note_loss: 2.4781 - vel_loss: 0.0186 - time_loss: 3.5326e-04 - onoff_accuracy: 0.8989 - note_accuracy: 0.3013 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1995\n",
            "Epoch 370/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.0673 - onoff_loss: 0.2548 - note_loss: 2.4281 - vel_loss: 0.0187 - time_loss: 3.6570e-04 - onoff_accuracy: 0.8917 - note_accuracy: 0.3046 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1855\n",
            "Epoch 371/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.2328 - onoff_loss: 0.2708 - note_loss: 2.5218 - vel_loss: 0.0177 - time_loss: 4.2245e-04 - onoff_accuracy: 0.8824 - note_accuracy: 0.2876 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1751\n",
            "Epoch 372/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.2548 - onoff_loss: 0.2537 - note_loss: 2.5094 - vel_loss: 0.0181 - time_loss: 4.7355e-04 - onoff_accuracy: 0.8914 - note_accuracy: 0.2871 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 373/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.0683 - onoff_loss: 0.2725 - note_loss: 2.4388 - vel_loss: 0.0179 - time_loss: 3.3907e-04 - onoff_accuracy: 0.8797 - note_accuracy: 0.3024 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 374/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.0372 - onoff_loss: 0.2411 - note_loss: 2.4085 - vel_loss: 0.0193 - time_loss: 3.6833e-04 - onoff_accuracy: 0.8981 - note_accuracy: 0.3186 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1910\n",
            "Epoch 375/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.0327 - onoff_loss: 0.2444 - note_loss: 2.4135 - vel_loss: 0.0183 - time_loss: 3.5660e-04 - onoff_accuracy: 0.8960 - note_accuracy: 0.3101 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 376/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.1245 - onoff_loss: 0.2386 - note_loss: 2.5116 - vel_loss: 0.0179 - time_loss: 3.5633e-04 - onoff_accuracy: 0.8983 - note_accuracy: 0.2886 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1697\n",
            "Epoch 377/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 3.1432 - onoff_loss: 0.2857 - note_loss: 2.5105 - vel_loss: 0.0171 - time_loss: 3.2992e-04 - onoff_accuracy: 0.8732 - note_accuracy: 0.2907 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 378/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.0591 - onoff_loss: 0.2374 - note_loss: 2.3867 - vel_loss: 0.0180 - time_loss: 4.1701e-04 - onoff_accuracy: 0.9016 - note_accuracy: 0.3192 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1789\n",
            "Epoch 379/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 3.0442 - onoff_loss: 0.2499 - note_loss: 2.4722 - vel_loss: 0.0176 - time_loss: 3.0456e-04 - onoff_accuracy: 0.8931 - note_accuracy: 0.2993 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1804\n",
            "Epoch 380/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.9273 - onoff_loss: 0.2189 - note_loss: 2.3416 - vel_loss: 0.0173 - time_loss: 3.4950e-04 - onoff_accuracy: 0.9091 - note_accuracy: 0.3260 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 381/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.9083 - onoff_loss: 0.2385 - note_loss: 2.3412 - vel_loss: 0.0185 - time_loss: 3.0999e-04 - onoff_accuracy: 0.8981 - note_accuracy: 0.3355 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1921\n",
            "Epoch 382/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 3.0764 - onoff_loss: 0.2625 - note_loss: 2.3939 - vel_loss: 0.0171 - time_loss: 4.0288e-04 - onoff_accuracy: 0.8874 - note_accuracy: 0.3198 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1610\n",
            "Epoch 383/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 3.0402 - onoff_loss: 0.2460 - note_loss: 2.4147 - vel_loss: 0.0174 - time_loss: 3.6203e-04 - onoff_accuracy: 0.8944 - note_accuracy: 0.3055 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1818\n",
            "Epoch 384/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 3.0452 - onoff_loss: 0.2502 - note_loss: 2.3687 - vel_loss: 0.0168 - time_loss: 4.0956e-04 - onoff_accuracy: 0.8922 - note_accuracy: 0.3171 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 385/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.9165 - onoff_loss: 0.2104 - note_loss: 2.3138 - vel_loss: 0.0186 - time_loss: 3.7375e-04 - onoff_accuracy: 0.9156 - note_accuracy: 0.3416 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 386/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.8709 - onoff_loss: 0.2319 - note_loss: 2.3007 - vel_loss: 0.0180 - time_loss: 3.2024e-04 - onoff_accuracy: 0.9028 - note_accuracy: 0.3422 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1876\n",
            "Epoch 387/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.9569 - onoff_loss: 0.2322 - note_loss: 2.2995 - vel_loss: 0.0192 - time_loss: 4.0585e-04 - onoff_accuracy: 0.9020 - note_accuracy: 0.3423 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1763\n",
            "Epoch 388/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.8870 - onoff_loss: 0.2350 - note_loss: 2.3167 - vel_loss: 0.0173 - time_loss: 3.1808e-04 - onoff_accuracy: 0.9000 - note_accuracy: 0.3362 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1818\n",
            "Epoch 389/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.9186 - onoff_loss: 0.2318 - note_loss: 2.3580 - vel_loss: 0.0179 - time_loss: 3.1085e-04 - onoff_accuracy: 0.9024 - note_accuracy: 0.3309 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1902\n",
            "Epoch 390/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.8797 - onoff_loss: 0.2406 - note_loss: 2.2774 - vel_loss: 0.0173 - time_loss: 3.4449e-04 - onoff_accuracy: 0.8952 - note_accuracy: 0.3418 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1618\n",
            "Epoch 391/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.8774 - onoff_loss: 0.2315 - note_loss: 2.2974 - vel_loss: 0.0176 - time_loss: 3.3092e-04 - onoff_accuracy: 0.9018 - note_accuracy: 0.3418 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1797\n",
            "Epoch 392/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.7863 - onoff_loss: 0.2165 - note_loss: 2.2526 - vel_loss: 0.0174 - time_loss: 2.9983e-04 - onoff_accuracy: 0.9120 - note_accuracy: 0.3525 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 393/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.8300 - onoff_loss: 0.2125 - note_loss: 2.2509 - vel_loss: 0.0184 - time_loss: 3.4819e-04 - onoff_accuracy: 0.9148 - note_accuracy: 0.3590 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1828\n",
            "Epoch 394/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.7789 - onoff_loss: 0.2328 - note_loss: 2.2433 - vel_loss: 0.0173 - time_loss: 2.8546e-04 - onoff_accuracy: 0.9020 - note_accuracy: 0.3584 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1957\n",
            "Epoch 395/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 2.7686 - onoff_loss: 0.2021 - note_loss: 2.1786 - vel_loss: 0.0177 - time_loss: 3.7010e-04 - onoff_accuracy: 0.9183 - note_accuracy: 0.3709 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1730\n",
            "Epoch 396/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.7953 - onoff_loss: 0.1955 - note_loss: 2.2587 - vel_loss: 0.0168 - time_loss: 3.2434e-04 - onoff_accuracy: 0.9219 - note_accuracy: 0.3486 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 397/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.8111 - onoff_loss: 0.2111 - note_loss: 2.2703 - vel_loss: 0.0175 - time_loss: 3.1226e-04 - onoff_accuracy: 0.9128 - note_accuracy: 0.3481 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 398/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.7347 - onoff_loss: 0.2076 - note_loss: 2.1985 - vel_loss: 0.0179 - time_loss: 3.1072e-04 - onoff_accuracy: 0.9147 - note_accuracy: 0.3690 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1860\n",
            "Epoch 399/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.7047 - onoff_loss: 0.2120 - note_loss: 2.1742 - vel_loss: 0.0186 - time_loss: 2.9992e-04 - onoff_accuracy: 0.9117 - note_accuracy: 0.3768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1856\n",
            "Epoch 400/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.7872 - onoff_loss: 0.2114 - note_loss: 2.1879 - vel_loss: 0.0173 - time_loss: 3.7069e-04 - onoff_accuracy: 0.9154 - note_accuracy: 0.3700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1647\n",
            "Epoch 401/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 2.7021 - onoff_loss: 0.1963 - note_loss: 2.1859 - vel_loss: 0.0175 - time_loss: 3.0246e-04 - onoff_accuracy: 0.9227 - note_accuracy: 0.3719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1757\n",
            "Epoch 402/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.7462 - onoff_loss: 0.2090 - note_loss: 2.1874 - vel_loss: 0.0176 - time_loss: 3.3225e-04 - onoff_accuracy: 0.9144 - note_accuracy: 0.3693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 403/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.6730 - onoff_loss: 0.1969 - note_loss: 2.1642 - vel_loss: 0.0171 - time_loss: 2.9487e-04 - onoff_accuracy: 0.9207 - note_accuracy: 0.3745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 404/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.7206 - onoff_loss: 0.2187 - note_loss: 2.1655 - vel_loss: 0.0175 - time_loss: 3.1890e-04 - onoff_accuracy: 0.9093 - note_accuracy: 0.3801 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 405/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.6455 - onoff_loss: 0.1968 - note_loss: 2.1203 - vel_loss: 0.0177 - time_loss: 3.1076e-04 - onoff_accuracy: 0.9206 - note_accuracy: 0.3877 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1832\n",
            "Epoch 406/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.5555 - onoff_loss: 0.1808 - note_loss: 2.0777 - vel_loss: 0.0168 - time_loss: 2.8019e-04 - onoff_accuracy: 0.9290 - note_accuracy: 0.3925 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 407/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 2.6497 - onoff_loss: 0.2046 - note_loss: 2.0950 - vel_loss: 0.0179 - time_loss: 3.3215e-04 - onoff_accuracy: 0.9145 - note_accuracy: 0.3942 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1824\n",
            "Epoch 408/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 2.6470 - onoff_loss: 0.2054 - note_loss: 2.0928 - vel_loss: 0.0175 - time_loss: 3.3131e-04 - onoff_accuracy: 0.9142 - note_accuracy: 0.3960 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 409/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.4984 - onoff_loss: 0.1820 - note_loss: 2.0216 - vel_loss: 0.0180 - time_loss: 2.7676e-04 - onoff_accuracy: 0.9286 - note_accuracy: 0.4119 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 410/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.5319 - onoff_loss: 0.1900 - note_loss: 2.0528 - vel_loss: 0.0177 - time_loss: 2.7143e-04 - onoff_accuracy: 0.9236 - note_accuracy: 0.4037 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 411/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.7086 - onoff_loss: 0.1949 - note_loss: 2.1345 - vel_loss: 0.0178 - time_loss: 3.6145e-04 - onoff_accuracy: 0.9200 - note_accuracy: 0.3829 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 412/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.4810 - onoff_loss: 0.1704 - note_loss: 2.0090 - vel_loss: 0.0168 - time_loss: 2.8475e-04 - onoff_accuracy: 0.9333 - note_accuracy: 0.4148 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1648\n",
            "Epoch 413/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.6267 - onoff_loss: 0.2152 - note_loss: 2.0672 - vel_loss: 0.0171 - time_loss: 3.2725e-04 - onoff_accuracy: 0.9107 - note_accuracy: 0.3966 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 414/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.5125 - onoff_loss: 0.1779 - note_loss: 2.0271 - vel_loss: 0.0172 - time_loss: 2.9033e-04 - onoff_accuracy: 0.9294 - note_accuracy: 0.4099 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1654\n",
            "Epoch 415/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.5143 - onoff_loss: 0.1757 - note_loss: 2.0195 - vel_loss: 0.0179 - time_loss: 3.0116e-04 - onoff_accuracy: 0.9309 - note_accuracy: 0.4133 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1876\n",
            "Epoch 416/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.4568 - onoff_loss: 0.1737 - note_loss: 1.9442 - vel_loss: 0.0180 - time_loss: 3.2091e-04 - onoff_accuracy: 0.9296 - note_accuracy: 0.4354 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 417/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.4861 - onoff_loss: 0.1806 - note_loss: 1.9809 - vel_loss: 0.0180 - time_loss: 3.0662e-04 - onoff_accuracy: 0.9282 - note_accuracy: 0.4268 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1808\n",
            "Epoch 418/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.5833 - onoff_loss: 0.1937 - note_loss: 2.0638 - vel_loss: 0.0174 - time_loss: 3.0843e-04 - onoff_accuracy: 0.9215 - note_accuracy: 0.4099 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1590\n",
            "Epoch 419/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.5592 - onoff_loss: 0.1896 - note_loss: 1.9654 - vel_loss: 0.0176 - time_loss: 3.8659e-04 - onoff_accuracy: 0.9204 - note_accuracy: 0.4292 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1723\n",
            "Epoch 420/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.4694 - onoff_loss: 0.1894 - note_loss: 1.9626 - vel_loss: 0.0183 - time_loss: 2.9925e-04 - onoff_accuracy: 0.9224 - note_accuracy: 0.4324 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1623\n",
            "Epoch 421/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 2.4436 - onoff_loss: 0.1608 - note_loss: 1.9719 - vel_loss: 0.0170 - time_loss: 2.9380e-04 - onoff_accuracy: 0.9395 - note_accuracy: 0.4335 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1763\n",
            "Epoch 422/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.4326 - onoff_loss: 0.1872 - note_loss: 1.9235 - vel_loss: 0.0175 - time_loss: 3.0440e-04 - onoff_accuracy: 0.9225 - note_accuracy: 0.4458 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 423/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.3708 - onoff_loss: 0.1592 - note_loss: 1.9113 - vel_loss: 0.0186 - time_loss: 2.8160e-04 - onoff_accuracy: 0.9387 - note_accuracy: 0.4474 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1928\n",
            "Epoch 424/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.4068 - onoff_loss: 0.1900 - note_loss: 1.9416 - vel_loss: 0.0178 - time_loss: 2.5739e-04 - onoff_accuracy: 0.9214 - note_accuracy: 0.4399 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1788\n",
            "Epoch 425/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.4158 - onoff_loss: 0.1565 - note_loss: 1.9212 - vel_loss: 0.0176 - time_loss: 3.2050e-04 - onoff_accuracy: 0.9415 - note_accuracy: 0.4446 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1613\n",
            "Epoch 426/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.3260 - onoff_loss: 0.1519 - note_loss: 1.8337 - vel_loss: 0.0185 - time_loss: 3.2181e-04 - onoff_accuracy: 0.9428 - note_accuracy: 0.4692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1774\n",
            "Epoch 427/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.2158 - onoff_loss: 0.1438 - note_loss: 1.7780 - vel_loss: 0.0182 - time_loss: 2.7583e-04 - onoff_accuracy: 0.9453 - note_accuracy: 0.4822 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1732\n",
            "Epoch 428/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.3449 - onoff_loss: 0.1499 - note_loss: 1.8653 - vel_loss: 0.0185 - time_loss: 3.1120e-04 - onoff_accuracy: 0.9422 - note_accuracy: 0.4584 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1871\n",
            "Epoch 429/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 2.3244 - onoff_loss: 0.1772 - note_loss: 1.8292 - vel_loss: 0.0175 - time_loss: 3.0040e-04 - onoff_accuracy: 0.9282 - note_accuracy: 0.4707 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1615\n",
            "Epoch 430/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.2876 - onoff_loss: 0.1474 - note_loss: 1.8342 - vel_loss: 0.0172 - time_loss: 2.8883e-04 - onoff_accuracy: 0.9445 - note_accuracy: 0.4645 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1727\n",
            "Epoch 431/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.2691 - onoff_loss: 0.1531 - note_loss: 1.8242 - vel_loss: 0.0170 - time_loss: 2.7488e-04 - onoff_accuracy: 0.9411 - note_accuracy: 0.4685 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1631\n",
            "Epoch 432/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.4261 - onoff_loss: 0.1666 - note_loss: 1.9221 - vel_loss: 0.0180 - time_loss: 3.1939e-04 - onoff_accuracy: 0.9336 - note_accuracy: 0.4550 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1816\n",
            "Epoch 433/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.2335 - onoff_loss: 0.1514 - note_loss: 1.7849 - vel_loss: 0.0177 - time_loss: 2.7955e-04 - onoff_accuracy: 0.9413 - note_accuracy: 0.4820 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1517\n",
            "Epoch 434/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.2994 - onoff_loss: 0.1476 - note_loss: 1.8557 - vel_loss: 0.0182 - time_loss: 2.7792e-04 - onoff_accuracy: 0.9443 - note_accuracy: 0.4644 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1876\n",
            "Epoch 435/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.2967 - onoff_loss: 0.1831 - note_loss: 1.8236 - vel_loss: 0.0171 - time_loss: 2.7298e-04 - onoff_accuracy: 0.9257 - note_accuracy: 0.4737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1767\n",
            "Epoch 436/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.1844 - onoff_loss: 0.1355 - note_loss: 1.7432 - vel_loss: 0.0177 - time_loss: 2.8800e-04 - onoff_accuracy: 0.9521 - note_accuracy: 0.4966 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1794\n",
            "Epoch 437/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.2175 - onoff_loss: 0.1415 - note_loss: 1.7720 - vel_loss: 0.0178 - time_loss: 2.8623e-04 - onoff_accuracy: 0.9482 - note_accuracy: 0.4853 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1715\n",
            "Epoch 438/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.1919 - onoff_loss: 0.1403 - note_loss: 1.7937 - vel_loss: 0.0181 - time_loss: 2.3978e-04 - onoff_accuracy: 0.9501 - note_accuracy: 0.4837 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1759\n",
            "Epoch 439/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.2979 - onoff_loss: 0.1830 - note_loss: 1.7527 - vel_loss: 0.0178 - time_loss: 3.4437e-04 - onoff_accuracy: 0.9247 - note_accuracy: 0.4963 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1683\n",
            "Epoch 440/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.0773 - onoff_loss: 0.1352 - note_loss: 1.6476 - vel_loss: 0.0181 - time_loss: 2.7634e-04 - onoff_accuracy: 0.9492 - note_accuracy: 0.5212 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1663\n",
            "Epoch 441/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.2866 - onoff_loss: 0.1356 - note_loss: 1.7423 - vel_loss: 0.0170 - time_loss: 3.9180e-04 - onoff_accuracy: 0.9494 - note_accuracy: 0.4939 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1550\n",
            "Epoch 442/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.0645 - onoff_loss: 0.1289 - note_loss: 1.6728 - vel_loss: 0.0178 - time_loss: 2.4492e-04 - onoff_accuracy: 0.9541 - note_accuracy: 0.5187 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1674\n",
            "Epoch 443/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.1910 - onoff_loss: 0.1637 - note_loss: 1.7168 - vel_loss: 0.0180 - time_loss: 2.9243e-04 - onoff_accuracy: 0.9345 - note_accuracy: 0.4963 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 444/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.0344 - onoff_loss: 0.1258 - note_loss: 1.6220 - vel_loss: 0.0172 - time_loss: 2.6939e-04 - onoff_accuracy: 0.9543 - note_accuracy: 0.5366 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1680\n",
            "Epoch 445/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.1107 - onoff_loss: 0.1499 - note_loss: 1.6740 - vel_loss: 0.0176 - time_loss: 2.6921e-04 - onoff_accuracy: 0.9413 - note_accuracy: 0.5161 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 446/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.0718 - onoff_loss: 0.1455 - note_loss: 1.6274 - vel_loss: 0.0171 - time_loss: 2.8179e-04 - onoff_accuracy: 0.9442 - note_accuracy: 0.5310 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1642\n",
            "Epoch 447/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.9908 - onoff_loss: 0.1145 - note_loss: 1.5911 - vel_loss: 0.0181 - time_loss: 2.6705e-04 - onoff_accuracy: 0.9605 - note_accuracy: 0.5379 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1749\n",
            "Epoch 448/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.1470 - onoff_loss: 0.1597 - note_loss: 1.7028 - vel_loss: 0.0168 - time_loss: 2.6767e-04 - onoff_accuracy: 0.9378 - note_accuracy: 0.5061 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1595\n",
            "Epoch 449/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.0725 - onoff_loss: 0.1387 - note_loss: 1.6308 - vel_loss: 0.0176 - time_loss: 2.8545e-04 - onoff_accuracy: 0.9498 - note_accuracy: 0.5288 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 450/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.9923 - onoff_loss: 0.1303 - note_loss: 1.5954 - vel_loss: 0.0175 - time_loss: 2.4911e-04 - onoff_accuracy: 0.9533 - note_accuracy: 0.5353 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1861\n",
            "Epoch 451/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.0214 - onoff_loss: 0.1282 - note_loss: 1.5782 - vel_loss: 0.0172 - time_loss: 2.9775e-04 - onoff_accuracy: 0.9519 - note_accuracy: 0.5470 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1719\n",
            "Epoch 452/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 2.1037 - onoff_loss: 0.1585 - note_loss: 1.6751 - vel_loss: 0.0172 - time_loss: 2.5294e-04 - onoff_accuracy: 0.9360 - note_accuracy: 0.5137 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1700\n",
            "Epoch 453/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 2.1868 - onoff_loss: 0.1508 - note_loss: 1.6471 - vel_loss: 0.0167 - time_loss: 3.7228e-04 - onoff_accuracy: 0.9421 - note_accuracy: 0.5219 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1635\n",
            "Epoch 454/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 2.0323 - onoff_loss: 0.1163 - note_loss: 1.6006 - vel_loss: 0.0178 - time_loss: 2.9770e-04 - onoff_accuracy: 0.9589 - note_accuracy: 0.5366 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 455/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.9419 - onoff_loss: 0.1259 - note_loss: 1.5075 - vel_loss: 0.0181 - time_loss: 2.9047e-04 - onoff_accuracy: 0.9530 - note_accuracy: 0.5619 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 456/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.9837 - onoff_loss: 0.1303 - note_loss: 1.5766 - vel_loss: 0.0180 - time_loss: 2.5875e-04 - onoff_accuracy: 0.9508 - note_accuracy: 0.5492 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1756\n",
            "Epoch 457/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 2.0500 - onoff_loss: 0.1196 - note_loss: 1.5765 - vel_loss: 0.0178 - time_loss: 3.3615e-04 - onoff_accuracy: 0.9566 - note_accuracy: 0.5477 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 458/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.9451 - onoff_loss: 0.1250 - note_loss: 1.5685 - vel_loss: 0.0174 - time_loss: 2.3421e-04 - onoff_accuracy: 0.9551 - note_accuracy: 0.5497 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1670\n",
            "Epoch 459/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.9489 - onoff_loss: 0.1271 - note_loss: 1.5172 - vel_loss: 0.0179 - time_loss: 2.8670e-04 - onoff_accuracy: 0.9522 - note_accuracy: 0.5609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 460/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.9637 - onoff_loss: 0.1629 - note_loss: 1.5049 - vel_loss: 0.0172 - time_loss: 2.7871e-04 - onoff_accuracy: 0.9365 - note_accuracy: 0.5660 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1688\n",
            "Epoch 461/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.8354 - onoff_loss: 0.1094 - note_loss: 1.4614 - vel_loss: 0.0175 - time_loss: 2.4717e-04 - onoff_accuracy: 0.9616 - note_accuracy: 0.5770 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 462/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.9604 - onoff_loss: 0.1270 - note_loss: 1.5605 - vel_loss: 0.0171 - time_loss: 2.5564e-04 - onoff_accuracy: 0.9515 - note_accuracy: 0.5505 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1610\n",
            "Epoch 463/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.8150 - onoff_loss: 0.1093 - note_loss: 1.4445 - vel_loss: 0.0182 - time_loss: 2.4302e-04 - onoff_accuracy: 0.9616 - note_accuracy: 0.5841 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 464/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 1.8383 - onoff_loss: 0.1077 - note_loss: 1.4575 - vel_loss: 0.0172 - time_loss: 2.5598e-04 - onoff_accuracy: 0.9618 - note_accuracy: 0.5785 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1914\n",
            "Epoch 465/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.9177 - onoff_loss: 0.1145 - note_loss: 1.4798 - vel_loss: 0.0175 - time_loss: 3.0595e-04 - onoff_accuracy: 0.9591 - note_accuracy: 0.5738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1663\n",
            "Epoch 466/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.8144 - onoff_loss: 0.1522 - note_loss: 1.4069 - vel_loss: 0.0173 - time_loss: 2.3794e-04 - onoff_accuracy: 0.9398 - note_accuracy: 0.6052 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1555\n",
            "Epoch 467/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.7849 - onoff_loss: 0.0974 - note_loss: 1.3860 - vel_loss: 0.0178 - time_loss: 2.8379e-04 - onoff_accuracy: 0.9674 - note_accuracy: 0.6073 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1800\n",
            "Epoch 468/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.8256 - onoff_loss: 0.1032 - note_loss: 1.4448 - vel_loss: 0.0181 - time_loss: 2.5959e-04 - onoff_accuracy: 0.9636 - note_accuracy: 0.5794 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1901\n",
            "Epoch 469/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.7345 - onoff_loss: 0.1035 - note_loss: 1.3124 - vel_loss: 0.0183 - time_loss: 3.0035e-04 - onoff_accuracy: 0.9633 - note_accuracy: 0.6240 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 470/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.7915 - onoff_loss: 0.1289 - note_loss: 1.4201 - vel_loss: 0.0175 - time_loss: 2.2501e-04 - onoff_accuracy: 0.9495 - note_accuracy: 0.5969 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 471/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.6752 - onoff_loss: 0.1102 - note_loss: 1.3025 - vel_loss: 0.0177 - time_loss: 2.4478e-04 - onoff_accuracy: 0.9604 - note_accuracy: 0.6370 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1538\n",
            "Epoch 472/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.8153 - onoff_loss: 0.1082 - note_loss: 1.4476 - vel_loss: 0.0172 - time_loss: 2.4236e-04 - onoff_accuracy: 0.9601 - note_accuracy: 0.5809 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 473/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.7035 - onoff_loss: 0.0898 - note_loss: 1.2792 - vel_loss: 0.0181 - time_loss: 3.1652e-04 - onoff_accuracy: 0.9711 - note_accuracy: 0.6395 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1810\n",
            "Epoch 474/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.8257 - onoff_loss: 0.1697 - note_loss: 1.3851 - vel_loss: 0.0181 - time_loss: 2.5278e-04 - onoff_accuracy: 0.9299 - note_accuracy: 0.6032 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 475/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.6910 - onoff_loss: 0.0911 - note_loss: 1.3056 - vel_loss: 0.0172 - time_loss: 2.7707e-04 - onoff_accuracy: 0.9685 - note_accuracy: 0.6285 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1884\n",
            "Epoch 476/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.6827 - onoff_loss: 0.1037 - note_loss: 1.3110 - vel_loss: 0.0174 - time_loss: 2.5066e-04 - onoff_accuracy: 0.9635 - note_accuracy: 0.6285 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1793\n",
            "Epoch 477/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.7915 - onoff_loss: 0.1023 - note_loss: 1.3560 - vel_loss: 0.0176 - time_loss: 3.1566e-04 - onoff_accuracy: 0.9648 - note_accuracy: 0.6124 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1718\n",
            "Epoch 478/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.6801 - onoff_loss: 0.1096 - note_loss: 1.3170 - vel_loss: 0.0178 - time_loss: 2.3576e-04 - onoff_accuracy: 0.9614 - note_accuracy: 0.6235 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1568\n",
            "Epoch 479/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.7253 - onoff_loss: 0.1163 - note_loss: 1.3086 - vel_loss: 0.0179 - time_loss: 2.8249e-04 - onoff_accuracy: 0.9561 - note_accuracy: 0.6266 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 480/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.6186 - onoff_loss: 0.1235 - note_loss: 1.2678 - vel_loss: 0.0175 - time_loss: 2.0984e-04 - onoff_accuracy: 0.9548 - note_accuracy: 0.6387 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1687\n",
            "Epoch 481/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.6726 - onoff_loss: 0.1003 - note_loss: 1.2756 - vel_loss: 0.0183 - time_loss: 2.7847e-04 - onoff_accuracy: 0.9634 - note_accuracy: 0.6375 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 482/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.6972 - onoff_loss: 0.0973 - note_loss: 1.3128 - vel_loss: 0.0180 - time_loss: 2.6907e-04 - onoff_accuracy: 0.9654 - note_accuracy: 0.6223 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1642\n",
            "Epoch 483/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.5990 - onoff_loss: 0.0895 - note_loss: 1.2079 - vel_loss: 0.0177 - time_loss: 2.8393e-04 - onoff_accuracy: 0.9707 - note_accuracy: 0.6603 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 484/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 1.6158 - onoff_loss: 0.0995 - note_loss: 1.3013 - vel_loss: 0.0168 - time_loss: 1.9817e-04 - onoff_accuracy: 0.9642 - note_accuracy: 0.6320 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1758\n",
            "Epoch 485/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.6871 - onoff_loss: 0.0964 - note_loss: 1.2890 - vel_loss: 0.0178 - time_loss: 2.8382e-04 - onoff_accuracy: 0.9656 - note_accuracy: 0.6321 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1802\n",
            "Epoch 486/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.5763 - onoff_loss: 0.1011 - note_loss: 1.1665 - vel_loss: 0.0190 - time_loss: 2.8968e-04 - onoff_accuracy: 0.9636 - note_accuracy: 0.6766 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1980\n",
            "Epoch 487/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 1.6588 - onoff_loss: 0.1343 - note_loss: 1.1944 - vel_loss: 0.0178 - time_loss: 3.1241e-04 - onoff_accuracy: 0.9487 - note_accuracy: 0.6709 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 488/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.4800 - onoff_loss: 0.0871 - note_loss: 1.1151 - vel_loss: 0.0182 - time_loss: 2.5962e-04 - onoff_accuracy: 0.9698 - note_accuracy: 0.6950 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1789\n",
            "Epoch 489/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.5116 - onoff_loss: 0.1022 - note_loss: 1.1613 - vel_loss: 0.0183 - time_loss: 2.2982e-04 - onoff_accuracy: 0.9632 - note_accuracy: 0.6800 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1782\n",
            "Epoch 490/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.5009 - onoff_loss: 0.0792 - note_loss: 1.1689 - vel_loss: 0.0176 - time_loss: 2.3518e-04 - onoff_accuracy: 0.9735 - note_accuracy: 0.6711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1691\n",
            "Epoch 491/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.6142 - onoff_loss: 0.0888 - note_loss: 1.2893 - vel_loss: 0.0170 - time_loss: 2.1911e-04 - onoff_accuracy: 0.9692 - note_accuracy: 0.6308 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1704\n",
            "Epoch 492/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.4700 - onoff_loss: 0.0922 - note_loss: 1.1011 - vel_loss: 0.0180 - time_loss: 2.5867e-04 - onoff_accuracy: 0.9662 - note_accuracy: 0.6916 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1678\n",
            "Epoch 493/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.5445 - onoff_loss: 0.0897 - note_loss: 1.1791 - vel_loss: 0.0180 - time_loss: 2.5775e-04 - onoff_accuracy: 0.9689 - note_accuracy: 0.6700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 494/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.4667 - onoff_loss: 0.1075 - note_loss: 1.1285 - vel_loss: 0.0170 - time_loss: 2.1372e-04 - onoff_accuracy: 0.9593 - note_accuracy: 0.6859 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 495/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.4807 - onoff_loss: 0.0915 - note_loss: 1.1415 - vel_loss: 0.0171 - time_loss: 2.3063e-04 - onoff_accuracy: 0.9673 - note_accuracy: 0.6742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 496/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.4579 - onoff_loss: 0.0818 - note_loss: 1.1318 - vel_loss: 0.0169 - time_loss: 2.2734e-04 - onoff_accuracy: 0.9719 - note_accuracy: 0.6789 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1799\n",
            "Epoch 497/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.4975 - onoff_loss: 0.1101 - note_loss: 1.1462 - vel_loss: 0.0170 - time_loss: 2.2428e-04 - onoff_accuracy: 0.9555 - note_accuracy: 0.6799 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 498/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.5548 - onoff_loss: 0.0946 - note_loss: 1.1774 - vel_loss: 0.0174 - time_loss: 2.6540e-04 - onoff_accuracy: 0.9659 - note_accuracy: 0.6708 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 499/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.5124 - onoff_loss: 0.1015 - note_loss: 1.1459 - vel_loss: 0.0165 - time_loss: 2.4843e-04 - onoff_accuracy: 0.9634 - note_accuracy: 0.6761 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1481\n",
            "Epoch 500/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.4476 - onoff_loss: 0.0808 - note_loss: 1.1093 - vel_loss: 0.0168 - time_loss: 2.4070e-04 - onoff_accuracy: 0.9726 - note_accuracy: 0.6899 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1707\n",
            "Epoch 501/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.4447 - onoff_loss: 0.0951 - note_loss: 1.1069 - vel_loss: 0.0176 - time_loss: 2.2506e-04 - onoff_accuracy: 0.9653 - note_accuracy: 0.6932 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1773\n",
            "Epoch 502/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.4462 - onoff_loss: 0.0870 - note_loss: 1.0387 - vel_loss: 0.0191 - time_loss: 3.0149e-04 - onoff_accuracy: 0.9702 - note_accuracy: 0.7131 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1809\n",
            "Epoch 503/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.3639 - onoff_loss: 0.0796 - note_loss: 1.0579 - vel_loss: 0.0182 - time_loss: 2.0823e-04 - onoff_accuracy: 0.9721 - note_accuracy: 0.7062 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1726\n",
            "Epoch 504/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.3454 - onoff_loss: 0.0729 - note_loss: 1.0020 - vel_loss: 0.0186 - time_loss: 2.5178e-04 - onoff_accuracy: 0.9750 - note_accuracy: 0.7309 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1859\n",
            "Epoch 505/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.2743 - onoff_loss: 0.0727 - note_loss: 0.9816 - vel_loss: 0.0168 - time_loss: 2.0322e-04 - onoff_accuracy: 0.9756 - note_accuracy: 0.7297 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2026\n",
            "Epoch 506/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.3702 - onoff_loss: 0.0799 - note_loss: 1.0413 - vel_loss: 0.0178 - time_loss: 2.3115e-04 - onoff_accuracy: 0.9734 - note_accuracy: 0.7117 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1755\n",
            "Epoch 507/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.3770 - onoff_loss: 0.0955 - note_loss: 1.0316 - vel_loss: 0.0170 - time_loss: 2.3284e-04 - onoff_accuracy: 0.9646 - note_accuracy: 0.7163 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1799\n",
            "Epoch 508/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.4152 - onoff_loss: 0.0836 - note_loss: 1.1119 - vel_loss: 0.0171 - time_loss: 2.0256e-04 - onoff_accuracy: 0.9703 - note_accuracy: 0.6944 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1780\n",
            "Epoch 509/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 1.3827 - onoff_loss: 0.0864 - note_loss: 0.9697 - vel_loss: 0.0168 - time_loss: 3.0980e-04 - onoff_accuracy: 0.9682 - note_accuracy: 0.7356 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 510/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.4636 - onoff_loss: 0.1162 - note_loss: 1.0719 - vel_loss: 0.0174 - time_loss: 2.5799e-04 - onoff_accuracy: 0.9555 - note_accuracy: 0.6977 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1587\n",
            "Epoch 511/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.1744 - onoff_loss: 0.0712 - note_loss: 0.8775 - vel_loss: 0.0174 - time_loss: 2.0833e-04 - onoff_accuracy: 0.9768 - note_accuracy: 0.7683 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 512/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.2808 - onoff_loss: 0.0908 - note_loss: 0.9610 - vel_loss: 0.0174 - time_loss: 2.1158e-04 - onoff_accuracy: 0.9670 - note_accuracy: 0.7370 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 513/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.3146 - onoff_loss: 0.0793 - note_loss: 0.9756 - vel_loss: 0.0171 - time_loss: 2.4251e-04 - onoff_accuracy: 0.9729 - note_accuracy: 0.7310 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 514/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.3401 - onoff_loss: 0.0708 - note_loss: 0.9956 - vel_loss: 0.0173 - time_loss: 2.5643e-04 - onoff_accuracy: 0.9764 - note_accuracy: 0.7263 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1800\n",
            "Epoch 515/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.2112 - onoff_loss: 0.0704 - note_loss: 0.8961 - vel_loss: 0.0169 - time_loss: 2.2779e-04 - onoff_accuracy: 0.9780 - note_accuracy: 0.7609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1651\n",
            "Epoch 516/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.3076 - onoff_loss: 0.0992 - note_loss: 0.9889 - vel_loss: 0.0172 - time_loss: 2.0224e-04 - onoff_accuracy: 0.9625 - note_accuracy: 0.7273 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1798\n",
            "Epoch 517/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.3266 - onoff_loss: 0.0798 - note_loss: 0.9794 - vel_loss: 0.0179 - time_loss: 2.4957e-04 - onoff_accuracy: 0.9725 - note_accuracy: 0.7302 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1691\n",
            "Epoch 518/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.2326 - onoff_loss: 0.0702 - note_loss: 0.9269 - vel_loss: 0.0166 - time_loss: 2.1898e-04 - onoff_accuracy: 0.9771 - note_accuracy: 0.7479 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1576\n",
            "Epoch 519/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.3475 - onoff_loss: 0.0807 - note_loss: 0.9740 - vel_loss: 0.0180 - time_loss: 2.7476e-04 - onoff_accuracy: 0.9725 - note_accuracy: 0.7325 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1805\n",
            "Epoch 520/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.2580 - onoff_loss: 0.0866 - note_loss: 0.8941 - vel_loss: 0.0167 - time_loss: 2.6059e-04 - onoff_accuracy: 0.9690 - note_accuracy: 0.7630 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1614\n",
            "Epoch 521/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.2477 - onoff_loss: 0.0709 - note_loss: 0.9407 - vel_loss: 0.0185 - time_loss: 2.1764e-04 - onoff_accuracy: 0.9766 - note_accuracy: 0.7429 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1995\n",
            "Epoch 522/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.3068 - onoff_loss: 0.0780 - note_loss: 0.9137 - vel_loss: 0.0174 - time_loss: 2.9776e-04 - onoff_accuracy: 0.9729 - note_accuracy: 0.7519 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 523/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.2130 - onoff_loss: 0.1054 - note_loss: 0.8811 - vel_loss: 0.0168 - time_loss: 2.0966e-04 - onoff_accuracy: 0.9597 - note_accuracy: 0.7631 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 524/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.1723 - onoff_loss: 0.0636 - note_loss: 0.8395 - vel_loss: 0.0174 - time_loss: 2.5186e-04 - onoff_accuracy: 0.9785 - note_accuracy: 0.7759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 525/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 1.1496 - onoff_loss: 0.0679 - note_loss: 0.8527 - vel_loss: 0.0180 - time_loss: 2.1094e-04 - onoff_accuracy: 0.9762 - note_accuracy: 0.7710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1830\n",
            "Epoch 526/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.2023 - onoff_loss: 0.0687 - note_loss: 0.8473 - vel_loss: 0.0172 - time_loss: 2.6909e-04 - onoff_accuracy: 0.9763 - note_accuracy: 0.7780 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1642\n",
            "Epoch 527/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.1526 - onoff_loss: 0.0752 - note_loss: 0.8534 - vel_loss: 0.0164 - time_loss: 2.0760e-04 - onoff_accuracy: 0.9735 - note_accuracy: 0.7737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1742\n",
            "Epoch 528/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.1717 - onoff_loss: 0.0727 - note_loss: 0.8646 - vel_loss: 0.0171 - time_loss: 2.1729e-04 - onoff_accuracy: 0.9754 - note_accuracy: 0.7716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1729\n",
            "Epoch 529/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.1666 - onoff_loss: 0.0832 - note_loss: 0.8312 - vel_loss: 0.0178 - time_loss: 2.3441e-04 - onoff_accuracy: 0.9712 - note_accuracy: 0.7878 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1806\n",
            "Epoch 530/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.0217 - onoff_loss: 0.0599 - note_loss: 0.7481 - vel_loss: 0.0169 - time_loss: 1.9683e-04 - onoff_accuracy: 0.9801 - note_accuracy: 0.8072 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 531/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.2302 - onoff_loss: 0.0840 - note_loss: 0.8991 - vel_loss: 0.0172 - time_loss: 2.2984e-04 - onoff_accuracy: 0.9701 - note_accuracy: 0.7566 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 532/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.1648 - onoff_loss: 0.0679 - note_loss: 0.8081 - vel_loss: 0.0171 - time_loss: 2.7173e-04 - onoff_accuracy: 0.9781 - note_accuracy: 0.7891 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 533/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.2502 - onoff_loss: 0.0874 - note_loss: 0.9243 - vel_loss: 0.0170 - time_loss: 2.2146e-04 - onoff_accuracy: 0.9689 - note_accuracy: 0.7458 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1611\n",
            "Epoch 534/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.0643 - onoff_loss: 0.0606 - note_loss: 0.7703 - vel_loss: 0.0176 - time_loss: 2.1572e-04 - onoff_accuracy: 0.9804 - note_accuracy: 0.8024 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1801\n",
            "Epoch 535/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.1638 - onoff_loss: 0.0766 - note_loss: 0.8139 - vel_loss: 0.0170 - time_loss: 2.5646e-04 - onoff_accuracy: 0.9720 - note_accuracy: 0.7802 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 536/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.1112 - onoff_loss: 0.0606 - note_loss: 0.7615 - vel_loss: 0.0165 - time_loss: 2.7250e-04 - onoff_accuracy: 0.9802 - note_accuracy: 0.8034 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 537/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.1290 - onoff_loss: 0.0702 - note_loss: 0.8596 - vel_loss: 0.0170 - time_loss: 1.8227e-04 - onoff_accuracy: 0.9749 - note_accuracy: 0.7687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 538/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.0752 - onoff_loss: 0.0595 - note_loss: 0.7609 - vel_loss: 0.0171 - time_loss: 2.3771e-04 - onoff_accuracy: 0.9804 - note_accuracy: 0.8015 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1689\n",
            "Epoch 539/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.0875 - onoff_loss: 0.0669 - note_loss: 0.7439 - vel_loss: 0.0176 - time_loss: 2.5905e-04 - onoff_accuracy: 0.9767 - note_accuracy: 0.8058 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 540/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 1.0489 - onoff_loss: 0.0637 - note_loss: 0.7611 - vel_loss: 0.0171 - time_loss: 2.0703e-04 - onoff_accuracy: 0.9785 - note_accuracy: 0.8071 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 541/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.0740 - onoff_loss: 0.0936 - note_loss: 0.7586 - vel_loss: 0.0176 - time_loss: 2.0408e-04 - onoff_accuracy: 0.9637 - note_accuracy: 0.7962 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1848\n",
            "Epoch 542/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.1844 - onoff_loss: 0.0735 - note_loss: 0.8208 - vel_loss: 0.0170 - time_loss: 2.7307e-04 - onoff_accuracy: 0.9741 - note_accuracy: 0.7789 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 543/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.9914 - onoff_loss: 0.0621 - note_loss: 0.7041 - vel_loss: 0.0172 - time_loss: 2.0798e-04 - onoff_accuracy: 0.9795 - note_accuracy: 0.8228 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 544/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.0447 - onoff_loss: 0.0666 - note_loss: 0.7382 - vel_loss: 0.0184 - time_loss: 2.2156e-04 - onoff_accuracy: 0.9772 - note_accuracy: 0.8121 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1881\n",
            "Epoch 545/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 1.0481 - onoff_loss: 0.0675 - note_loss: 0.7393 - vel_loss: 0.0162 - time_loss: 2.2505e-04 - onoff_accuracy: 0.9762 - note_accuracy: 0.8111 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1624\n",
            "Epoch 546/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 1.0062 - onoff_loss: 0.0645 - note_loss: 0.7136 - vel_loss: 0.0174 - time_loss: 2.1070e-04 - onoff_accuracy: 0.9782 - note_accuracy: 0.8172 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1878\n",
            "Epoch 547/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 1.0305 - onoff_loss: 0.0655 - note_loss: 0.7435 - vel_loss: 0.0179 - time_loss: 2.0355e-04 - onoff_accuracy: 0.9777 - note_accuracy: 0.8065 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1866\n",
            "Epoch 548/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.9606 - onoff_loss: 0.0609 - note_loss: 0.6936 - vel_loss: 0.0174 - time_loss: 1.8862e-04 - onoff_accuracy: 0.9790 - note_accuracy: 0.8237 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1877\n",
            "Epoch 549/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.0449 - onoff_loss: 0.0650 - note_loss: 0.7419 - vel_loss: 0.0174 - time_loss: 2.2054e-04 - onoff_accuracy: 0.9772 - note_accuracy: 0.8063 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1986\n",
            "Epoch 550/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 1.0191 - onoff_loss: 0.0627 - note_loss: 0.7131 - vel_loss: 0.0174 - time_loss: 2.2584e-04 - onoff_accuracy: 0.9794 - note_accuracy: 0.8223 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 551/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.9859 - onoff_loss: 0.0627 - note_loss: 0.7200 - vel_loss: 0.0174 - time_loss: 1.8573e-04 - onoff_accuracy: 0.9786 - note_accuracy: 0.8129 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 552/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.9552 - onoff_loss: 0.0593 - note_loss: 0.6258 - vel_loss: 0.0177 - time_loss: 2.5249e-04 - onoff_accuracy: 0.9799 - note_accuracy: 0.8502 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1624\n",
            "Epoch 553/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.8804 - onoff_loss: 0.0619 - note_loss: 0.6236 - vel_loss: 0.0175 - time_loss: 1.7745e-04 - onoff_accuracy: 0.9783 - note_accuracy: 0.8472 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 554/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.9537 - onoff_loss: 0.0649 - note_loss: 0.6289 - vel_loss: 0.0165 - time_loss: 2.4336e-04 - onoff_accuracy: 0.9771 - note_accuracy: 0.8468 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1644\n",
            "Epoch 555/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9300 - onoff_loss: 0.0540 - note_loss: 0.6645 - vel_loss: 0.0169 - time_loss: 1.9454e-04 - onoff_accuracy: 0.9817 - note_accuracy: 0.8329 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 556/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9573 - onoff_loss: 0.0589 - note_loss: 0.6717 - vel_loss: 0.0182 - time_loss: 2.0852e-04 - onoff_accuracy: 0.9807 - note_accuracy: 0.8304 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1786\n",
            "Epoch 557/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9010 - onoff_loss: 0.0646 - note_loss: 0.5948 - vel_loss: 0.0167 - time_loss: 2.2497e-04 - onoff_accuracy: 0.9775 - note_accuracy: 0.8572 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1674\n",
            "Epoch 558/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9007 - onoff_loss: 0.0623 - note_loss: 0.6222 - vel_loss: 0.0167 - time_loss: 1.9955e-04 - onoff_accuracy: 0.9779 - note_accuracy: 0.8460 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1673\n",
            "Epoch 559/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.9781 - onoff_loss: 0.0630 - note_loss: 0.6834 - vel_loss: 0.0166 - time_loss: 2.1516e-04 - onoff_accuracy: 0.9771 - note_accuracy: 0.8223 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1824\n",
            "Epoch 560/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.9302 - onoff_loss: 0.0579 - note_loss: 0.6291 - vel_loss: 0.0177 - time_loss: 2.2556e-04 - onoff_accuracy: 0.9804 - note_accuracy: 0.8456 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1930\n",
            "Epoch 561/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.9347 - onoff_loss: 0.0553 - note_loss: 0.6165 - vel_loss: 0.0159 - time_loss: 2.4698e-04 - onoff_accuracy: 0.9814 - note_accuracy: 0.8486 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1596\n",
            "Epoch 562/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.8608 - onoff_loss: 0.0520 - note_loss: 0.5943 - vel_loss: 0.0164 - time_loss: 1.9817e-04 - onoff_accuracy: 0.9817 - note_accuracy: 0.8499 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1718\n",
            "Epoch 563/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.8835 - onoff_loss: 0.0617 - note_loss: 0.6164 - vel_loss: 0.0168 - time_loss: 1.8850e-04 - onoff_accuracy: 0.9788 - note_accuracy: 0.8467 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1861\n",
            "Epoch 564/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 1.0712 - onoff_loss: 0.1026 - note_loss: 0.6511 - vel_loss: 0.0172 - time_loss: 3.0030e-04 - onoff_accuracy: 0.9622 - note_accuracy: 0.8347 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1662\n",
            "Epoch 565/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.8113 - onoff_loss: 0.0493 - note_loss: 0.5627 - vel_loss: 0.0171 - time_loss: 1.8221e-04 - onoff_accuracy: 0.9837 - note_accuracy: 0.8647 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 566/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.9487 - onoff_loss: 0.0664 - note_loss: 0.6819 - vel_loss: 0.0168 - time_loss: 1.8362e-04 - onoff_accuracy: 0.9754 - note_accuracy: 0.8257 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 567/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9303 - onoff_loss: 0.0553 - note_loss: 0.6102 - vel_loss: 0.0172 - time_loss: 2.4749e-04 - onoff_accuracy: 0.9806 - note_accuracy: 0.8522 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 568/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.8398 - onoff_loss: 0.0593 - note_loss: 0.5736 - vel_loss: 0.0172 - time_loss: 1.8973e-04 - onoff_accuracy: 0.9800 - note_accuracy: 0.8609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1686\n",
            "Epoch 569/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 1.0344 - onoff_loss: 0.0580 - note_loss: 0.6369 - vel_loss: 0.0183 - time_loss: 3.2119e-04 - onoff_accuracy: 0.9795 - note_accuracy: 0.8448 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 570/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.9174 - onoff_loss: 0.0721 - note_loss: 0.6089 - vel_loss: 0.0183 - time_loss: 2.1819e-04 - onoff_accuracy: 0.9752 - note_accuracy: 0.8506 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 571/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.8727 - onoff_loss: 0.0580 - note_loss: 0.5385 - vel_loss: 0.0170 - time_loss: 2.5913e-04 - onoff_accuracy: 0.9800 - note_accuracy: 0.8758 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1687\n",
            "Epoch 572/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9144 - onoff_loss: 0.0560 - note_loss: 0.6401 - vel_loss: 0.0181 - time_loss: 2.0014e-04 - onoff_accuracy: 0.9804 - note_accuracy: 0.8351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1880\n",
            "Epoch 573/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7919 - onoff_loss: 0.0485 - note_loss: 0.5247 - vel_loss: 0.0178 - time_loss: 2.0090e-04 - onoff_accuracy: 0.9837 - note_accuracy: 0.8795 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 574/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.9575 - onoff_loss: 0.0606 - note_loss: 0.6376 - vel_loss: 0.0167 - time_loss: 2.4252e-04 - onoff_accuracy: 0.9790 - note_accuracy: 0.8413 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1591\n",
            "Epoch 575/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.7259 - onoff_loss: 0.0522 - note_loss: 0.4733 - vel_loss: 0.0163 - time_loss: 1.8399e-04 - onoff_accuracy: 0.9812 - note_accuracy: 0.8932 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1546\n",
            "Epoch 576/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.8776 - onoff_loss: 0.0520 - note_loss: 0.5786 - vel_loss: 0.0170 - time_loss: 2.3008e-04 - onoff_accuracy: 0.9814 - note_accuracy: 0.8572 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1644\n",
            "Epoch 577/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.9080 - onoff_loss: 0.0817 - note_loss: 0.6125 - vel_loss: 0.0185 - time_loss: 1.9539e-04 - onoff_accuracy: 0.9698 - note_accuracy: 0.8458 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1935\n",
            "Epoch 578/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.8027 - onoff_loss: 0.0453 - note_loss: 0.4935 - vel_loss: 0.0163 - time_loss: 2.4746e-04 - onoff_accuracy: 0.9848 - note_accuracy: 0.8879 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1491\n",
            "Epoch 579/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.8404 - onoff_loss: 0.0587 - note_loss: 0.5629 - vel_loss: 0.0173 - time_loss: 2.0155e-04 - onoff_accuracy: 0.9789 - note_accuracy: 0.8622 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1761\n",
            "Epoch 580/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.9167 - onoff_loss: 0.0808 - note_loss: 0.5953 - vel_loss: 0.0166 - time_loss: 2.2397e-04 - onoff_accuracy: 0.9673 - note_accuracy: 0.8514 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 581/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.8314 - onoff_loss: 0.0559 - note_loss: 0.5447 - vel_loss: 0.0176 - time_loss: 2.1317e-04 - onoff_accuracy: 0.9810 - note_accuracy: 0.8704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 582/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7977 - onoff_loss: 0.0473 - note_loss: 0.5263 - vel_loss: 0.0169 - time_loss: 2.0728e-04 - onoff_accuracy: 0.9837 - note_accuracy: 0.8735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1811\n",
            "Epoch 583/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7950 - onoff_loss: 0.0487 - note_loss: 0.5385 - vel_loss: 0.0168 - time_loss: 1.9101e-04 - onoff_accuracy: 0.9832 - note_accuracy: 0.8735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1691\n",
            "Epoch 584/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.8170 - onoff_loss: 0.0553 - note_loss: 0.5205 - vel_loss: 0.0172 - time_loss: 2.2389e-04 - onoff_accuracy: 0.9802 - note_accuracy: 0.8726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 585/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7380 - onoff_loss: 0.0483 - note_loss: 0.4546 - vel_loss: 0.0168 - time_loss: 2.1835e-04 - onoff_accuracy: 0.9839 - note_accuracy: 0.9002 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 586/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.8775 - onoff_loss: 0.0576 - note_loss: 0.5944 - vel_loss: 0.0177 - time_loss: 2.0780e-04 - onoff_accuracy: 0.9790 - note_accuracy: 0.8503 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1668\n",
            "Epoch 587/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.8299 - onoff_loss: 0.0523 - note_loss: 0.5558 - vel_loss: 0.0177 - time_loss: 2.0415e-04 - onoff_accuracy: 0.9815 - note_accuracy: 0.8658 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 588/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.7526 - onoff_loss: 0.0660 - note_loss: 0.5058 - vel_loss: 0.0170 - time_loss: 1.6372e-04 - onoff_accuracy: 0.9753 - note_accuracy: 0.8811 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1686\n",
            "Epoch 589/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7544 - onoff_loss: 0.0454 - note_loss: 0.4507 - vel_loss: 0.0166 - time_loss: 2.4165e-04 - onoff_accuracy: 0.9847 - note_accuracy: 0.9005 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1717\n",
            "Epoch 590/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.7773 - onoff_loss: 0.0511 - note_loss: 0.5147 - vel_loss: 0.0174 - time_loss: 1.9414e-04 - onoff_accuracy: 0.9817 - note_accuracy: 0.8785 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1858\n",
            "Epoch 591/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7789 - onoff_loss: 0.0560 - note_loss: 0.4974 - vel_loss: 0.0167 - time_loss: 2.0880e-04 - onoff_accuracy: 0.9804 - note_accuracy: 0.8868 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1718\n",
            "Epoch 592/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7426 - onoff_loss: 0.0700 - note_loss: 0.4568 - vel_loss: 0.0163 - time_loss: 1.9948e-04 - onoff_accuracy: 0.9742 - note_accuracy: 0.8965 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1548\n",
            "Epoch 593/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7718 - onoff_loss: 0.0533 - note_loss: 0.4981 - vel_loss: 0.0178 - time_loss: 2.0254e-04 - onoff_accuracy: 0.9809 - note_accuracy: 0.8850 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1887\n",
            "Epoch 594/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7709 - onoff_loss: 0.0552 - note_loss: 0.4940 - vel_loss: 0.0179 - time_loss: 2.0389e-04 - onoff_accuracy: 0.9803 - note_accuracy: 0.8840 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1877\n",
            "Epoch 595/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7816 - onoff_loss: 0.0490 - note_loss: 0.5215 - vel_loss: 0.0167 - time_loss: 1.9445e-04 - onoff_accuracy: 0.9823 - note_accuracy: 0.8714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 596/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.6955 - onoff_loss: 0.0468 - note_loss: 0.4265 - vel_loss: 0.0174 - time_loss: 2.0476e-04 - onoff_accuracy: 0.9836 - note_accuracy: 0.9061 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 597/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.8398 - onoff_loss: 0.0768 - note_loss: 0.5054 - vel_loss: 0.0167 - time_loss: 2.4090e-04 - onoff_accuracy: 0.9710 - note_accuracy: 0.8788 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 598/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.6324 - onoff_loss: 0.0420 - note_loss: 0.3944 - vel_loss: 0.0171 - time_loss: 1.7888e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9168 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1942\n",
            "Epoch 599/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7388 - onoff_loss: 0.0455 - note_loss: 0.4760 - vel_loss: 0.0167 - time_loss: 2.0071e-04 - onoff_accuracy: 0.9837 - note_accuracy: 0.8850 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 600/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7226 - onoff_loss: 0.0501 - note_loss: 0.4491 - vel_loss: 0.0180 - time_loss: 2.0547e-04 - onoff_accuracy: 0.9822 - note_accuracy: 0.8979 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1937\n",
            "Epoch 601/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7640 - onoff_loss: 0.0791 - note_loss: 0.4730 - vel_loss: 0.0172 - time_loss: 1.9466e-04 - onoff_accuracy: 0.9710 - note_accuracy: 0.8909 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1795\n",
            "Epoch 602/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6971 - onoff_loss: 0.0476 - note_loss: 0.4168 - vel_loss: 0.0166 - time_loss: 2.1606e-04 - onoff_accuracy: 0.9829 - note_accuracy: 0.9097 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1659\n",
            "Epoch 603/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7046 - onoff_loss: 0.0467 - note_loss: 0.4801 - vel_loss: 0.0166 - time_loss: 1.6128e-04 - onoff_accuracy: 0.9844 - note_accuracy: 0.8874 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1556\n",
            "Epoch 604/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7638 - onoff_loss: 0.0452 - note_loss: 0.4130 - vel_loss: 0.0176 - time_loss: 2.8801e-04 - onoff_accuracy: 0.9837 - note_accuracy: 0.9091 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1673\n",
            "Epoch 605/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7412 - onoff_loss: 0.0505 - note_loss: 0.4896 - vel_loss: 0.0181 - time_loss: 1.8305e-04 - onoff_accuracy: 0.9815 - note_accuracy: 0.8821 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 606/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.7390 - onoff_loss: 0.0517 - note_loss: 0.4573 - vel_loss: 0.0177 - time_loss: 2.1226e-04 - onoff_accuracy: 0.9813 - note_accuracy: 0.8926 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1878\n",
            "Epoch 607/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6719 - onoff_loss: 0.0601 - note_loss: 0.4094 - vel_loss: 0.0165 - time_loss: 1.8596e-04 - onoff_accuracy: 0.9771 - note_accuracy: 0.9096 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1788\n",
            "Epoch 608/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.6845 - onoff_loss: 0.0486 - note_loss: 0.4357 - vel_loss: 0.0171 - time_loss: 1.8305e-04 - onoff_accuracy: 0.9821 - note_accuracy: 0.9018 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 609/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6854 - onoff_loss: 0.0473 - note_loss: 0.4352 - vel_loss: 0.0168 - time_loss: 1.8617e-04 - onoff_accuracy: 0.9831 - note_accuracy: 0.8999 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1580\n",
            "Epoch 610/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6504 - onoff_loss: 0.0434 - note_loss: 0.3864 - vel_loss: 0.0178 - time_loss: 2.0289e-04 - onoff_accuracy: 0.9849 - note_accuracy: 0.9173 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1501\n",
            "Epoch 611/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6141 - onoff_loss: 0.0419 - note_loss: 0.3873 - vel_loss: 0.0164 - time_loss: 1.6853e-04 - onoff_accuracy: 0.9844 - note_accuracy: 0.9156 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 612/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7597 - onoff_loss: 0.0490 - note_loss: 0.4953 - vel_loss: 0.0166 - time_loss: 1.9874e-04 - onoff_accuracy: 0.9829 - note_accuracy: 0.8768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 613/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.6255 - onoff_loss: 0.0427 - note_loss: 0.3627 - vel_loss: 0.0169 - time_loss: 2.0317e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9212 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1880\n",
            "Epoch 614/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6839 - onoff_loss: 0.0478 - note_loss: 0.4421 - vel_loss: 0.0170 - time_loss: 1.7701e-04 - onoff_accuracy: 0.9830 - note_accuracy: 0.8961 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 615/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7784 - onoff_loss: 0.0543 - note_loss: 0.4901 - vel_loss: 0.0171 - time_loss: 2.1697e-04 - onoff_accuracy: 0.9806 - note_accuracy: 0.8763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1548\n",
            "Epoch 616/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6513 - onoff_loss: 0.0420 - note_loss: 0.3747 - vel_loss: 0.0166 - time_loss: 2.1792e-04 - onoff_accuracy: 0.9849 - note_accuracy: 0.9227 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1955\n",
            "Epoch 617/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.6045 - onoff_loss: 0.0443 - note_loss: 0.3822 - vel_loss: 0.0173 - time_loss: 1.6063e-04 - onoff_accuracy: 0.9838 - note_accuracy: 0.9123 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1861\n",
            "Epoch 618/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6464 - onoff_loss: 0.0509 - note_loss: 0.3805 - vel_loss: 0.0165 - time_loss: 1.9852e-04 - onoff_accuracy: 0.9815 - note_accuracy: 0.9170 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1573\n",
            "Epoch 619/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6256 - onoff_loss: 0.0394 - note_loss: 0.3680 - vel_loss: 0.0179 - time_loss: 2.0032e-04 - onoff_accuracy: 0.9859 - note_accuracy: 0.9216 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1811\n",
            "Epoch 620/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7277 - onoff_loss: 0.0573 - note_loss: 0.4688 - vel_loss: 0.0159 - time_loss: 1.8562e-04 - onoff_accuracy: 0.9790 - note_accuracy: 0.8869 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 621/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6170 - onoff_loss: 0.0408 - note_loss: 0.3505 - vel_loss: 0.0167 - time_loss: 2.0899e-04 - onoff_accuracy: 0.9855 - note_accuracy: 0.9287 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1742\n",
            "Epoch 622/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6245 - onoff_loss: 0.0460 - note_loss: 0.3621 - vel_loss: 0.0163 - time_loss: 2.0004e-04 - onoff_accuracy: 0.9828 - note_accuracy: 0.9207 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1642\n",
            "Epoch 623/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6448 - onoff_loss: 0.0531 - note_loss: 0.3809 - vel_loss: 0.0170 - time_loss: 1.9370e-04 - onoff_accuracy: 0.9798 - note_accuracy: 0.9159 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1673\n",
            "Epoch 624/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6374 - onoff_loss: 0.0419 - note_loss: 0.3611 - vel_loss: 0.0165 - time_loss: 2.1795e-04 - onoff_accuracy: 0.9851 - note_accuracy: 0.9234 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1478\n",
            "Epoch 625/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6175 - onoff_loss: 0.0411 - note_loss: 0.3854 - vel_loss: 0.0164 - time_loss: 1.7466e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9125 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1766\n",
            "Epoch 626/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6450 - onoff_loss: 0.0423 - note_loss: 0.3661 - vel_loss: 0.0166 - time_loss: 2.2000e-04 - onoff_accuracy: 0.9846 - note_accuracy: 0.9194 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 627/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.8976 - onoff_loss: 0.0708 - note_loss: 0.6192 - vel_loss: 0.0170 - time_loss: 1.9065e-04 - onoff_accuracy: 0.9743 - note_accuracy: 0.8524 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1740\n",
            "Epoch 628/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5852 - onoff_loss: 0.0395 - note_loss: 0.3272 - vel_loss: 0.0169 - time_loss: 2.0171e-04 - onoff_accuracy: 0.9854 - note_accuracy: 0.9327 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1882\n",
            "Epoch 629/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6613 - onoff_loss: 0.0455 - note_loss: 0.3829 - vel_loss: 0.0155 - time_loss: 2.1729e-04 - onoff_accuracy: 0.9835 - note_accuracy: 0.9140 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 630/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6129 - onoff_loss: 0.0415 - note_loss: 0.3519 - vel_loss: 0.0175 - time_loss: 2.0203e-04 - onoff_accuracy: 0.9845 - note_accuracy: 0.9235 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1726\n",
            "Epoch 631/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.7273 - onoff_loss: 0.0495 - note_loss: 0.4710 - vel_loss: 0.0168 - time_loss: 1.9005e-04 - onoff_accuracy: 0.9822 - note_accuracy: 0.8802 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 632/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.5800 - onoff_loss: 0.0430 - note_loss: 0.3449 - vel_loss: 0.0165 - time_loss: 1.7560e-04 - onoff_accuracy: 0.9838 - note_accuracy: 0.9278 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1733\n",
            "Epoch 633/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6264 - onoff_loss: 0.0594 - note_loss: 0.3439 - vel_loss: 0.0174 - time_loss: 2.0575e-04 - onoff_accuracy: 0.9783 - note_accuracy: 0.9239 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 634/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5750 - onoff_loss: 0.0470 - note_loss: 0.3494 - vel_loss: 0.0168 - time_loss: 1.6181e-04 - onoff_accuracy: 0.9825 - note_accuracy: 0.9205 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1579\n",
            "Epoch 635/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6125 - onoff_loss: 0.0419 - note_loss: 0.3358 - vel_loss: 0.0175 - time_loss: 2.1731e-04 - onoff_accuracy: 0.9838 - note_accuracy: 0.9271 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1784\n",
            "Epoch 636/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.7621 - onoff_loss: 0.0545 - note_loss: 0.4843 - vel_loss: 0.0171 - time_loss: 2.0613e-04 - onoff_accuracy: 0.9789 - note_accuracy: 0.8774 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1759\n",
            "Epoch 637/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.5729 - onoff_loss: 0.0409 - note_loss: 0.3124 - vel_loss: 0.0157 - time_loss: 2.0392e-04 - onoff_accuracy: 0.9854 - note_accuracy: 0.9351 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1580\n",
            "Epoch 638/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.5462 - onoff_loss: 0.0391 - note_loss: 0.3400 - vel_loss: 0.0163 - time_loss: 1.5071e-04 - onoff_accuracy: 0.9856 - note_accuracy: 0.9235 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1869\n",
            "Epoch 639/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.5757 - onoff_loss: 0.0384 - note_loss: 0.3156 - vel_loss: 0.0164 - time_loss: 2.0523e-04 - onoff_accuracy: 0.9857 - note_accuracy: 0.9338 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1599\n",
            "Epoch 640/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.7699 - onoff_loss: 0.0715 - note_loss: 0.4621 - vel_loss: 0.0170 - time_loss: 2.1935e-04 - onoff_accuracy: 0.9736 - note_accuracy: 0.8836 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 641/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5463 - onoff_loss: 0.0369 - note_loss: 0.3044 - vel_loss: 0.0172 - time_loss: 1.8774e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9381 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1726\n",
            "Epoch 642/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5580 - onoff_loss: 0.0376 - note_loss: 0.3102 - vel_loss: 0.0161 - time_loss: 1.9413e-04 - onoff_accuracy: 0.9864 - note_accuracy: 0.9350 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 643/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.5962 - onoff_loss: 0.0436 - note_loss: 0.3618 - vel_loss: 0.0156 - time_loss: 1.7520e-04 - onoff_accuracy: 0.9839 - note_accuracy: 0.9171 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1443\n",
            "Epoch 644/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.5281 - onoff_loss: 0.0372 - note_loss: 0.2889 - vel_loss: 0.0165 - time_loss: 1.8559e-04 - onoff_accuracy: 0.9867 - note_accuracy: 0.9409 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 645/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.7023 - onoff_loss: 0.0683 - note_loss: 0.4014 - vel_loss: 0.0164 - time_loss: 2.1622e-04 - onoff_accuracy: 0.9734 - note_accuracy: 0.9027 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1620\n",
            "Epoch 646/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.5108 - onoff_loss: 0.0369 - note_loss: 0.2953 - vel_loss: 0.0170 - time_loss: 1.6163e-04 - onoff_accuracy: 0.9862 - note_accuracy: 0.9396 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1778\n",
            "Epoch 647/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4993 - onoff_loss: 0.0358 - note_loss: 0.2726 - vel_loss: 0.0158 - time_loss: 1.7512e-04 - onoff_accuracy: 0.9864 - note_accuracy: 0.9464 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1582\n",
            "Epoch 648/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.6521 - onoff_loss: 0.0609 - note_loss: 0.4102 - vel_loss: 0.0183 - time_loss: 1.6267e-04 - onoff_accuracy: 0.9768 - note_accuracy: 0.9002 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2018\n",
            "Epoch 649/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5274 - onoff_loss: 0.0371 - note_loss: 0.2745 - vel_loss: 0.0155 - time_loss: 2.0029e-04 - onoff_accuracy: 0.9861 - note_accuracy: 0.9424 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1513\n",
            "Epoch 650/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5736 - onoff_loss: 0.0419 - note_loss: 0.3578 - vel_loss: 0.0162 - time_loss: 1.5768e-04 - onoff_accuracy: 0.9843 - note_accuracy: 0.9187 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1925\n",
            "Epoch 651/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5343 - onoff_loss: 0.0361 - note_loss: 0.3089 - vel_loss: 0.0163 - time_loss: 1.7295e-04 - onoff_accuracy: 0.9862 - note_accuracy: 0.9333 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1784\n",
            "Epoch 652/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5631 - onoff_loss: 0.0349 - note_loss: 0.2949 - vel_loss: 0.0170 - time_loss: 2.1627e-04 - onoff_accuracy: 0.9867 - note_accuracy: 0.9369 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 653/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5323 - onoff_loss: 0.0393 - note_loss: 0.3125 - vel_loss: 0.0167 - time_loss: 1.6390e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9296 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823\n",
            "Epoch 654/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5048 - onoff_loss: 0.0395 - note_loss: 0.3000 - vel_loss: 0.0162 - time_loss: 1.4914e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9355 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1771\n",
            "Epoch 655/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5740 - onoff_loss: 0.0422 - note_loss: 0.3379 - vel_loss: 0.0164 - time_loss: 1.7755e-04 - onoff_accuracy: 0.9847 - note_accuracy: 0.9238 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 656/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5153 - onoff_loss: 0.0352 - note_loss: 0.3068 - vel_loss: 0.0160 - time_loss: 1.5731e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9347 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1766\n",
            "Epoch 657/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5413 - onoff_loss: 0.0386 - note_loss: 0.3092 - vel_loss: 0.0160 - time_loss: 1.7748e-04 - onoff_accuracy: 0.9854 - note_accuracy: 0.9322 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1683\n",
            "Epoch 658/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6335 - onoff_loss: 0.0480 - note_loss: 0.3723 - vel_loss: 0.0168 - time_loss: 1.9633e-04 - onoff_accuracy: 0.9825 - note_accuracy: 0.9130 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1701\n",
            "Epoch 659/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4814 - onoff_loss: 0.0340 - note_loss: 0.2553 - vel_loss: 0.0166 - time_loss: 1.7545e-04 - onoff_accuracy: 0.9863 - note_accuracy: 0.9469 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1623\n",
            "Epoch 660/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5381 - onoff_loss: 0.0360 - note_loss: 0.2844 - vel_loss: 0.0169 - time_loss: 2.0075e-04 - onoff_accuracy: 0.9862 - note_accuracy: 0.9393 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1868\n",
            "Epoch 661/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6112 - onoff_loss: 0.0760 - note_loss: 0.3594 - vel_loss: 0.0156 - time_loss: 1.6020e-04 - onoff_accuracy: 0.9706 - note_accuracy: 0.9118 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1556\n",
            "Epoch 662/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.4800 - onoff_loss: 0.0345 - note_loss: 0.2612 - vel_loss: 0.0161 - time_loss: 1.6829e-04 - onoff_accuracy: 0.9861 - note_accuracy: 0.9464 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1827\n",
            "Epoch 663/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5721 - onoff_loss: 0.0407 - note_loss: 0.3097 - vel_loss: 0.0168 - time_loss: 2.0489e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9317 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 664/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4885 - onoff_loss: 0.0353 - note_loss: 0.2943 - vel_loss: 0.0166 - time_loss: 1.4235e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9356 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 665/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4854 - onoff_loss: 0.0351 - note_loss: 0.2663 - vel_loss: 0.0164 - time_loss: 1.6753e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9435 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 666/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6364 - onoff_loss: 0.0725 - note_loss: 0.3689 - vel_loss: 0.0165 - time_loss: 1.7852e-04 - onoff_accuracy: 0.9723 - note_accuracy: 0.9106 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1611\n",
            "Epoch 667/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4514 - onoff_loss: 0.0313 - note_loss: 0.2474 - vel_loss: 0.0163 - time_loss: 1.5646e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9479 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1923\n",
            "Epoch 668/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4910 - onoff_loss: 0.0360 - note_loss: 0.2742 - vel_loss: 0.0165 - time_loss: 1.6426e-04 - onoff_accuracy: 0.9860 - note_accuracy: 0.9404 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1685\n",
            "Epoch 669/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4929 - onoff_loss: 0.0361 - note_loss: 0.2826 - vel_loss: 0.0156 - time_loss: 1.5852e-04 - onoff_accuracy: 0.9863 - note_accuracy: 0.9397 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 670/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4957 - onoff_loss: 0.0348 - note_loss: 0.2752 - vel_loss: 0.0158 - time_loss: 1.6980e-04 - onoff_accuracy: 0.9871 - note_accuracy: 0.9416 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 671/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4896 - onoff_loss: 0.0374 - note_loss: 0.2646 - vel_loss: 0.0166 - time_loss: 1.7101e-04 - onoff_accuracy: 0.9858 - note_accuracy: 0.9459 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 672/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.5479 - onoff_loss: 0.0402 - note_loss: 0.2983 - vel_loss: 0.0168 - time_loss: 1.9249e-04 - onoff_accuracy: 0.9850 - note_accuracy: 0.9344 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 673/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4861 - onoff_loss: 0.0341 - note_loss: 0.2649 - vel_loss: 0.0167 - time_loss: 1.7033e-04 - onoff_accuracy: 0.9867 - note_accuracy: 0.9438 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1664\n",
            "Epoch 674/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4800 - onoff_loss: 0.0334 - note_loss: 0.2504 - vel_loss: 0.0160 - time_loss: 1.8019e-04 - onoff_accuracy: 0.9873 - note_accuracy: 0.9478 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 675/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6236 - onoff_loss: 0.0595 - note_loss: 0.3310 - vel_loss: 0.0167 - time_loss: 2.1647e-04 - onoff_accuracy: 0.9785 - note_accuracy: 0.9233 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1627\n",
            "Epoch 676/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4524 - onoff_loss: 0.0332 - note_loss: 0.2613 - vel_loss: 0.0158 - time_loss: 1.4209e-04 - onoff_accuracy: 0.9873 - note_accuracy: 0.9460 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 677/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6056 - onoff_loss: 0.0394 - note_loss: 0.3483 - vel_loss: 0.0162 - time_loss: 2.0165e-04 - onoff_accuracy: 0.9844 - note_accuracy: 0.9181 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 678/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4557 - onoff_loss: 0.0322 - note_loss: 0.2522 - vel_loss: 0.0157 - time_loss: 1.5566e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9480 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1536\n",
            "Epoch 679/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4245 - onoff_loss: 0.0331 - note_loss: 0.2449 - vel_loss: 0.0169 - time_loss: 1.2955e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9475 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1757\n",
            "Epoch 680/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5565 - onoff_loss: 0.0403 - note_loss: 0.2832 - vel_loss: 0.0167 - time_loss: 2.1645e-04 - onoff_accuracy: 0.9841 - note_accuracy: 0.9360 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 681/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4726 - onoff_loss: 0.0410 - note_loss: 0.2653 - vel_loss: 0.0183 - time_loss: 1.4795e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9415 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1872\n",
            "Epoch 682/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4696 - onoff_loss: 0.0331 - note_loss: 0.2558 - vel_loss: 0.0157 - time_loss: 1.6494e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9452 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 683/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4725 - onoff_loss: 0.0330 - note_loss: 0.2645 - vel_loss: 0.0154 - time_loss: 1.5959e-04 - onoff_accuracy: 0.9872 - note_accuracy: 0.9431 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1636\n",
            "Epoch 684/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4862 - onoff_loss: 0.0328 - note_loss: 0.2536 - vel_loss: 0.0168 - time_loss: 1.8303e-04 - onoff_accuracy: 0.9869 - note_accuracy: 0.9457 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1771\n",
            "Epoch 685/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6687 - onoff_loss: 0.0682 - note_loss: 0.3974 - vel_loss: 0.0169 - time_loss: 1.8625e-04 - onoff_accuracy: 0.9741 - note_accuracy: 0.9012 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1725\n",
            "Epoch 686/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4541 - onoff_loss: 0.0331 - note_loss: 0.2418 - vel_loss: 0.0159 - time_loss: 1.6331e-04 - onoff_accuracy: 0.9866 - note_accuracy: 0.9483 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 687/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4533 - onoff_loss: 0.0321 - note_loss: 0.2421 - vel_loss: 0.0163 - time_loss: 1.6281e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9490 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1833\n",
            "Epoch 688/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5515 - onoff_loss: 0.0403 - note_loss: 0.2846 - vel_loss: 0.0170 - time_loss: 2.0962e-04 - onoff_accuracy: 0.9848 - note_accuracy: 0.9358 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1806\n",
            "Epoch 689/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4665 - onoff_loss: 0.0354 - note_loss: 0.2736 - vel_loss: 0.0168 - time_loss: 1.4072e-04 - onoff_accuracy: 0.9863 - note_accuracy: 0.9388 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2030\n",
            "Epoch 690/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4841 - onoff_loss: 0.0334 - note_loss: 0.2358 - vel_loss: 0.0168 - time_loss: 1.9814e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9506 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 691/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.5625 - onoff_loss: 0.0698 - note_loss: 0.2897 - vel_loss: 0.0171 - time_loss: 1.8593e-04 - onoff_accuracy: 0.9752 - note_accuracy: 0.9336 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 692/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.4571 - onoff_loss: 0.0332 - note_loss: 0.2503 - vel_loss: 0.0173 - time_loss: 1.5633e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9457 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1771\n",
            "Epoch 693/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4388 - onoff_loss: 0.0313 - note_loss: 0.2345 - vel_loss: 0.0160 - time_loss: 1.5694e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9498 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1742\n",
            "Epoch 694/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6057 - onoff_loss: 0.0448 - note_loss: 0.3840 - vel_loss: 0.0165 - time_loss: 1.6043e-04 - onoff_accuracy: 0.9823 - note_accuracy: 0.9049 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 695/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4809 - onoff_loss: 0.0351 - note_loss: 0.2437 - vel_loss: 0.0166 - time_loss: 1.8556e-04 - onoff_accuracy: 0.9862 - note_accuracy: 0.9472 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1987\n",
            "Epoch 696/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4304 - onoff_loss: 0.0307 - note_loss: 0.2276 - vel_loss: 0.0159 - time_loss: 1.5617e-04 - onoff_accuracy: 0.9874 - note_accuracy: 0.9521 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1882\n",
            "Epoch 697/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4443 - onoff_loss: 0.0336 - note_loss: 0.2334 - vel_loss: 0.0155 - time_loss: 1.6176e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9498 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1631\n",
            "Epoch 698/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5289 - onoff_loss: 0.0441 - note_loss: 0.2974 - vel_loss: 0.0166 - time_loss: 1.7079e-04 - onoff_accuracy: 0.9835 - note_accuracy: 0.9313 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 699/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4495 - onoff_loss: 0.0333 - note_loss: 0.2376 - vel_loss: 0.0164 - time_loss: 1.6221e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9488 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1808\n",
            "Epoch 700/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4485 - onoff_loss: 0.0311 - note_loss: 0.2284 - vel_loss: 0.0163 - time_loss: 1.7275e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9506 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1685\n",
            "Epoch 701/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4219 - onoff_loss: 0.0323 - note_loss: 0.2301 - vel_loss: 0.0164 - time_loss: 1.4311e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9507 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1993\n",
            "Epoch 702/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5260 - onoff_loss: 0.0426 - note_loss: 0.3087 - vel_loss: 0.0163 - time_loss: 1.5839e-04 - onoff_accuracy: 0.9837 - note_accuracy: 0.9279 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1820\n",
            "Epoch 703/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4486 - onoff_loss: 0.0320 - note_loss: 0.2172 - vel_loss: 0.0165 - time_loss: 1.8293e-04 - onoff_accuracy: 0.9871 - note_accuracy: 0.9538 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 704/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4784 - onoff_loss: 0.0357 - note_loss: 0.2513 - vel_loss: 0.0154 - time_loss: 1.7599e-04 - onoff_accuracy: 0.9863 - note_accuracy: 0.9449 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1647\n",
            "Epoch 705/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4983 - onoff_loss: 0.0349 - note_loss: 0.2739 - vel_loss: 0.0167 - time_loss: 1.7279e-04 - onoff_accuracy: 0.9864 - note_accuracy: 0.9385 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1600\n",
            "Epoch 706/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4169 - onoff_loss: 0.0307 - note_loss: 0.2296 - vel_loss: 0.0161 - time_loss: 1.4040e-04 - onoff_accuracy: 0.9881 - note_accuracy: 0.9514 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1883\n",
            "Epoch 707/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4013 - onoff_loss: 0.0304 - note_loss: 0.2258 - vel_loss: 0.0160 - time_loss: 1.2913e-04 - onoff_accuracy: 0.9881 - note_accuracy: 0.9512 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 708/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.5112 - onoff_loss: 0.0523 - note_loss: 0.2705 - vel_loss: 0.0160 - time_loss: 1.7234e-04 - onoff_accuracy: 0.9789 - note_accuracy: 0.9376 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1637\n",
            "Epoch 709/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4271 - onoff_loss: 0.0363 - note_loss: 0.2237 - vel_loss: 0.0155 - time_loss: 1.5156e-04 - onoff_accuracy: 0.9855 - note_accuracy: 0.9521 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 710/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4039 - onoff_loss: 0.0319 - note_loss: 0.2216 - vel_loss: 0.0161 - time_loss: 1.3434e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9526 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1815\n",
            "Epoch 711/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4872 - onoff_loss: 0.0343 - note_loss: 0.2439 - vel_loss: 0.0166 - time_loss: 1.9251e-04 - onoff_accuracy: 0.9869 - note_accuracy: 0.9455 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1808\n",
            "Epoch 712/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4954 - onoff_loss: 0.0354 - note_loss: 0.2764 - vel_loss: 0.0162 - time_loss: 1.6732e-04 - onoff_accuracy: 0.9864 - note_accuracy: 0.9353 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1825\n",
            "Epoch 713/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4185 - onoff_loss: 0.0309 - note_loss: 0.2247 - vel_loss: 0.0159 - time_loss: 1.4700e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9512 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 714/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4691 - onoff_loss: 0.0506 - note_loss: 0.2506 - vel_loss: 0.0160 - time_loss: 1.5194e-04 - onoff_accuracy: 0.9794 - note_accuracy: 0.9434 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 715/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4462 - onoff_loss: 0.0350 - note_loss: 0.2366 - vel_loss: 0.0169 - time_loss: 1.5770e-04 - onoff_accuracy: 0.9866 - note_accuracy: 0.9478 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1990\n",
            "Epoch 716/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6469 - onoff_loss: 0.0456 - note_loss: 0.3811 - vel_loss: 0.0169 - time_loss: 2.0327e-04 - onoff_accuracy: 0.9822 - note_accuracy: 0.9046 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1901\n",
            "Epoch 717/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4017 - onoff_loss: 0.0286 - note_loss: 0.2088 - vel_loss: 0.0160 - time_loss: 1.4829e-04 - onoff_accuracy: 0.9885 - note_accuracy: 0.9553 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1744\n",
            "Epoch 718/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4582 - onoff_loss: 0.0363 - note_loss: 0.2519 - vel_loss: 0.0163 - time_loss: 1.5372e-04 - onoff_accuracy: 0.9857 - note_accuracy: 0.9463 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1780\n",
            "Epoch 719/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4285 - onoff_loss: 0.0318 - note_loss: 0.2287 - vel_loss: 0.0161 - time_loss: 1.5183e-04 - onoff_accuracy: 0.9872 - note_accuracy: 0.9504 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 720/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5226 - onoff_loss: 0.0397 - note_loss: 0.3208 - vel_loss: 0.0157 - time_loss: 1.4646e-04 - onoff_accuracy: 0.9846 - note_accuracy: 0.9192 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 721/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4182 - onoff_loss: 0.0308 - note_loss: 0.2293 - vel_loss: 0.0152 - time_loss: 1.4302e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9525 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1680\n",
            "Epoch 722/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3869 - onoff_loss: 0.0317 - note_loss: 0.2085 - vel_loss: 0.0160 - time_loss: 1.3070e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9543 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1943\n",
            "Epoch 723/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.5576 - onoff_loss: 0.0450 - note_loss: 0.3115 - vel_loss: 0.0157 - time_loss: 1.8544e-04 - onoff_accuracy: 0.9824 - note_accuracy: 0.9235 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1620\n",
            "Epoch 724/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4353 - onoff_loss: 0.0307 - note_loss: 0.2040 - vel_loss: 0.0159 - time_loss: 1.8465e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9557 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1505\n",
            "Epoch 725/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4055 - onoff_loss: 0.0296 - note_loss: 0.2121 - vel_loss: 0.0152 - time_loss: 1.4863e-04 - onoff_accuracy: 0.9885 - note_accuracy: 0.9553 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1541\n",
            "Epoch 726/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4503 - onoff_loss: 0.0359 - note_loss: 0.2436 - vel_loss: 0.0156 - time_loss: 1.5521e-04 - onoff_accuracy: 0.9856 - note_accuracy: 0.9449 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1559\n",
            "Epoch 727/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4038 - onoff_loss: 0.0307 - note_loss: 0.2082 - vel_loss: 0.0163 - time_loss: 1.4860e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9552 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1774\n",
            "Epoch 728/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4494 - onoff_loss: 0.0348 - note_loss: 0.2447 - vel_loss: 0.0168 - time_loss: 1.5310e-04 - onoff_accuracy: 0.9862 - note_accuracy: 0.9461 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1882\n",
            "Epoch 729/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4553 - onoff_loss: 0.0344 - note_loss: 0.2271 - vel_loss: 0.0156 - time_loss: 1.7826e-04 - onoff_accuracy: 0.9867 - note_accuracy: 0.9502 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1608\n",
            "Epoch 730/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3790 - onoff_loss: 0.0319 - note_loss: 0.2054 - vel_loss: 0.0152 - time_loss: 1.2651e-04 - onoff_accuracy: 0.9874 - note_accuracy: 0.9550 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 731/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4729 - onoff_loss: 0.0367 - note_loss: 0.2397 - vel_loss: 0.0156 - time_loss: 1.8093e-04 - onoff_accuracy: 0.9859 - note_accuracy: 0.9464 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1706\n",
            "Epoch 732/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4235 - onoff_loss: 0.0301 - note_loss: 0.2073 - vel_loss: 0.0153 - time_loss: 1.7080e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9545 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1621\n",
            "Epoch 733/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4467 - onoff_loss: 0.0370 - note_loss: 0.2270 - vel_loss: 0.0160 - time_loss: 1.6675e-04 - onoff_accuracy: 0.9848 - note_accuracy: 0.9482 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 734/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4453 - onoff_loss: 0.0463 - note_loss: 0.2437 - vel_loss: 0.0159 - time_loss: 1.3947e-04 - onoff_accuracy: 0.9814 - note_accuracy: 0.9442 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1615\n",
            "Epoch 735/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3981 - onoff_loss: 0.0284 - note_loss: 0.2091 - vel_loss: 0.0160 - time_loss: 1.4456e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9533 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1962\n",
            "Epoch 736/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3863 - onoff_loss: 0.0282 - note_loss: 0.2051 - vel_loss: 0.0151 - time_loss: 1.3794e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9545 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 737/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5627 - onoff_loss: 0.0429 - note_loss: 0.3381 - vel_loss: 0.0161 - time_loss: 1.6564e-04 - onoff_accuracy: 0.9829 - note_accuracy: 0.9138 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1874\n",
            "Epoch 738/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3856 - onoff_loss: 0.0299 - note_loss: 0.1991 - vel_loss: 0.0153 - time_loss: 1.4135e-04 - onoff_accuracy: 0.9873 - note_accuracy: 0.9564 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1706\n",
            "Epoch 739/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3707 - onoff_loss: 0.0295 - note_loss: 0.1963 - vel_loss: 0.0170 - time_loss: 1.2791e-04 - onoff_accuracy: 0.9873 - note_accuracy: 0.9569 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1824\n",
            "Epoch 740/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4411 - onoff_loss: 0.0302 - note_loss: 0.2156 - vel_loss: 0.0165 - time_loss: 1.7876e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9542 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1857\n",
            "Epoch 741/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4484 - onoff_loss: 0.0350 - note_loss: 0.2403 - vel_loss: 0.0161 - time_loss: 1.5701e-04 - onoff_accuracy: 0.9856 - note_accuracy: 0.9453 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1703\n",
            "Epoch 742/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3826 - onoff_loss: 0.0307 - note_loss: 0.2032 - vel_loss: 0.0168 - time_loss: 1.3192e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9557 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 743/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4659 - onoff_loss: 0.0350 - note_loss: 0.2408 - vel_loss: 0.0158 - time_loss: 1.7432e-04 - onoff_accuracy: 0.9861 - note_accuracy: 0.9447 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 744/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3976 - onoff_loss: 0.0289 - note_loss: 0.2071 - vel_loss: 0.0154 - time_loss: 1.4628e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9556 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1504\n",
            "Epoch 745/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4255 - onoff_loss: 0.0335 - note_loss: 0.2185 - vel_loss: 0.0161 - time_loss: 1.5736e-04 - onoff_accuracy: 0.9871 - note_accuracy: 0.9508 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1872\n",
            "Epoch 746/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5329 - onoff_loss: 0.0490 - note_loss: 0.2961 - vel_loss: 0.0164 - time_loss: 1.7138e-04 - onoff_accuracy: 0.9818 - note_accuracy: 0.9270 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 747/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4007 - onoff_loss: 0.0300 - note_loss: 0.2008 - vel_loss: 0.0156 - time_loss: 1.5421e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9554 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 748/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4142 - onoff_loss: 0.0288 - note_loss: 0.2063 - vel_loss: 0.0160 - time_loss: 1.6313e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9545 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1849\n",
            "Epoch 749/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4407 - onoff_loss: 0.0312 - note_loss: 0.2104 - vel_loss: 0.0154 - time_loss: 1.8380e-04 - onoff_accuracy: 0.9873 - note_accuracy: 0.9532 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 750/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4762 - onoff_loss: 0.0587 - note_loss: 0.2588 - vel_loss: 0.0155 - time_loss: 1.4321e-04 - onoff_accuracy: 0.9782 - note_accuracy: 0.9395 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1700\n",
            "Epoch 751/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3667 - onoff_loss: 0.0306 - note_loss: 0.1825 - vel_loss: 0.0151 - time_loss: 1.3844e-04 - onoff_accuracy: 0.9869 - note_accuracy: 0.9597 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1779\n",
            "Epoch 752/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4207 - onoff_loss: 0.0294 - note_loss: 0.2099 - vel_loss: 0.0150 - time_loss: 1.6635e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9528 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1609\n",
            "Epoch 753/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4497 - onoff_loss: 0.0318 - note_loss: 0.2309 - vel_loss: 0.0160 - time_loss: 1.7095e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9480 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1835\n",
            "Epoch 754/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4941 - onoff_loss: 0.0364 - note_loss: 0.2678 - vel_loss: 0.0170 - time_loss: 1.7278e-04 - onoff_accuracy: 0.9850 - note_accuracy: 0.9344 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1867\n",
            "Epoch 755/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3820 - onoff_loss: 0.0280 - note_loss: 0.2079 - vel_loss: 0.0155 - time_loss: 1.3057e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9545 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1616\n",
            "Epoch 756/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3722 - onoff_loss: 0.0311 - note_loss: 0.1983 - vel_loss: 0.0155 - time_loss: 1.2740e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9551 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1636\n",
            "Epoch 757/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.4098 - onoff_loss: 0.0294 - note_loss: 0.1905 - vel_loss: 0.0153 - time_loss: 1.7465e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9582 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 758/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4226 - onoff_loss: 0.0313 - note_loss: 0.2154 - vel_loss: 0.0164 - time_loss: 1.5950e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9517 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823\n",
            "Epoch 759/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3762 - onoff_loss: 0.0254 - note_loss: 0.1893 - vel_loss: 0.0158 - time_loss: 1.4582e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9576 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 760/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3752 - onoff_loss: 0.0340 - note_loss: 0.2063 - vel_loss: 0.0157 - time_loss: 1.1918e-04 - onoff_accuracy: 0.9863 - note_accuracy: 0.9536 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1836\n",
            "Epoch 761/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4753 - onoff_loss: 0.0370 - note_loss: 0.2681 - vel_loss: 0.0158 - time_loss: 1.5435e-04 - onoff_accuracy: 0.9856 - note_accuracy: 0.9342 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 762/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4028 - onoff_loss: 0.0278 - note_loss: 0.2021 - vel_loss: 0.0157 - time_loss: 1.5720e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9566 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1562\n",
            "Epoch 763/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3535 - onoff_loss: 0.0260 - note_loss: 0.1796 - vel_loss: 0.0152 - time_loss: 1.3276e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9605 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 764/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3726 - onoff_loss: 0.0287 - note_loss: 0.1936 - vel_loss: 0.0153 - time_loss: 1.3509e-04 - onoff_accuracy: 0.9886 - note_accuracy: 0.9581 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1863\n",
            "Epoch 765/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5000 - onoff_loss: 0.0426 - note_loss: 0.3076 - vel_loss: 0.0164 - time_loss: 1.3343e-04 - onoff_accuracy: 0.9827 - note_accuracy: 0.9239 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 766/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3633 - onoff_loss: 0.0255 - note_loss: 0.1812 - vel_loss: 0.0156 - time_loss: 1.4100e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9599 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 767/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3920 - onoff_loss: 0.0296 - note_loss: 0.1933 - vel_loss: 0.0156 - time_loss: 1.5361e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9576 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 768/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4006 - onoff_loss: 0.0318 - note_loss: 0.1948 - vel_loss: 0.0151 - time_loss: 1.5890e-04 - onoff_accuracy: 0.9871 - note_accuracy: 0.9546 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1596\n",
            "Epoch 769/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3637 - onoff_loss: 0.0301 - note_loss: 0.1998 - vel_loss: 0.0149 - time_loss: 1.1885e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9555 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1647\n",
            "Epoch 770/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4383 - onoff_loss: 0.0302 - note_loss: 0.1959 - vel_loss: 0.0149 - time_loss: 1.9729e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9566 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1591\n",
            "Epoch 771/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.5373 - onoff_loss: 0.0375 - note_loss: 0.3575 - vel_loss: 0.0159 - time_loss: 1.2629e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9191 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1987\n",
            "Epoch 772/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3482 - onoff_loss: 0.0276 - note_loss: 0.1804 - vel_loss: 0.0152 - time_loss: 1.2499e-04 - onoff_accuracy: 0.9881 - note_accuracy: 0.9584 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1732\n",
            "Epoch 773/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3667 - onoff_loss: 0.0293 - note_loss: 0.1851 - vel_loss: 0.0164 - time_loss: 1.3591e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9578 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 774/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3867 - onoff_loss: 0.0294 - note_loss: 0.1879 - vel_loss: 0.0153 - time_loss: 1.5409e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9581 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1592\n",
            "Epoch 775/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3825 - onoff_loss: 0.0284 - note_loss: 0.1857 - vel_loss: 0.0147 - time_loss: 1.5371e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9581 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1608\n",
            "Epoch 776/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4056 - onoff_loss: 0.0315 - note_loss: 0.1895 - vel_loss: 0.0150 - time_loss: 1.6968e-04 - onoff_accuracy: 0.9871 - note_accuracy: 0.9578 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1530\n",
            "Epoch 777/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4267 - onoff_loss: 0.0328 - note_loss: 0.2304 - vel_loss: 0.0150 - time_loss: 1.4856e-04 - onoff_accuracy: 0.9869 - note_accuracy: 0.9460 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 778/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3682 - onoff_loss: 0.0287 - note_loss: 0.1939 - vel_loss: 0.0157 - time_loss: 1.2992e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9574 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1796\n",
            "Epoch 779/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4240 - onoff_loss: 0.0305 - note_loss: 0.1919 - vel_loss: 0.0146 - time_loss: 1.8700e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9566 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1645\n",
            "Epoch 780/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3834 - onoff_loss: 0.0285 - note_loss: 0.1873 - vel_loss: 0.0157 - time_loss: 1.5201e-04 - onoff_accuracy: 0.9887 - note_accuracy: 0.9580 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1753\n",
            "Epoch 781/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3653 - onoff_loss: 0.0284 - note_loss: 0.1852 - vel_loss: 0.0147 - time_loss: 1.3700e-04 - onoff_accuracy: 0.9881 - note_accuracy: 0.9575 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1705\n",
            "Epoch 782/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.5238 - onoff_loss: 0.0554 - note_loss: 0.2972 - vel_loss: 0.0147 - time_loss: 1.5649e-04 - onoff_accuracy: 0.9791 - note_accuracy: 0.9229 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 783/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3658 - onoff_loss: 0.0262 - note_loss: 0.1757 - vel_loss: 0.0157 - time_loss: 1.4824e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9601 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 784/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3686 - onoff_loss: 0.0266 - note_loss: 0.1737 - vel_loss: 0.0154 - time_loss: 1.5292e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9607 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 785/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.3934 - onoff_loss: 0.0363 - note_loss: 0.2015 - vel_loss: 0.0151 - time_loss: 1.4055e-04 - onoff_accuracy: 0.9855 - note_accuracy: 0.9546 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1815\n",
            "Epoch 786/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3901 - onoff_loss: 0.0309 - note_loss: 0.1925 - vel_loss: 0.0152 - time_loss: 1.5152e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9566 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1584\n",
            "Epoch 787/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3677 - onoff_loss: 0.0272 - note_loss: 0.1808 - vel_loss: 0.0156 - time_loss: 1.4398e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9595 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1636\n",
            "Epoch 788/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4744 - onoff_loss: 0.0371 - note_loss: 0.2782 - vel_loss: 0.0161 - time_loss: 1.4300e-04 - onoff_accuracy: 0.9861 - note_accuracy: 0.9325 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1836\n",
            "Epoch 789/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3599 - onoff_loss: 0.0281 - note_loss: 0.1790 - vel_loss: 0.0149 - time_loss: 1.3787e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9598 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1862\n",
            "Epoch 790/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3235 - onoff_loss: 0.0257 - note_loss: 0.1750 - vel_loss: 0.0150 - time_loss: 1.0773e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1582\n",
            "Epoch 791/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4002 - onoff_loss: 0.0292 - note_loss: 0.1820 - vel_loss: 0.0150 - time_loss: 1.7395e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9592 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 792/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4142 - onoff_loss: 0.0330 - note_loss: 0.2087 - vel_loss: 0.0164 - time_loss: 1.5610e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9531 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 793/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3929 - onoff_loss: 0.0265 - note_loss: 0.1804 - vel_loss: 0.0150 - time_loss: 1.7110e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9592 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1664\n",
            "Epoch 794/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3355 - onoff_loss: 0.0285 - note_loss: 0.1826 - vel_loss: 0.0155 - time_loss: 1.0902e-04 - onoff_accuracy: 0.9886 - note_accuracy: 0.9581 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 795/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4190 - onoff_loss: 0.0324 - note_loss: 0.2283 - vel_loss: 0.0146 - time_loss: 1.4361e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9462 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1668\n",
            "Epoch 796/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3334 - onoff_loss: 0.0261 - note_loss: 0.1682 - vel_loss: 0.0148 - time_loss: 1.2424e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9613 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 797/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3959 - onoff_loss: 0.0351 - note_loss: 0.2184 - vel_loss: 0.0155 - time_loss: 1.2683e-04 - onoff_accuracy: 0.9851 - note_accuracy: 0.9481 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 798/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3546 - onoff_loss: 0.0274 - note_loss: 0.1803 - vel_loss: 0.0149 - time_loss: 1.3208e-04 - onoff_accuracy: 0.9884 - note_accuracy: 0.9588 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 799/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3912 - onoff_loss: 0.0283 - note_loss: 0.1865 - vel_loss: 0.0155 - time_loss: 1.6091e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9573 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 800/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4450 - onoff_loss: 0.0353 - note_loss: 0.2292 - vel_loss: 0.0156 - time_loss: 1.6485e-04 - onoff_accuracy: 0.9860 - note_accuracy: 0.9446 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 801/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3329 - onoff_loss: 0.0295 - note_loss: 0.1833 - vel_loss: 0.0137 - time_loss: 1.0649e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9577 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 802/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3369 - onoff_loss: 0.0247 - note_loss: 0.1575 - vel_loss: 0.0159 - time_loss: 1.3890e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9634 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2039\n",
            "Epoch 803/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3809 - onoff_loss: 0.0276 - note_loss: 0.1763 - vel_loss: 0.0155 - time_loss: 1.6153e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9596 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1773\n",
            "Epoch 804/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3584 - onoff_loss: 0.0286 - note_loss: 0.1768 - vel_loss: 0.0156 - time_loss: 1.3735e-04 - onoff_accuracy: 0.9877 - note_accuracy: 0.9600 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1644\n",
            "Epoch 805/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4457 - onoff_loss: 0.0366 - note_loss: 0.2132 - vel_loss: 0.0150 - time_loss: 1.8082e-04 - onoff_accuracy: 0.9851 - note_accuracy: 0.9492 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 806/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3638 - onoff_loss: 0.0264 - note_loss: 0.1628 - vel_loss: 0.0145 - time_loss: 1.6005e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9627 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1605\n",
            "Epoch 807/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3694 - onoff_loss: 0.0268 - note_loss: 0.1740 - vel_loss: 0.0146 - time_loss: 1.5387e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9605 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1549\n",
            "Epoch 808/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4078 - onoff_loss: 0.0286 - note_loss: 0.1833 - vel_loss: 0.0152 - time_loss: 1.8070e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9571 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 809/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3932 - onoff_loss: 0.0358 - note_loss: 0.2161 - vel_loss: 0.0153 - time_loss: 1.2603e-04 - onoff_accuracy: 0.9861 - note_accuracy: 0.9479 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 810/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3626 - onoff_loss: 0.0270 - note_loss: 0.1739 - vel_loss: 0.0162 - time_loss: 1.4553e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9610 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1803\n",
            "Epoch 811/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3658 - onoff_loss: 0.0285 - note_loss: 0.1757 - vel_loss: 0.0143 - time_loss: 1.4725e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9600 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1617\n",
            "Epoch 812/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3591 - onoff_loss: 0.0282 - note_loss: 0.1762 - vel_loss: 0.0151 - time_loss: 1.3966e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9585 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1771\n",
            "Epoch 813/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3807 - onoff_loss: 0.0301 - note_loss: 0.2081 - vel_loss: 0.0145 - time_loss: 1.2800e-04 - onoff_accuracy: 0.9874 - note_accuracy: 0.9493 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1626\n",
            "Epoch 814/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3540 - onoff_loss: 0.0269 - note_loss: 0.1744 - vel_loss: 0.0146 - time_loss: 1.3820e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9602 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1622\n",
            "Epoch 815/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3631 - onoff_loss: 0.0258 - note_loss: 0.1687 - vel_loss: 0.0152 - time_loss: 1.5344e-04 - onoff_accuracy: 0.9887 - note_accuracy: 0.9618 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1711\n",
            "Epoch 816/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3905 - onoff_loss: 0.0305 - note_loss: 0.2037 - vel_loss: 0.0143 - time_loss: 1.4207e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9523 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1621\n",
            "Epoch 817/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3705 - onoff_loss: 0.0275 - note_loss: 0.1988 - vel_loss: 0.0153 - time_loss: 1.2898e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9531 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1618\n",
            "Epoch 818/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3546 - onoff_loss: 0.0275 - note_loss: 0.1738 - vel_loss: 0.0150 - time_loss: 1.3828e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9597 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1631\n",
            "Epoch 819/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3357 - onoff_loss: 0.0256 - note_loss: 0.1626 - vel_loss: 0.0152 - time_loss: 1.3223e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9619 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1856\n",
            "Epoch 820/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3350 - onoff_loss: 0.0264 - note_loss: 0.1695 - vel_loss: 0.0154 - time_loss: 1.2370e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9611 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1910\n",
            "Epoch 821/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4046 - onoff_loss: 0.0330 - note_loss: 0.2102 - vel_loss: 0.0149 - time_loss: 1.4653e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9496 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 822/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3519 - onoff_loss: 0.0290 - note_loss: 0.1622 - vel_loss: 0.0154 - time_loss: 1.4529e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9619 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1756\n",
            "Epoch 823/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3295 - onoff_loss: 0.0268 - note_loss: 0.1789 - vel_loss: 0.0145 - time_loss: 1.0941e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9594 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1633\n",
            "Epoch 824/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4058 - onoff_loss: 0.0289 - note_loss: 0.1896 - vel_loss: 0.0147 - time_loss: 1.7262e-04 - onoff_accuracy: 0.9870 - note_accuracy: 0.9558 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1678\n",
            "Epoch 825/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4084 - onoff_loss: 0.0290 - note_loss: 0.1996 - vel_loss: 0.0152 - time_loss: 1.6467e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9541 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1936\n",
            "Epoch 826/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3142 - onoff_loss: 0.0240 - note_loss: 0.1618 - vel_loss: 0.0152 - time_loss: 1.1307e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1818\n",
            "Epoch 827/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3497 - onoff_loss: 0.0260 - note_loss: 0.1691 - vel_loss: 0.0151 - time_loss: 1.3953e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9616 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 828/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4068 - onoff_loss: 0.0408 - note_loss: 0.2124 - vel_loss: 0.0155 - time_loss: 1.3806e-04 - onoff_accuracy: 0.9835 - note_accuracy: 0.9485 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1770\n",
            "Epoch 829/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3298 - onoff_loss: 0.0256 - note_loss: 0.1592 - vel_loss: 0.0154 - time_loss: 1.2954e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9624 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1878\n",
            "Epoch 830/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3179 - onoff_loss: 0.0238 - note_loss: 0.1640 - vel_loss: 0.0151 - time_loss: 1.1506e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9620 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 831/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3576 - onoff_loss: 0.0260 - note_loss: 0.1723 - vel_loss: 0.0145 - time_loss: 1.4483e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9602 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 832/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3709 - onoff_loss: 0.0260 - note_loss: 0.1793 - vel_loss: 0.0148 - time_loss: 1.5079e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9581 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1807\n",
            "Epoch 833/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3525 - onoff_loss: 0.0285 - note_loss: 0.1740 - vel_loss: 0.0149 - time_loss: 1.3507e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9601 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1689\n",
            "Epoch 834/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3311 - onoff_loss: 0.0260 - note_loss: 0.1666 - vel_loss: 0.0150 - time_loss: 1.2346e-04 - onoff_accuracy: 0.9884 - note_accuracy: 0.9612 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1688\n",
            "Epoch 835/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3594 - onoff_loss: 0.0289 - note_loss: 0.1734 - vel_loss: 0.0151 - time_loss: 1.4199e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9601 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1699\n",
            "Epoch 836/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3337 - onoff_loss: 0.0263 - note_loss: 0.1686 - vel_loss: 0.0151 - time_loss: 1.2375e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1584\n",
            "Epoch 837/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3369 - onoff_loss: 0.0257 - note_loss: 0.1671 - vel_loss: 0.0143 - time_loss: 1.2976e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9620 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1641\n",
            "Epoch 838/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3739 - onoff_loss: 0.0288 - note_loss: 0.1905 - vel_loss: 0.0146 - time_loss: 1.4000e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9565 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1581\n",
            "Epoch 839/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3357 - onoff_loss: 0.0256 - note_loss: 0.1577 - vel_loss: 0.0148 - time_loss: 1.3762e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9628 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1626\n",
            "Epoch 840/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3129 - onoff_loss: 0.0258 - note_loss: 0.1663 - vel_loss: 0.0137 - time_loss: 1.0711e-04 - onoff_accuracy: 0.9885 - note_accuracy: 0.9619 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1741\n",
            "Epoch 841/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3434 - onoff_loss: 0.0256 - note_loss: 0.1762 - vel_loss: 0.0150 - time_loss: 1.2656e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9579 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1751\n",
            "Epoch 842/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4002 - onoff_loss: 0.0287 - note_loss: 0.1732 - vel_loss: 0.0158 - time_loss: 1.8264e-04 - onoff_accuracy: 0.9876 - note_accuracy: 0.9595 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1615\n",
            "Epoch 843/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3179 - onoff_loss: 0.0263 - note_loss: 0.1605 - vel_loss: 0.0151 - time_loss: 1.1594e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9624 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1927\n",
            "Epoch 844/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3513 - onoff_loss: 0.0257 - note_loss: 0.1703 - vel_loss: 0.0149 - time_loss: 1.4035e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9604 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1774\n",
            "Epoch 845/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3475 - onoff_loss: 0.0268 - note_loss: 0.1737 - vel_loss: 0.0143 - time_loss: 1.3261e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9584 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1612\n",
            "Epoch 846/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3735 - onoff_loss: 0.0260 - note_loss: 0.1808 - vel_loss: 0.0146 - time_loss: 1.5197e-04 - onoff_accuracy: 0.9886 - note_accuracy: 0.9582 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 847/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3247 - onoff_loss: 0.0260 - note_loss: 0.1646 - vel_loss: 0.0146 - time_loss: 1.1954e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9613 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 848/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3568 - onoff_loss: 0.0260 - note_loss: 0.1739 - vel_loss: 0.0147 - time_loss: 1.4219e-04 - onoff_accuracy: 0.9885 - note_accuracy: 0.9591 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1859\n",
            "Epoch 849/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3802 - onoff_loss: 0.0357 - note_loss: 0.2115 - vel_loss: 0.0147 - time_loss: 1.1831e-04 - onoff_accuracy: 0.9852 - note_accuracy: 0.9483 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1789\n",
            "Epoch 850/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3465 - onoff_loss: 0.0258 - note_loss: 0.1585 - vel_loss: 0.0146 - time_loss: 1.4762e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9625 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1676\n",
            "Epoch 851/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.3438 - onoff_loss: 0.0268 - note_loss: 0.1624 - vel_loss: 0.0150 - time_loss: 1.3951e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9616 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1673\n",
            "Epoch 852/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3223 - onoff_loss: 0.0237 - note_loss: 0.1617 - vel_loss: 0.0148 - time_loss: 1.2217e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9628 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1659\n",
            "Epoch 853/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3472 - onoff_loss: 0.0267 - note_loss: 0.1715 - vel_loss: 0.0143 - time_loss: 1.3468e-04 - onoff_accuracy: 0.9885 - note_accuracy: 0.9611 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1624\n",
            "Epoch 854/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3811 - onoff_loss: 0.0317 - note_loss: 0.2055 - vel_loss: 0.0156 - time_loss: 1.2830e-04 - onoff_accuracy: 0.9868 - note_accuracy: 0.9495 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1875\n",
            "Epoch 855/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3426 - onoff_loss: 0.0258 - note_loss: 0.1638 - vel_loss: 0.0145 - time_loss: 1.3846e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9618 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1701\n",
            "Epoch 856/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3260 - onoff_loss: 0.0230 - note_loss: 0.1564 - vel_loss: 0.0150 - time_loss: 1.3159e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9634 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1934\n",
            "Epoch 857/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3173 - onoff_loss: 0.0248 - note_loss: 0.1611 - vel_loss: 0.0147 - time_loss: 1.1678e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9623 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1874\n",
            "Epoch 858/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3270 - onoff_loss: 0.0269 - note_loss: 0.1696 - vel_loss: 0.0138 - time_loss: 1.1671e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9606 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1846\n",
            "Epoch 859/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3457 - onoff_loss: 0.0247 - note_loss: 0.1659 - vel_loss: 0.0143 - time_loss: 1.4074e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9617 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1766\n",
            "Epoch 860/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3333 - onoff_loss: 0.0282 - note_loss: 0.1602 - vel_loss: 0.0140 - time_loss: 1.3089e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9613 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 861/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3386 - onoff_loss: 0.0253 - note_loss: 0.1670 - vel_loss: 0.0151 - time_loss: 1.3121e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9610 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1690\n",
            "Epoch 862/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3131 - onoff_loss: 0.0244 - note_loss: 0.1612 - vel_loss: 0.0146 - time_loss: 1.1288e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9616 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1810\n",
            "Epoch 863/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3756 - onoff_loss: 0.0292 - note_loss: 0.2095 - vel_loss: 0.0141 - time_loss: 1.2281e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9472 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 864/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3270 - onoff_loss: 0.0222 - note_loss: 0.1507 - vel_loss: 0.0150 - time_loss: 1.3909e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9640 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1866\n",
            "Epoch 865/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3279 - onoff_loss: 0.0231 - note_loss: 0.1549 - vel_loss: 0.0148 - time_loss: 1.3508e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9636 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1900\n",
            "Epoch 866/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3392 - onoff_loss: 0.0267 - note_loss: 0.1601 - vel_loss: 0.0139 - time_loss: 1.3840e-04 - onoff_accuracy: 0.9884 - note_accuracy: 0.9619 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1579\n",
            "Epoch 867/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3413 - onoff_loss: 0.0275 - note_loss: 0.1823 - vel_loss: 0.0143 - time_loss: 1.1718e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9560 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1629\n",
            "Epoch 868/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3688 - onoff_loss: 0.0257 - note_loss: 0.1642 - vel_loss: 0.0145 - time_loss: 1.6441e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9615 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1703\n",
            "Epoch 869/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3111 - onoff_loss: 0.0249 - note_loss: 0.1550 - vel_loss: 0.0146 - time_loss: 1.1661e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9630 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1665\n",
            "Epoch 870/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3739 - onoff_loss: 0.0271 - note_loss: 0.1721 - vel_loss: 0.0148 - time_loss: 1.5997e-04 - onoff_accuracy: 0.9886 - note_accuracy: 0.9592 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1741\n",
            "Epoch 871/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3284 - onoff_loss: 0.0272 - note_loss: 0.1664 - vel_loss: 0.0142 - time_loss: 1.2063e-04 - onoff_accuracy: 0.9886 - note_accuracy: 0.9613 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 872/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3505 - onoff_loss: 0.0282 - note_loss: 0.1688 - vel_loss: 0.0144 - time_loss: 1.3916e-04 - onoff_accuracy: 0.9878 - note_accuracy: 0.9614 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1753\n",
            "Epoch 873/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3661 - onoff_loss: 0.0330 - note_loss: 0.1695 - vel_loss: 0.0150 - time_loss: 1.4870e-04 - onoff_accuracy: 0.9865 - note_accuracy: 0.9601 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1740\n",
            "Epoch 874/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3095 - onoff_loss: 0.0241 - note_loss: 0.1551 - vel_loss: 0.0151 - time_loss: 1.1526e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1998\n",
            "Epoch 875/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3180 - onoff_loss: 0.0237 - note_loss: 0.1579 - vel_loss: 0.0143 - time_loss: 1.2204e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9631 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1799\n",
            "Epoch 876/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2999 - onoff_loss: 0.0238 - note_loss: 0.1558 - vel_loss: 0.0142 - time_loss: 1.0604e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9631 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 877/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4077 - onoff_loss: 0.0282 - note_loss: 0.1663 - vel_loss: 0.0148 - time_loss: 1.9847e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9603 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 878/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3210 - onoff_loss: 0.0250 - note_loss: 0.1599 - vel_loss: 0.0153 - time_loss: 1.2084e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9625 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1798\n",
            "Epoch 879/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3197 - onoff_loss: 0.0266 - note_loss: 0.1657 - vel_loss: 0.0140 - time_loss: 1.1338e-04 - onoff_accuracy: 0.9896 - note_accuracy: 0.9603 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 880/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.4034 - onoff_loss: 0.0458 - note_loss: 0.2239 - vel_loss: 0.0148 - time_loss: 1.1896e-04 - onoff_accuracy: 0.9828 - note_accuracy: 0.9441 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1865\n",
            "Epoch 881/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2978 - onoff_loss: 0.0235 - note_loss: 0.1478 - vel_loss: 0.0129 - time_loss: 1.1354e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9650 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1544\n",
            "Epoch 882/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3305 - onoff_loss: 0.0231 - note_loss: 0.1515 - vel_loss: 0.0143 - time_loss: 1.4162e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9649 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1504\n",
            "Epoch 883/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3796 - onoff_loss: 0.0383 - note_loss: 0.1947 - vel_loss: 0.0143 - time_loss: 1.3231e-04 - onoff_accuracy: 0.9846 - note_accuracy: 0.9517 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1733\n",
            "Epoch 884/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3000 - onoff_loss: 0.0238 - note_loss: 0.1571 - vel_loss: 0.0148 - time_loss: 1.0434e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9625 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 885/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2968 - onoff_loss: 0.0241 - note_loss: 0.1507 - vel_loss: 0.0147 - time_loss: 1.0728e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9641 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1690\n",
            "Epoch 886/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3327 - onoff_loss: 0.0231 - note_loss: 0.1543 - vel_loss: 0.0144 - time_loss: 1.4095e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9628 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1790\n",
            "Epoch 887/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3193 - onoff_loss: 0.0235 - note_loss: 0.1470 - vel_loss: 0.0151 - time_loss: 1.3377e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9661 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 888/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3002 - onoff_loss: 0.0244 - note_loss: 0.1571 - vel_loss: 0.0135 - time_loss: 1.0516e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9626 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1676\n",
            "Epoch 889/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3622 - onoff_loss: 0.0255 - note_loss: 0.1556 - vel_loss: 0.0144 - time_loss: 1.6662e-04 - onoff_accuracy: 0.9886 - note_accuracy: 0.9633 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1705\n",
            "Epoch 890/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3676 - onoff_loss: 0.0328 - note_loss: 0.1937 - vel_loss: 0.0146 - time_loss: 1.2650e-04 - onoff_accuracy: 0.9866 - note_accuracy: 0.9522 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1737\n",
            "Epoch 891/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3327 - onoff_loss: 0.0244 - note_loss: 0.1527 - vel_loss: 0.0133 - time_loss: 1.4233e-04 - onoff_accuracy: 0.9889 - note_accuracy: 0.9631 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1536\n",
            "Epoch 892/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3076 - onoff_loss: 0.0225 - note_loss: 0.1440 - vel_loss: 0.0146 - time_loss: 1.2644e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9656 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 893/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2956 - onoff_loss: 0.0249 - note_loss: 0.1487 - vel_loss: 0.0134 - time_loss: 1.0863e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9642 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1851\n",
            "Epoch 894/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3591 - onoff_loss: 0.0237 - note_loss: 0.1630 - vel_loss: 0.0147 - time_loss: 1.5771e-04 - onoff_accuracy: 0.9896 - note_accuracy: 0.9605 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1655\n",
            "Epoch 895/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3733 - onoff_loss: 0.0261 - note_loss: 0.1800 - vel_loss: 0.0149 - time_loss: 1.5230e-04 - onoff_accuracy: 0.9884 - note_accuracy: 0.9558 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1803\n",
            "Epoch 896/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2957 - onoff_loss: 0.0227 - note_loss: 0.1523 - vel_loss: 0.0142 - time_loss: 1.0650e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1725\n",
            "Epoch 897/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3189 - onoff_loss: 0.0221 - note_loss: 0.1431 - vel_loss: 0.0134 - time_loss: 1.4026e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9655 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 898/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3157 - onoff_loss: 0.0270 - note_loss: 0.1671 - vel_loss: 0.0141 - time_loss: 1.0748e-04 - onoff_accuracy: 0.9882 - note_accuracy: 0.9602 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1832\n",
            "Epoch 899/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3144 - onoff_loss: 0.0260 - note_loss: 0.1534 - vel_loss: 0.0133 - time_loss: 1.2164e-04 - onoff_accuracy: 0.9887 - note_accuracy: 0.9633 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 900/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3010 - onoff_loss: 0.0247 - note_loss: 0.1549 - vel_loss: 0.0142 - time_loss: 1.0718e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9626 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 901/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3290 - onoff_loss: 0.0248 - note_loss: 0.1583 - vel_loss: 0.0135 - time_loss: 1.3243e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9624 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1684\n",
            "Epoch 902/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3397 - onoff_loss: 0.0257 - note_loss: 0.1627 - vel_loss: 0.0149 - time_loss: 1.3638e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9616 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 903/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3165 - onoff_loss: 0.0249 - note_loss: 0.1540 - vel_loss: 0.0142 - time_loss: 1.2345e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9638 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1632\n",
            "Epoch 904/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4353 - onoff_loss: 0.0873 - note_loss: 0.2162 - vel_loss: 0.0139 - time_loss: 1.1793e-04 - onoff_accuracy: 0.9682 - note_accuracy: 0.9441 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 905/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3046 - onoff_loss: 0.0240 - note_loss: 0.1436 - vel_loss: 0.0134 - time_loss: 1.2358e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9651 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1606\n",
            "Epoch 906/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3429 - onoff_loss: 0.0247 - note_loss: 0.1494 - vel_loss: 0.0149 - time_loss: 1.5383e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1665\n",
            "Epoch 907/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3090 - onoff_loss: 0.0240 - note_loss: 0.1516 - vel_loss: 0.0150 - time_loss: 1.1833e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9639 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1840\n",
            "Epoch 908/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3151 - onoff_loss: 0.0226 - note_loss: 0.1500 - vel_loss: 0.0136 - time_loss: 1.2891e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9644 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1667\n",
            "Epoch 909/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2997 - onoff_loss: 0.0221 - note_loss: 0.1512 - vel_loss: 0.0133 - time_loss: 1.1314e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 910/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3334 - onoff_loss: 0.0242 - note_loss: 0.1495 - vel_loss: 0.0143 - time_loss: 1.4532e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9647 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 911/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3309 - onoff_loss: 0.0276 - note_loss: 0.1626 - vel_loss: 0.0143 - time_loss: 1.2639e-04 - onoff_accuracy: 0.9880 - note_accuracy: 0.9621 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1739\n",
            "Epoch 912/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3039 - onoff_loss: 0.0264 - note_loss: 0.1511 - vel_loss: 0.0144 - time_loss: 1.1196e-04 - onoff_accuracy: 0.9887 - note_accuracy: 0.9639 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 913/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3015 - onoff_loss: 0.0238 - note_loss: 0.1517 - vel_loss: 0.0142 - time_loss: 1.1176e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9644 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 914/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2857 - onoff_loss: 0.0227 - note_loss: 0.1482 - vel_loss: 0.0137 - time_loss: 1.0102e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9642 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1800\n",
            "Epoch 915/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3120 - onoff_loss: 0.0223 - note_loss: 0.1454 - vel_loss: 0.0141 - time_loss: 1.3010e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9653 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1820\n",
            "Epoch 916/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3370 - onoff_loss: 0.0232 - note_loss: 0.1509 - vel_loss: 0.0137 - time_loss: 1.4914e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9638 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 917/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3102 - onoff_loss: 0.0251 - note_loss: 0.1526 - vel_loss: 0.0139 - time_loss: 1.1856e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9640 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 918/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3037 - onoff_loss: 0.0268 - note_loss: 0.1522 - vel_loss: 0.0145 - time_loss: 1.1018e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9639 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1806\n",
            "Epoch 919/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3421 - onoff_loss: 0.0249 - note_loss: 0.1683 - vel_loss: 0.0155 - time_loss: 1.3338e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9609 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1701\n",
            "Epoch 920/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3221 - onoff_loss: 0.0226 - note_loss: 0.1544 - vel_loss: 0.0147 - time_loss: 1.3046e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9636 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 921/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3049 - onoff_loss: 0.0238 - note_loss: 0.1561 - vel_loss: 0.0145 - time_loss: 1.1056e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9624 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1822\n",
            "Epoch 922/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2872 - onoff_loss: 0.0233 - note_loss: 0.1431 - vel_loss: 0.0143 - time_loss: 1.0653e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9655 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2077\n",
            "Epoch 923/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2957 - onoff_loss: 0.0241 - note_loss: 0.1537 - vel_loss: 0.0138 - time_loss: 1.0404e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 924/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3608 - onoff_loss: 0.0249 - note_loss: 0.1504 - vel_loss: 0.0146 - time_loss: 1.7089e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1788\n",
            "Epoch 925/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3001 - onoff_loss: 0.0231 - note_loss: 0.1417 - vel_loss: 0.0142 - time_loss: 1.2113e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9653 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1683\n",
            "Epoch 926/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3510 - onoff_loss: 0.0473 - note_loss: 0.1848 - vel_loss: 0.0144 - time_loss: 1.0452e-04 - onoff_accuracy: 0.9812 - note_accuracy: 0.9545 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1911\n",
            "Epoch 927/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2850 - onoff_loss: 0.0229 - note_loss: 0.1466 - vel_loss: 0.0140 - time_loss: 1.0155e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9654 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 928/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2953 - onoff_loss: 0.0209 - note_loss: 0.1449 - vel_loss: 0.0147 - time_loss: 1.1479e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9647 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1851\n",
            "Epoch 929/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3108 - onoff_loss: 0.0218 - note_loss: 0.1497 - vel_loss: 0.0143 - time_loss: 1.2500e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9642 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1911\n",
            "Epoch 930/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3876 - onoff_loss: 0.0297 - note_loss: 0.2356 - vel_loss: 0.0142 - time_loss: 1.0804e-04 - onoff_accuracy: 0.9875 - note_accuracy: 0.9391 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1607\n",
            "Epoch 931/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3272 - onoff_loss: 0.0218 - note_loss: 0.1370 - vel_loss: 0.0145 - time_loss: 1.5394e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9661 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1771\n",
            "Epoch 932/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2898 - onoff_loss: 0.0233 - note_loss: 0.1485 - vel_loss: 0.0140 - time_loss: 1.0399e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9643 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1624\n",
            "Epoch 933/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2987 - onoff_loss: 0.0232 - note_loss: 0.1401 - vel_loss: 0.0142 - time_loss: 1.2122e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9657 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1746\n",
            "Epoch 934/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3039 - onoff_loss: 0.0225 - note_loss: 0.1487 - vel_loss: 0.0138 - time_loss: 1.1881e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9654 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 935/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3288 - onoff_loss: 0.0233 - note_loss: 0.1522 - vel_loss: 0.0146 - time_loss: 1.3878e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9637 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2023\n",
            "Epoch 936/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3115 - onoff_loss: 0.0221 - note_loss: 0.1486 - vel_loss: 0.0151 - time_loss: 1.2571e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9652 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1628\n",
            "Epoch 937/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2960 - onoff_loss: 0.0242 - note_loss: 0.1469 - vel_loss: 0.0140 - time_loss: 1.1084e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9647 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1636\n",
            "Epoch 938/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2815 - onoff_loss: 0.0237 - note_loss: 0.1419 - vel_loss: 0.0142 - time_loss: 1.0176e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9650 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 939/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3472 - onoff_loss: 0.0265 - note_loss: 0.1768 - vel_loss: 0.0145 - time_loss: 1.2936e-04 - onoff_accuracy: 0.9884 - note_accuracy: 0.9562 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 940/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3336 - onoff_loss: 0.0263 - note_loss: 0.1677 - vel_loss: 0.0141 - time_loss: 1.2556e-04 - onoff_accuracy: 0.9883 - note_accuracy: 0.9595 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1645\n",
            "Epoch 941/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3262 - onoff_loss: 0.0231 - note_loss: 0.1437 - vel_loss: 0.0142 - time_loss: 1.4526e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9659 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1569\n",
            "Epoch 942/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2823 - onoff_loss: 0.0222 - note_loss: 0.1393 - vel_loss: 0.0135 - time_loss: 1.0729e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9654 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1767\n",
            "Epoch 943/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2845 - onoff_loss: 0.0227 - note_loss: 0.1421 - vel_loss: 0.0152 - time_loss: 1.0448e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9655 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1817\n",
            "Epoch 944/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2985 - onoff_loss: 0.0249 - note_loss: 0.1515 - vel_loss: 0.0139 - time_loss: 1.0815e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9635 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1631\n",
            "Epoch 945/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2767 - onoff_loss: 0.0223 - note_loss: 0.1432 - vel_loss: 0.0140 - time_loss: 9.7365e-05 - onoff_accuracy: 0.9898 - note_accuracy: 0.9652 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1948\n",
            "Epoch 946/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3474 - onoff_loss: 0.0244 - note_loss: 0.1587 - vel_loss: 0.0145 - time_loss: 1.4976e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9614 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1742\n",
            "Epoch 947/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2886 - onoff_loss: 0.0226 - note_loss: 0.1482 - vel_loss: 0.0139 - time_loss: 1.0389e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9636 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 948/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2655 - onoff_loss: 0.0212 - note_loss: 0.1379 - vel_loss: 0.0142 - time_loss: 9.2181e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9665 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1974\n",
            "Epoch 949/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3448 - onoff_loss: 0.0237 - note_loss: 0.1557 - vel_loss: 0.0137 - time_loss: 1.5174e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9629 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 950/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2791 - onoff_loss: 0.0232 - note_loss: 0.1458 - vel_loss: 0.0137 - time_loss: 9.6272e-05 - onoff_accuracy: 0.9895 - note_accuracy: 0.9651 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 951/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3053 - onoff_loss: 0.0220 - note_loss: 0.1443 - vel_loss: 0.0142 - time_loss: 1.2476e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9647 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 952/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3093 - onoff_loss: 0.0253 - note_loss: 0.1538 - vel_loss: 0.0134 - time_loss: 1.1683e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9628 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1791\n",
            "Epoch 953/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3123 - onoff_loss: 0.0252 - note_loss: 0.1512 - vel_loss: 0.0137 - time_loss: 1.2229e-04 - onoff_accuracy: 0.9888 - note_accuracy: 0.9636 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1558\n",
            "Epoch 954/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2781 - onoff_loss: 0.0241 - note_loss: 0.1405 - vel_loss: 0.0136 - time_loss: 9.9916e-05 - onoff_accuracy: 0.9900 - note_accuracy: 0.9662 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 955/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3181 - onoff_loss: 0.0244 - note_loss: 0.1433 - vel_loss: 0.0135 - time_loss: 1.3684e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9660 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1613\n",
            "Epoch 956/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2858 - onoff_loss: 0.0224 - note_loss: 0.1406 - vel_loss: 0.0140 - time_loss: 1.0888e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9656 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1525\n",
            "Epoch 957/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3213 - onoff_loss: 0.0260 - note_loss: 0.1549 - vel_loss: 0.0140 - time_loss: 1.2629e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9617 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1601\n",
            "Epoch 958/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2712 - onoff_loss: 0.0223 - note_loss: 0.1339 - vel_loss: 0.0140 - time_loss: 1.0102e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9668 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1691\n",
            "Epoch 959/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2876 - onoff_loss: 0.0240 - note_loss: 0.1459 - vel_loss: 0.0139 - time_loss: 1.0366e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9647 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 960/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3076 - onoff_loss: 0.0231 - note_loss: 0.1472 - vel_loss: 0.0138 - time_loss: 1.2348e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9645 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1789\n",
            "Epoch 961/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2789 - onoff_loss: 0.0196 - note_loss: 0.1426 - vel_loss: 0.0141 - time_loss: 1.0260e-04 - onoff_accuracy: 0.9909 - note_accuracy: 0.9652 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1966\n",
            "Epoch 962/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2925 - onoff_loss: 0.0244 - note_loss: 0.1414 - vel_loss: 0.0132 - time_loss: 1.1344e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9654 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1541\n",
            "Epoch 963/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3027 - onoff_loss: 0.0303 - note_loss: 0.1739 - vel_loss: 0.0128 - time_loss: 8.5632e-05 - onoff_accuracy: 0.9877 - note_accuracy: 0.9580 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1641\n",
            "Epoch 964/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3036 - onoff_loss: 0.0222 - note_loss: 0.1473 - vel_loss: 0.0145 - time_loss: 1.1957e-04 - onoff_accuracy: 0.9896 - note_accuracy: 0.9648 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 965/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2685 - onoff_loss: 0.0217 - note_loss: 0.1330 - vel_loss: 0.0129 - time_loss: 1.0085e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9668 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1689\n",
            "Epoch 966/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3084 - onoff_loss: 0.0236 - note_loss: 0.1477 - vel_loss: 0.0134 - time_loss: 1.2360e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9649 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1671\n",
            "Epoch 967/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2753 - onoff_loss: 0.0219 - note_loss: 0.1421 - vel_loss: 0.0140 - time_loss: 9.7336e-05 - onoff_accuracy: 0.9897 - note_accuracy: 0.9658 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 968/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2765 - onoff_loss: 0.0225 - note_loss: 0.1435 - vel_loss: 0.0140 - time_loss: 9.6473e-05 - onoff_accuracy: 0.9898 - note_accuracy: 0.9652 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 969/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3264 - onoff_loss: 0.0288 - note_loss: 0.1722 - vel_loss: 0.0136 - time_loss: 1.1183e-04 - onoff_accuracy: 0.9881 - note_accuracy: 0.9570 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2051\n",
            "Epoch 970/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3141 - onoff_loss: 0.0262 - note_loss: 0.1516 - vel_loss: 0.0140 - time_loss: 1.2227e-04 - onoff_accuracy: 0.9885 - note_accuracy: 0.9633 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1571\n",
            "Epoch 971/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.2868 - onoff_loss: 0.0222 - note_loss: 0.1353 - vel_loss: 0.0133 - time_loss: 1.1600e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9663 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1655\n",
            "Epoch 972/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2819 - onoff_loss: 0.0236 - note_loss: 0.1372 - vel_loss: 0.0137 - time_loss: 1.0734e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9664 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1719\n",
            "Epoch 973/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2896 - onoff_loss: 0.0238 - note_loss: 0.1410 - vel_loss: 0.0131 - time_loss: 1.1170e-04 - onoff_accuracy: 0.9890 - note_accuracy: 0.9662 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1697\n",
            "Epoch 974/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3170 - onoff_loss: 0.0218 - note_loss: 0.1415 - vel_loss: 0.0132 - time_loss: 1.4049e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9666 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1643\n",
            "Epoch 975/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3052 - onoff_loss: 0.0196 - note_loss: 0.1387 - vel_loss: 0.0141 - time_loss: 1.3278e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9669 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1842\n",
            "Epoch 976/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3191 - onoff_loss: 0.0232 - note_loss: 0.1686 - vel_loss: 0.0144 - time_loss: 1.1296e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9586 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1901\n",
            "Epoch 977/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3164 - onoff_loss: 0.0203 - note_loss: 0.1323 - vel_loss: 0.0139 - time_loss: 1.5001e-04 - onoff_accuracy: 0.9907 - note_accuracy: 0.9676 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 978/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3000 - onoff_loss: 0.0230 - note_loss: 0.1417 - vel_loss: 0.0135 - time_loss: 1.2170e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9661 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1651\n",
            "Epoch 979/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3419 - onoff_loss: 0.0449 - note_loss: 0.1738 - vel_loss: 0.0136 - time_loss: 1.0968e-04 - onoff_accuracy: 0.9828 - note_accuracy: 0.9556 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1680\n",
            "Epoch 980/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2928 - onoff_loss: 0.0252 - note_loss: 0.1396 - vel_loss: 0.0134 - time_loss: 1.1455e-04 - onoff_accuracy: 0.9892 - note_accuracy: 0.9661 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 981/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2599 - onoff_loss: 0.0201 - note_loss: 0.1342 - vel_loss: 0.0142 - time_loss: 9.1421e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9673 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823\n",
            "Epoch 982/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3088 - onoff_loss: 0.0229 - note_loss: 0.1428 - vel_loss: 0.0131 - time_loss: 1.2991e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9656 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 983/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2754 - onoff_loss: 0.0216 - note_loss: 0.1390 - vel_loss: 0.0133 - time_loss: 1.0147e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9657 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1742\n",
            "Epoch 984/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2860 - onoff_loss: 0.0237 - note_loss: 0.1379 - vel_loss: 0.0123 - time_loss: 1.1217e-04 - onoff_accuracy: 0.9896 - note_accuracy: 0.9655 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1539\n",
            "Epoch 985/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2828 - onoff_loss: 0.0215 - note_loss: 0.1355 - vel_loss: 0.0144 - time_loss: 1.1141e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 986/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2825 - onoff_loss: 0.0221 - note_loss: 0.1416 - vel_loss: 0.0135 - time_loss: 1.0523e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9653 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1794\n",
            "Epoch 987/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2908 - onoff_loss: 0.0223 - note_loss: 0.1481 - vel_loss: 0.0134 - time_loss: 1.0694e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9638 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 988/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2968 - onoff_loss: 0.0212 - note_loss: 0.1375 - vel_loss: 0.0134 - time_loss: 1.2469e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9665 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1964\n",
            "Epoch 989/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3000 - onoff_loss: 0.0229 - note_loss: 0.1477 - vel_loss: 0.0138 - time_loss: 1.1565e-04 - onoff_accuracy: 0.9895 - note_accuracy: 0.9638 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1753\n",
            "Epoch 990/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2771 - onoff_loss: 0.0214 - note_loss: 0.1322 - vel_loss: 0.0125 - time_loss: 1.1098e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1540\n",
            "Epoch 991/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2599 - onoff_loss: 0.0209 - note_loss: 0.1345 - vel_loss: 0.0134 - time_loss: 9.1146e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9667 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 992/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3455 - onoff_loss: 0.0286 - note_loss: 0.1778 - vel_loss: 0.0141 - time_loss: 1.2510e-04 - onoff_accuracy: 0.9879 - note_accuracy: 0.9567 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 993/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2787 - onoff_loss: 0.0205 - note_loss: 0.1264 - vel_loss: 0.0127 - time_loss: 1.1901e-04 - onoff_accuracy: 0.9907 - note_accuracy: 0.9687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1638\n",
            "Epoch 994/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2839 - onoff_loss: 0.0213 - note_loss: 0.1363 - vel_loss: 0.0127 - time_loss: 1.1372e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9670 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1521\n",
            "Epoch 995/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2842 - onoff_loss: 0.0222 - note_loss: 0.1361 - vel_loss: 0.0131 - time_loss: 1.1278e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9661 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1690\n",
            "Epoch 996/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2638 - onoff_loss: 0.0226 - note_loss: 0.1302 - vel_loss: 0.0128 - time_loss: 9.8245e-05 - onoff_accuracy: 0.9902 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1459\n",
            "Epoch 997/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3096 - onoff_loss: 0.0239 - note_loss: 0.1429 - vel_loss: 0.0137 - time_loss: 1.2916e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9658 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1665\n",
            "Epoch 998/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2673 - onoff_loss: 0.0210 - note_loss: 0.1332 - vel_loss: 0.0134 - time_loss: 9.9691e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 999/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3621 - onoff_loss: 0.0240 - note_loss: 0.1668 - vel_loss: 0.0134 - time_loss: 1.5792e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9597 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 1000/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2706 - onoff_loss: 0.0230 - note_loss: 0.1394 - vel_loss: 0.0131 - time_loss: 9.5051e-05 - onoff_accuracy: 0.9896 - note_accuracy: 0.9665 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1661\n",
            "Epoch 1001/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3036 - onoff_loss: 0.0223 - note_loss: 0.1366 - vel_loss: 0.0134 - time_loss: 1.3144e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9670 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 1002/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2859 - onoff_loss: 0.0215 - note_loss: 0.1332 - vel_loss: 0.0134 - time_loss: 1.1786e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9676 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 1003/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2633 - onoff_loss: 0.0201 - note_loss: 0.1326 - vel_loss: 0.0134 - time_loss: 9.7160e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1835\n",
            "Epoch 1004/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3024 - onoff_loss: 0.0212 - note_loss: 0.1336 - vel_loss: 0.0134 - time_loss: 1.3421e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9673 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1837\n",
            "Epoch 1005/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2917 - onoff_loss: 0.0239 - note_loss: 0.1424 - vel_loss: 0.0132 - time_loss: 1.1216e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9653 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1573\n",
            "Epoch 1006/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3425 - onoff_loss: 0.0358 - note_loss: 0.1759 - vel_loss: 0.0139 - time_loss: 1.1686e-04 - onoff_accuracy: 0.9847 - note_accuracy: 0.9553 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1628\n",
            "Epoch 1007/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2845 - onoff_loss: 0.0194 - note_loss: 0.1298 - vel_loss: 0.0138 - time_loss: 1.2145e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 1008/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2625 - onoff_loss: 0.0198 - note_loss: 0.1267 - vel_loss: 0.0131 - time_loss: 1.0291e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9683 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1859\n",
            "Epoch 1009/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3227 - onoff_loss: 0.0227 - note_loss: 0.1440 - vel_loss: 0.0143 - time_loss: 1.4175e-04 - onoff_accuracy: 0.9896 - note_accuracy: 0.9652 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823\n",
            "Epoch 1010/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2631 - onoff_loss: 0.0207 - note_loss: 0.1325 - vel_loss: 0.0132 - time_loss: 9.6758e-05 - onoff_accuracy: 0.9903 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1779\n",
            "Epoch 1011/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3002 - onoff_loss: 0.0212 - note_loss: 0.1321 - vel_loss: 0.0141 - time_loss: 1.3284e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9669 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 1012/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2660 - onoff_loss: 0.0219 - note_loss: 0.1325 - vel_loss: 0.0133 - time_loss: 9.8235e-05 - onoff_accuracy: 0.9897 - note_accuracy: 0.9673 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1821\n",
            "Epoch 1013/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3170 - onoff_loss: 0.0244 - note_loss: 0.1458 - vel_loss: 0.0135 - time_loss: 1.3330e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9634 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1773\n",
            "Epoch 1014/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2631 - onoff_loss: 0.0217 - note_loss: 0.1341 - vel_loss: 0.0138 - time_loss: 9.3525e-05 - onoff_accuracy: 0.9903 - note_accuracy: 0.9657 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1816\n",
            "Epoch 1015/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3290 - onoff_loss: 0.0218 - note_loss: 0.1481 - vel_loss: 0.0134 - time_loss: 1.4573e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9641 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 1016/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2728 - onoff_loss: 0.0207 - note_loss: 0.1304 - vel_loss: 0.0129 - time_loss: 1.0890e-04 - onoff_accuracy: 0.9909 - note_accuracy: 0.9675 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 1017/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2489 - onoff_loss: 0.0205 - note_loss: 0.1312 - vel_loss: 0.0131 - time_loss: 8.4119e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9680 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 1018/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3113 - onoff_loss: 0.0241 - note_loss: 0.1448 - vel_loss: 0.0131 - time_loss: 1.2933e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9653 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 1019/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2987 - onoff_loss: 0.0236 - note_loss: 0.1306 - vel_loss: 0.0131 - time_loss: 1.3136e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 1020/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2782 - onoff_loss: 0.0227 - note_loss: 0.1347 - vel_loss: 0.0133 - time_loss: 1.0748e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9664 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 1021/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2992 - onoff_loss: 0.0202 - note_loss: 0.1322 - vel_loss: 0.0134 - time_loss: 1.3338e-04 - onoff_accuracy: 0.9909 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1686\n",
            "Epoch 1022/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2709 - onoff_loss: 0.0225 - note_loss: 0.1392 - vel_loss: 0.0131 - time_loss: 9.6105e-05 - onoff_accuracy: 0.9899 - note_accuracy: 0.9654 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1827\n",
            "Epoch 1023/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2847 - onoff_loss: 0.0205 - note_loss: 0.1373 - vel_loss: 0.0125 - time_loss: 1.1435e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9663 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1825\n",
            "Epoch 1024/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2531 - onoff_loss: 0.0194 - note_loss: 0.1262 - vel_loss: 0.0130 - time_loss: 9.4475e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9685 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1846\n",
            "Epoch 1025/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2669 - onoff_loss: 0.0206 - note_loss: 0.1304 - vel_loss: 0.0138 - time_loss: 1.0207e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9675 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1857\n",
            "Epoch 1026/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2622 - onoff_loss: 0.0217 - note_loss: 0.1318 - vel_loss: 0.0127 - time_loss: 9.5936e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9676 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1630\n",
            "Epoch 1027/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3175 - onoff_loss: 0.0211 - note_loss: 0.1354 - vel_loss: 0.0135 - time_loss: 1.4754e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9668 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 1028/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2715 - onoff_loss: 0.0214 - note_loss: 0.1271 - vel_loss: 0.0122 - time_loss: 1.1085e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1609\n",
            "Epoch 1029/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3178 - onoff_loss: 0.0237 - note_loss: 0.1394 - vel_loss: 0.0129 - time_loss: 1.4193e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9664 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1614\n",
            "Epoch 1030/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2508 - onoff_loss: 0.0214 - note_loss: 0.1258 - vel_loss: 0.0134 - time_loss: 9.0192e-05 - onoff_accuracy: 0.9900 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1705\n",
            "Epoch 1031/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3297 - onoff_loss: 0.0234 - note_loss: 0.1703 - vel_loss: 0.0129 - time_loss: 1.2304e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9568 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 1032/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2518 - onoff_loss: 0.0206 - note_loss: 0.1334 - vel_loss: 0.0131 - time_loss: 8.4722e-05 - onoff_accuracy: 0.9902 - note_accuracy: 0.9672 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1033/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2880 - onoff_loss: 0.0205 - note_loss: 0.1239 - vel_loss: 0.0136 - time_loss: 1.3008e-04 - onoff_accuracy: 0.9909 - note_accuracy: 0.9690 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1783\n",
            "Epoch 1034/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2974 - onoff_loss: 0.0251 - note_loss: 0.1541 - vel_loss: 0.0131 - time_loss: 1.0517e-04 - onoff_accuracy: 0.9894 - note_accuracy: 0.9627 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 1035/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2705 - onoff_loss: 0.0208 - note_loss: 0.1450 - vel_loss: 0.0132 - time_loss: 9.1620e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9642 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 1036/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2617 - onoff_loss: 0.0210 - note_loss: 0.1264 - vel_loss: 0.0133 - time_loss: 1.0095e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1876\n",
            "Epoch 1037/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2687 - onoff_loss: 0.0193 - note_loss: 0.1253 - vel_loss: 0.0135 - time_loss: 1.1064e-04 - onoff_accuracy: 0.9912 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1873\n",
            "Epoch 1038/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2582 - onoff_loss: 0.0201 - note_loss: 0.1296 - vel_loss: 0.0135 - time_loss: 9.5014e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9676 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1890\n",
            "Epoch 1039/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2849 - onoff_loss: 0.0220 - note_loss: 0.1361 - vel_loss: 0.0130 - time_loss: 1.1384e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9665 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 1040/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2553 - onoff_loss: 0.0218 - note_loss: 0.1264 - vel_loss: 0.0129 - time_loss: 9.4174e-05 - onoff_accuracy: 0.9902 - note_accuracy: 0.9679 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1041/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3014 - onoff_loss: 0.0222 - note_loss: 0.1378 - vel_loss: 0.0130 - time_loss: 1.2839e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9665 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1732\n",
            "Epoch 1042/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2609 - onoff_loss: 0.0207 - note_loss: 0.1290 - vel_loss: 0.0127 - time_loss: 9.8532e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1825\n",
            "Epoch 1043/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2738 - onoff_loss: 0.0231 - note_loss: 0.1373 - vel_loss: 0.0123 - time_loss: 1.0118e-04 - onoff_accuracy: 0.9893 - note_accuracy: 0.9661 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1582\n",
            "Epoch 1044/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2820 - onoff_loss: 0.0233 - note_loss: 0.1363 - vel_loss: 0.0135 - time_loss: 1.0887e-04 - onoff_accuracy: 0.9891 - note_accuracy: 0.9666 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1807\n",
            "Epoch 1045/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2504 - onoff_loss: 0.0201 - note_loss: 0.1279 - vel_loss: 0.0128 - time_loss: 8.9540e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1652\n",
            "Epoch 1046/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2910 - onoff_loss: 0.0207 - note_loss: 0.1292 - vel_loss: 0.0132 - time_loss: 1.2787e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9679 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 1047/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2318 - onoff_loss: 0.0201 - note_loss: 0.1194 - vel_loss: 0.0121 - time_loss: 8.0178e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1048/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2696 - onoff_loss: 0.0218 - note_loss: 0.1347 - vel_loss: 0.0133 - time_loss: 9.9867e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9674 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1704\n",
            "Epoch 1049/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2784 - onoff_loss: 0.0203 - note_loss: 0.1234 - vel_loss: 0.0132 - time_loss: 1.2152e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9685 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1867\n",
            "Epoch 1050/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2900 - onoff_loss: 0.0238 - note_loss: 0.1576 - vel_loss: 0.0137 - time_loss: 9.4829e-05 - onoff_accuracy: 0.9893 - note_accuracy: 0.9603 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 1051/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2753 - onoff_loss: 0.0212 - note_loss: 0.1325 - vel_loss: 0.0129 - time_loss: 1.0866e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9672 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1831\n",
            "Epoch 1052/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2647 - onoff_loss: 0.0195 - note_loss: 0.1282 - vel_loss: 0.0140 - time_loss: 1.0310e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9677 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2026\n",
            "Epoch 1053/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2406 - onoff_loss: 0.0222 - note_loss: 0.1307 - vel_loss: 0.0120 - time_loss: 7.5768e-05 - onoff_accuracy: 0.9900 - note_accuracy: 0.9681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 1054/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2576 - onoff_loss: 0.0207 - note_loss: 0.1241 - vel_loss: 0.0120 - time_loss: 1.0076e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9695 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 1055/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2528 - onoff_loss: 0.0201 - note_loss: 0.1237 - vel_loss: 0.0132 - time_loss: 9.5795e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9697 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1764\n",
            "Epoch 1056/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2881 - onoff_loss: 0.0199 - note_loss: 0.1345 - vel_loss: 0.0139 - time_loss: 1.1990e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9675 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1973\n",
            "Epoch 1057/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2496 - onoff_loss: 0.0207 - note_loss: 0.1268 - vel_loss: 0.0122 - time_loss: 8.9841e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1718\n",
            "Epoch 1058/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2786 - onoff_loss: 0.0216 - note_loss: 0.1299 - vel_loss: 0.0121 - time_loss: 1.1512e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9677 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1678\n",
            "Epoch 1059/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2781 - onoff_loss: 0.0211 - note_loss: 0.1319 - vel_loss: 0.0134 - time_loss: 1.1174e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 1060/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3189 - onoff_loss: 0.0418 - note_loss: 0.1593 - vel_loss: 0.0129 - time_loss: 1.0498e-04 - onoff_accuracy: 0.9832 - note_accuracy: 0.9595 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1769\n",
            "Epoch 1061/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2483 - onoff_loss: 0.0219 - note_loss: 0.1287 - vel_loss: 0.0122 - time_loss: 8.5502e-05 - onoff_accuracy: 0.9900 - note_accuracy: 0.9680 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1909\n",
            "Epoch 1062/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2449 - onoff_loss: 0.0188 - note_loss: 0.1193 - vel_loss: 0.0132 - time_loss: 9.3616e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9709 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1877\n",
            "Epoch 1063/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2788 - onoff_loss: 0.0209 - note_loss: 0.1296 - vel_loss: 0.0134 - time_loss: 1.1495e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1833\n",
            "Epoch 1064/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2995 - onoff_loss: 0.0221 - note_loss: 0.1337 - vel_loss: 0.0134 - time_loss: 1.3032e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9672 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1862\n",
            "Epoch 1065/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2685 - onoff_loss: 0.0212 - note_loss: 0.1323 - vel_loss: 0.0134 - time_loss: 1.0164e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9675 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 1066/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2818 - onoff_loss: 0.0196 - note_loss: 0.1273 - vel_loss: 0.0126 - time_loss: 1.2224e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1718\n",
            "Epoch 1067/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2518 - onoff_loss: 0.0202 - note_loss: 0.1278 - vel_loss: 0.0132 - time_loss: 9.0670e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1685\n",
            "Epoch 1068/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2851 - onoff_loss: 0.0204 - note_loss: 0.1397 - vel_loss: 0.0133 - time_loss: 1.1165e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9655 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1865\n",
            "Epoch 1069/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2710 - onoff_loss: 0.0214 - note_loss: 0.1234 - vel_loss: 0.0132 - time_loss: 1.1304e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9685 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 1070/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2576 - onoff_loss: 0.0216 - note_loss: 0.1313 - vel_loss: 0.0132 - time_loss: 9.1478e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9679 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 1071/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2931 - onoff_loss: 0.0216 - note_loss: 0.1355 - vel_loss: 0.0127 - time_loss: 1.2324e-04 - onoff_accuracy: 0.9900 - note_accuracy: 0.9668 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1575\n",
            "Epoch 1072/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2530 - onoff_loss: 0.0193 - note_loss: 0.1266 - vel_loss: 0.0124 - time_loss: 9.4664e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9691 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 1073/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2746 - onoff_loss: 0.0215 - note_loss: 0.1276 - vel_loss: 0.0131 - time_loss: 1.1251e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 1074/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2612 - onoff_loss: 0.0232 - note_loss: 0.1287 - vel_loss: 0.0121 - time_loss: 9.7182e-05 - onoff_accuracy: 0.9900 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1626\n",
            "Epoch 1075/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2616 - onoff_loss: 0.0213 - note_loss: 0.1312 - vel_loss: 0.0125 - time_loss: 9.6666e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9675 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1788\n",
            "Epoch 1076/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2775 - onoff_loss: 0.0219 - note_loss: 0.1270 - vel_loss: 0.0128 - time_loss: 1.1585e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 1077/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2569 - onoff_loss: 0.0217 - note_loss: 0.1324 - vel_loss: 0.0124 - time_loss: 9.0347e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1584\n",
            "Epoch 1078/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2440 - onoff_loss: 0.0203 - note_loss: 0.1316 - vel_loss: 0.0133 - time_loss: 7.8762e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9677 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 1079/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2749 - onoff_loss: 0.0201 - note_loss: 0.1243 - vel_loss: 0.0123 - time_loss: 1.1823e-04 - onoff_accuracy: 0.9907 - note_accuracy: 0.9697 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 1080/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2642 - onoff_loss: 0.0201 - note_loss: 0.1298 - vel_loss: 0.0138 - time_loss: 1.0057e-04 - onoff_accuracy: 0.9909 - note_accuracy: 0.9680 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2017\n",
            "Epoch 1081/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2673 - onoff_loss: 0.0196 - note_loss: 0.1296 - vel_loss: 0.0123 - time_loss: 1.0579e-04 - onoff_accuracy: 0.9914 - note_accuracy: 0.9687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 1082/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2591 - onoff_loss: 0.0202 - note_loss: 0.1267 - vel_loss: 0.0125 - time_loss: 9.9629e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9686 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1830\n",
            "Epoch 1083/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2687 - onoff_loss: 0.0201 - note_loss: 0.1254 - vel_loss: 0.0129 - time_loss: 1.1027e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9691 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1788\n",
            "Epoch 1084/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2610 - onoff_loss: 0.0194 - note_loss: 0.1215 - vel_loss: 0.0124 - time_loss: 1.0768e-04 - onoff_accuracy: 0.9912 - note_accuracy: 0.9699 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1969\n",
            "Epoch 1085/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2732 - onoff_loss: 0.0209 - note_loss: 0.1268 - vel_loss: 0.0130 - time_loss: 1.1248e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9680 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1659\n",
            "Epoch 1086/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2333 - onoff_loss: 0.0208 - note_loss: 0.1209 - vel_loss: 0.0115 - time_loss: 8.0035e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 1087/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3468 - onoff_loss: 0.0247 - note_loss: 0.1550 - vel_loss: 0.0130 - time_loss: 1.5404e-04 - onoff_accuracy: 0.9898 - note_accuracy: 0.9616 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1767\n",
            "Epoch 1088/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2485 - onoff_loss: 0.0210 - note_loss: 0.1238 - vel_loss: 0.0135 - time_loss: 9.0229e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9691 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 1089/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2552 - onoff_loss: 0.0205 - note_loss: 0.1251 - vel_loss: 0.0121 - time_loss: 9.7461e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 1090/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2751 - onoff_loss: 0.0195 - note_loss: 0.1288 - vel_loss: 0.0121 - time_loss: 1.1467e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9678 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1576\n",
            "Epoch 1091/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2812 - onoff_loss: 0.0221 - note_loss: 0.1323 - vel_loss: 0.0130 - time_loss: 1.1366e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1767\n",
            "Epoch 1092/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2587 - onoff_loss: 0.0196 - note_loss: 0.1247 - vel_loss: 0.0126 - time_loss: 1.0180e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1773\n",
            "Epoch 1093/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2619 - onoff_loss: 0.0202 - note_loss: 0.1270 - vel_loss: 0.0131 - time_loss: 1.0153e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 1094/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2384 - onoff_loss: 0.0213 - note_loss: 0.1255 - vel_loss: 0.0129 - time_loss: 7.8645e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9683 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1865\n",
            "Epoch 1095/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2706 - onoff_loss: 0.0243 - note_loss: 0.1347 - vel_loss: 0.0127 - time_loss: 9.8920e-05 - onoff_accuracy: 0.9897 - note_accuracy: 0.9662 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1849\n",
            "Epoch 1096/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2531 - onoff_loss: 0.0210 - note_loss: 0.1214 - vel_loss: 0.0127 - time_loss: 9.7930e-05 - onoff_accuracy: 0.9902 - note_accuracy: 0.9699 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1640\n",
            "Epoch 1097/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2735 - onoff_loss: 0.0216 - note_loss: 0.1339 - vel_loss: 0.0127 - time_loss: 1.0529e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9677 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1796\n",
            "Epoch 1098/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3203 - onoff_loss: 0.0192 - note_loss: 0.1311 - vel_loss: 0.0132 - time_loss: 1.5671e-04 - onoff_accuracy: 0.9907 - note_accuracy: 0.9675 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1664\n",
            "Epoch 1099/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2751 - onoff_loss: 0.0217 - note_loss: 0.1274 - vel_loss: 0.0126 - time_loss: 1.1352e-04 - onoff_accuracy: 0.9899 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 1100/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2666 - onoff_loss: 0.0198 - note_loss: 0.1218 - vel_loss: 0.0123 - time_loss: 1.1267e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9694 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1748\n",
            "Epoch 1101/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2823 - onoff_loss: 0.0203 - note_loss: 0.1237 - vel_loss: 0.0133 - time_loss: 1.2500e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9698 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1581\n",
            "Epoch 1102/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2480 - onoff_loss: 0.0199 - note_loss: 0.1208 - vel_loss: 0.0120 - time_loss: 9.5308e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9702 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1615\n",
            "Epoch 1103/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2534 - onoff_loss: 0.0207 - note_loss: 0.1300 - vel_loss: 0.0120 - time_loss: 9.0658e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9666 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1637\n",
            "Epoch 1104/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2896 - onoff_loss: 0.0198 - note_loss: 0.1256 - vel_loss: 0.0127 - time_loss: 1.3151e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9686 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1560\n",
            "Epoch 1105/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3116 - onoff_loss: 0.0283 - note_loss: 0.1675 - vel_loss: 0.0127 - time_loss: 1.0308e-04 - onoff_accuracy: 0.9884 - note_accuracy: 0.9599 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1796\n",
            "Epoch 1106/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2603 - onoff_loss: 0.0210 - note_loss: 0.1282 - vel_loss: 0.0121 - time_loss: 9.8934e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1738\n",
            "Epoch 1107/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2402 - onoff_loss: 0.0182 - note_loss: 0.1205 - vel_loss: 0.0116 - time_loss: 8.9902e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1658\n",
            "Epoch 1108/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2706 - onoff_loss: 0.0199 - note_loss: 0.1244 - vel_loss: 0.0125 - time_loss: 1.1376e-04 - onoff_accuracy: 0.9911 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1965\n",
            "Epoch 1109/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2419 - onoff_loss: 0.0191 - note_loss: 0.1185 - vel_loss: 0.0121 - time_loss: 9.2192e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9701 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1897\n",
            "Epoch 1110/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2425 - onoff_loss: 0.0194 - note_loss: 0.1207 - vel_loss: 0.0118 - time_loss: 9.0632e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 1111/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2595 - onoff_loss: 0.0185 - note_loss: 0.1215 - vel_loss: 0.0122 - time_loss: 1.0733e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9698 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1698\n",
            "Epoch 1112/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2596 - onoff_loss: 0.0198 - note_loss: 0.1220 - vel_loss: 0.0131 - time_loss: 1.0469e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9697 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1861\n",
            "Epoch 1113/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2418 - onoff_loss: 0.0187 - note_loss: 0.1215 - vel_loss: 0.0123 - time_loss: 8.9360e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9691 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 1114/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2699 - onoff_loss: 0.0222 - note_loss: 0.1257 - vel_loss: 0.0126 - time_loss: 1.0936e-04 - onoff_accuracy: 0.9897 - note_accuracy: 0.9683 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 1115/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2343 - onoff_loss: 0.0204 - note_loss: 0.1215 - vel_loss: 0.0119 - time_loss: 8.0514e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9698 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1782\n",
            "Epoch 1116/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2704 - onoff_loss: 0.0208 - note_loss: 0.1269 - vel_loss: 0.0125 - time_loss: 1.1025e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1925\n",
            "Epoch 1117/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2796 - onoff_loss: 0.0203 - note_loss: 0.1343 - vel_loss: 0.0128 - time_loss: 1.1224e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9666 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 1118/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2537 - onoff_loss: 0.0209 - note_loss: 0.1201 - vel_loss: 0.0126 - time_loss: 1.0001e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9695 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1647\n",
            "Epoch 1119/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2556 - onoff_loss: 0.0184 - note_loss: 0.1195 - vel_loss: 0.0121 - time_loss: 1.0563e-04 - onoff_accuracy: 0.9912 - note_accuracy: 0.9706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1120/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2599 - onoff_loss: 0.0200 - note_loss: 0.1276 - vel_loss: 0.0129 - time_loss: 9.9451e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9683 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1782\n",
            "Epoch 1121/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2273 - onoff_loss: 0.0195 - note_loss: 0.1154 - vel_loss: 0.0117 - time_loss: 8.0691e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 1122/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2849 - onoff_loss: 0.0186 - note_loss: 0.1294 - vel_loss: 0.0119 - time_loss: 1.2489e-04 - onoff_accuracy: 0.9911 - note_accuracy: 0.9685 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1845\n",
            "Epoch 1123/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.2561 - onoff_loss: 0.0209 - note_loss: 0.1218 - vel_loss: 0.0134 - time_loss: 1.0003e-04 - onoff_accuracy: 0.9902 - note_accuracy: 0.9693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1938\n",
            "Epoch 1124/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2459 - onoff_loss: 0.0198 - note_loss: 0.1226 - vel_loss: 0.0126 - time_loss: 9.0881e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1814\n",
            "Epoch 1125/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2709 - onoff_loss: 0.0219 - note_loss: 0.1357 - vel_loss: 0.0124 - time_loss: 1.0090e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9657 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 1126/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2418 - onoff_loss: 0.0203 - note_loss: 0.1217 - vel_loss: 0.0118 - time_loss: 8.7995e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 1127/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2705 - onoff_loss: 0.0233 - note_loss: 0.1480 - vel_loss: 0.0130 - time_loss: 8.6216e-05 - onoff_accuracy: 0.9896 - note_accuracy: 0.9627 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 1128/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2464 - onoff_loss: 0.0193 - note_loss: 0.1158 - vel_loss: 0.0122 - time_loss: 9.8996e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 1129/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2768 - onoff_loss: 0.0194 - note_loss: 0.1261 - vel_loss: 0.0123 - time_loss: 1.1900e-04 - onoff_accuracy: 0.9911 - note_accuracy: 0.9684 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1683\n",
            "Epoch 1130/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2335 - onoff_loss: 0.0190 - note_loss: 0.1152 - vel_loss: 0.0124 - time_loss: 8.6833e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2095\n",
            "Epoch 1131/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2534 - onoff_loss: 0.0204 - note_loss: 0.1245 - vel_loss: 0.0126 - time_loss: 9.6042e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9689 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 1132/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2439 - onoff_loss: 0.0197 - note_loss: 0.1181 - vel_loss: 0.0125 - time_loss: 9.3578e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 1133/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2539 - onoff_loss: 0.0208 - note_loss: 0.1230 - vel_loss: 0.0123 - time_loss: 9.7834e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9691 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1686\n",
            "Epoch 1134/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2462 - onoff_loss: 0.0195 - note_loss: 0.1225 - vel_loss: 0.0119 - time_loss: 9.2331e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9694 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1591\n",
            "Epoch 1135/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2340 - onoff_loss: 0.0182 - note_loss: 0.1112 - vel_loss: 0.0123 - time_loss: 9.2227e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1769\n",
            "Epoch 1136/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2272 - onoff_loss: 0.0190 - note_loss: 0.1181 - vel_loss: 0.0119 - time_loss: 7.8235e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9701 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1759\n",
            "Epoch 1137/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2429 - onoff_loss: 0.0196 - note_loss: 0.1191 - vel_loss: 0.0121 - time_loss: 9.2098e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1138/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2595 - onoff_loss: 0.0245 - note_loss: 0.1378 - vel_loss: 0.0121 - time_loss: 8.5122e-05 - onoff_accuracy: 0.9894 - note_accuracy: 0.9650 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1638\n",
            "Epoch 1139/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2380 - onoff_loss: 0.0187 - note_loss: 0.1212 - vel_loss: 0.0122 - time_loss: 8.5969e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1912\n",
            "Epoch 1140/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2404 - onoff_loss: 0.0191 - note_loss: 0.1173 - vel_loss: 0.0125 - time_loss: 9.1430e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9708 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1916\n",
            "Epoch 1141/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2453 - onoff_loss: 0.0186 - note_loss: 0.1181 - vel_loss: 0.0118 - time_loss: 9.6862e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1837\n",
            "Epoch 1142/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2188 - onoff_loss: 0.0181 - note_loss: 0.1153 - vel_loss: 0.0116 - time_loss: 7.3760e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1918\n",
            "Epoch 1143/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2693 - onoff_loss: 0.0194 - note_loss: 0.1196 - vel_loss: 0.0123 - time_loss: 1.1803e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1806\n",
            "Epoch 1144/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2422 - onoff_loss: 0.0192 - note_loss: 0.1159 - vel_loss: 0.0124 - time_loss: 9.4638e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9702 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1550\n",
            "Epoch 1145/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2524 - onoff_loss: 0.0209 - note_loss: 0.1206 - vel_loss: 0.0121 - time_loss: 9.8781e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9699 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 1146/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2606 - onoff_loss: 0.0193 - note_loss: 0.1230 - vel_loss: 0.0123 - time_loss: 1.0608e-04 - onoff_accuracy: 0.9911 - note_accuracy: 0.9695 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1753\n",
            "Epoch 1147/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2387 - onoff_loss: 0.0197 - note_loss: 0.1200 - vel_loss: 0.0112 - time_loss: 8.7784e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9701 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 1148/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2377 - onoff_loss: 0.0209 - note_loss: 0.1173 - vel_loss: 0.0119 - time_loss: 8.7612e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9702 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1636\n",
            "Epoch 1149/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2442 - onoff_loss: 0.0196 - note_loss: 0.1196 - vel_loss: 0.0121 - time_loss: 9.2926e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9695 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1919\n",
            "Epoch 1150/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2830 - onoff_loss: 0.0199 - note_loss: 0.1162 - vel_loss: 0.0124 - time_loss: 1.3442e-04 - onoff_accuracy: 0.9907 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1647\n",
            "Epoch 1151/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2412 - onoff_loss: 0.0209 - note_loss: 0.1306 - vel_loss: 0.0113 - time_loss: 7.8352e-05 - onoff_accuracy: 0.9902 - note_accuracy: 0.9679 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1665\n",
            "Epoch 1152/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2600 - onoff_loss: 0.0192 - note_loss: 0.1160 - vel_loss: 0.0122 - time_loss: 1.1262e-04 - onoff_accuracy: 0.9908 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 1153/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2331 - onoff_loss: 0.0209 - note_loss: 0.1180 - vel_loss: 0.0125 - time_loss: 8.1762e-05 - onoff_accuracy: 0.9902 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 1154/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2694 - onoff_loss: 0.0194 - note_loss: 0.1218 - vel_loss: 0.0122 - time_loss: 1.1606e-04 - onoff_accuracy: 0.9914 - note_accuracy: 0.9693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 1155/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2306 - onoff_loss: 0.0190 - note_loss: 0.1193 - vel_loss: 0.0128 - time_loss: 7.9472e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9709 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1688\n",
            "Epoch 1156/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2494 - onoff_loss: 0.0194 - note_loss: 0.1194 - vel_loss: 0.0118 - time_loss: 9.8820e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1661\n",
            "Epoch 1157/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2515 - onoff_loss: 0.0206 - note_loss: 0.1274 - vel_loss: 0.0121 - time_loss: 9.1283e-05 - onoff_accuracy: 0.9901 - note_accuracy: 0.9681 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1715\n",
            "Epoch 1158/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2589 - onoff_loss: 0.0202 - note_loss: 0.1281 - vel_loss: 0.0120 - time_loss: 9.8544e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9682 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1893\n",
            "Epoch 1159/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2354 - onoff_loss: 0.0191 - note_loss: 0.1162 - vel_loss: 0.0120 - time_loss: 8.8068e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 1160/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2373 - onoff_loss: 0.0191 - note_loss: 0.1204 - vel_loss: 0.0121 - time_loss: 8.5650e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9695 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1828\n",
            "Epoch 1161/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2291 - onoff_loss: 0.0191 - note_loss: 0.1156 - vel_loss: 0.0119 - time_loss: 8.2461e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9707 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 1162/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2568 - onoff_loss: 0.0203 - note_loss: 0.1293 - vel_loss: 0.0121 - time_loss: 9.5126e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9674 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823\n",
            "Epoch 1163/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2377 - onoff_loss: 0.0178 - note_loss: 0.1136 - vel_loss: 0.0113 - time_loss: 9.4945e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1577\n",
            "Epoch 1164/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2848 - onoff_loss: 0.0358 - note_loss: 0.1476 - vel_loss: 0.0132 - time_loss: 8.8195e-05 - onoff_accuracy: 0.9881 - note_accuracy: 0.9634 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1857\n",
            "Epoch 1165/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2277 - onoff_loss: 0.0187 - note_loss: 0.1132 - vel_loss: 0.0113 - time_loss: 8.4440e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1598\n",
            "Epoch 1166/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2215 - onoff_loss: 0.0187 - note_loss: 0.1119 - vel_loss: 0.0121 - time_loss: 7.8807e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9715 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 1167/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.2873 - onoff_loss: 0.0196 - note_loss: 0.1227 - vel_loss: 0.0120 - time_loss: 1.3296e-04 - onoff_accuracy: 0.9912 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 1168/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2300 - onoff_loss: 0.0196 - note_loss: 0.1149 - vel_loss: 0.0120 - time_loss: 8.3519e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1689\n",
            "Epoch 1169/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2268 - onoff_loss: 0.0189 - note_loss: 0.1118 - vel_loss: 0.0118 - time_loss: 8.4327e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1827\n",
            "Epoch 1170/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2802 - onoff_loss: 0.0248 - note_loss: 0.1363 - vel_loss: 0.0121 - time_loss: 1.0708e-04 - onoff_accuracy: 0.9896 - note_accuracy: 0.9666 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1715\n",
            "Epoch 1171/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2548 - onoff_loss: 0.0200 - note_loss: 0.1219 - vel_loss: 0.0125 - time_loss: 1.0043e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9695 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1757\n",
            "Epoch 1172/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2354 - onoff_loss: 0.0183 - note_loss: 0.1112 - vel_loss: 0.0114 - time_loss: 9.4427e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9713 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1659\n",
            "Epoch 1173/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2560 - onoff_loss: 0.0188 - note_loss: 0.1232 - vel_loss: 0.0118 - time_loss: 1.0232e-04 - onoff_accuracy: 0.9914 - note_accuracy: 0.9699 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 1174/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2589 - onoff_loss: 0.0199 - note_loss: 0.1146 - vel_loss: 0.0126 - time_loss: 1.1182e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1907\n",
            "Epoch 1175/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2260 - onoff_loss: 0.0178 - note_loss: 0.1125 - vel_loss: 0.0118 - time_loss: 8.3915e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 1176/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2563 - onoff_loss: 0.0197 - note_loss: 0.1176 - vel_loss: 0.0114 - time_loss: 1.0764e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 1177/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2673 - onoff_loss: 0.0206 - note_loss: 0.1239 - vel_loss: 0.0115 - time_loss: 1.1136e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9693 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1562\n",
            "Epoch 1178/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2228 - onoff_loss: 0.0202 - note_loss: 0.1208 - vel_loss: 0.0119 - time_loss: 6.9952e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1824\n",
            "Epoch 1179/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2652 - onoff_loss: 0.0203 - note_loss: 0.1219 - vel_loss: 0.0121 - time_loss: 1.1082e-04 - onoff_accuracy: 0.9903 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1793\n",
            "Epoch 1180/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2492 - onoff_loss: 0.0216 - note_loss: 0.1222 - vel_loss: 0.0118 - time_loss: 9.3662e-05 - onoff_accuracy: 0.9900 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 1181/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2309 - onoff_loss: 0.0192 - note_loss: 0.1175 - vel_loss: 0.0114 - time_loss: 8.2800e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1182/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2768 - onoff_loss: 0.0202 - note_loss: 0.1266 - vel_loss: 0.0118 - time_loss: 1.1827e-04 - onoff_accuracy: 0.9904 - note_accuracy: 0.9687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 1183/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2535 - onoff_loss: 0.0178 - note_loss: 0.1169 - vel_loss: 0.0120 - time_loss: 1.0679e-04 - onoff_accuracy: 0.9918 - note_accuracy: 0.9705 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1730\n",
            "Epoch 1184/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2246 - onoff_loss: 0.0189 - note_loss: 0.1136 - vel_loss: 0.0113 - time_loss: 8.0864e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 1185/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2520 - onoff_loss: 0.0197 - note_loss: 0.1189 - vel_loss: 0.0115 - time_loss: 1.0191e-04 - onoff_accuracy: 0.9909 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1589\n",
            "Epoch 1186/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2321 - onoff_loss: 0.0185 - note_loss: 0.1108 - vel_loss: 0.0118 - time_loss: 9.0882e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 1187/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2703 - onoff_loss: 0.0208 - note_loss: 0.1293 - vel_loss: 0.0120 - time_loss: 1.0829e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9672 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1188/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2303 - onoff_loss: 0.0176 - note_loss: 0.1096 - vel_loss: 0.0113 - time_loss: 9.1820e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1713\n",
            "Epoch 1189/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2112 - onoff_loss: 0.0178 - note_loss: 0.1119 - vel_loss: 0.0120 - time_loss: 6.9534e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1760\n",
            "Epoch 1190/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2366 - onoff_loss: 0.0187 - note_loss: 0.1182 - vel_loss: 0.0120 - time_loss: 8.7671e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9699 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1191/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2584 - onoff_loss: 0.0199 - note_loss: 0.1187 - vel_loss: 0.0118 - time_loss: 1.0800e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9708 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1930\n",
            "Epoch 1192/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2397 - onoff_loss: 0.0181 - note_loss: 0.1171 - vel_loss: 0.0120 - time_loss: 9.2436e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1193/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2638 - onoff_loss: 0.0205 - note_loss: 0.1169 - vel_loss: 0.0122 - time_loss: 1.1422e-04 - onoff_accuracy: 0.9906 - note_accuracy: 0.9707 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1696\n",
            "Epoch 1194/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2329 - onoff_loss: 0.0183 - note_loss: 0.1095 - vel_loss: 0.0114 - time_loss: 9.3690e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1620\n",
            "Epoch 1195/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2545 - onoff_loss: 0.0194 - note_loss: 0.1230 - vel_loss: 0.0125 - time_loss: 9.9717e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9688 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1971\n",
            "Epoch 1196/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2337 - onoff_loss: 0.0190 - note_loss: 0.1098 - vel_loss: 0.0118 - time_loss: 9.3152e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 1197/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2273 - onoff_loss: 0.0189 - note_loss: 0.1190 - vel_loss: 0.0120 - time_loss: 7.7381e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9705 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1806\n",
            "Epoch 1198/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2433 - onoff_loss: 0.0191 - note_loss: 0.1185 - vel_loss: 0.0114 - time_loss: 9.4383e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1541\n",
            "Epoch 1199/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2703 - onoff_loss: 0.0210 - note_loss: 0.1180 - vel_loss: 0.0123 - time_loss: 1.1897e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 1200/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2225 - onoff_loss: 0.0190 - note_loss: 0.1158 - vel_loss: 0.0117 - time_loss: 7.6049e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9713 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1794\n",
            "Epoch 1201/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2587 - onoff_loss: 0.0183 - note_loss: 0.1111 - vel_loss: 0.0123 - time_loss: 1.1699e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1687\n",
            "Epoch 1202/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2491 - onoff_loss: 0.0208 - note_loss: 0.1166 - vel_loss: 0.0116 - time_loss: 1.0016e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1636\n",
            "Epoch 1203/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2586 - onoff_loss: 0.0213 - note_loss: 0.1248 - vel_loss: 0.0115 - time_loss: 1.0112e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9687 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 1204/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2478 - onoff_loss: 0.0170 - note_loss: 0.1131 - vel_loss: 0.0117 - time_loss: 1.0604e-04 - onoff_accuracy: 0.9916 - note_accuracy: 0.9715 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 1205/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2152 - onoff_loss: 0.0181 - note_loss: 0.1088 - vel_loss: 0.0117 - time_loss: 7.6673e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9721 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1618\n",
            "Epoch 1206/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2385 - onoff_loss: 0.0192 - note_loss: 0.1174 - vel_loss: 0.0109 - time_loss: 9.1126e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9699 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1609\n",
            "Epoch 1207/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2300 - onoff_loss: 0.0193 - note_loss: 0.1201 - vel_loss: 0.0115 - time_loss: 7.9071e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1730\n",
            "Epoch 1208/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2576 - onoff_loss: 0.0175 - note_loss: 0.1089 - vel_loss: 0.0110 - time_loss: 1.2016e-04 - onoff_accuracy: 0.9914 - note_accuracy: 0.9728 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 1209/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2256 - onoff_loss: 0.0186 - note_loss: 0.1121 - vel_loss: 0.0115 - time_loss: 8.3345e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 1210/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2388 - onoff_loss: 0.0188 - note_loss: 0.1214 - vel_loss: 0.0116 - time_loss: 8.6965e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1513\n",
            "Epoch 1211/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2363 - onoff_loss: 0.0180 - note_loss: 0.1150 - vel_loss: 0.0124 - time_loss: 9.0865e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9713 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1799\n",
            "Epoch 1212/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2287 - onoff_loss: 0.0174 - note_loss: 0.1142 - vel_loss: 0.0116 - time_loss: 8.5520e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9707 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1923\n",
            "Epoch 1213/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.2417 - onoff_loss: 0.0199 - note_loss: 0.1258 - vel_loss: 0.0112 - time_loss: 8.4736e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9686 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1869\n",
            "Epoch 1214/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2453 - onoff_loss: 0.0186 - note_loss: 0.1131 - vel_loss: 0.0120 - time_loss: 1.0166e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9715 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1877\n",
            "Epoch 1215/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2572 - onoff_loss: 0.0205 - note_loss: 0.1234 - vel_loss: 0.0116 - time_loss: 1.0175e-04 - onoff_accuracy: 0.9905 - note_accuracy: 0.9698 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1902\n",
            "Epoch 1216/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2226 - onoff_loss: 0.0185 - note_loss: 0.1107 - vel_loss: 0.0107 - time_loss: 8.2577e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1217/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2342 - onoff_loss: 0.0174 - note_loss: 0.1116 - vel_loss: 0.0117 - time_loss: 9.3493e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1621\n",
            "Epoch 1218/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2285 - onoff_loss: 0.0179 - note_loss: 0.1102 - vel_loss: 0.0114 - time_loss: 8.9033e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1837\n",
            "Epoch 1219/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2286 - onoff_loss: 0.0194 - note_loss: 0.1145 - vel_loss: 0.0112 - time_loss: 8.3439e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9715 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 1220/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2512 - onoff_loss: 0.0190 - note_loss: 0.1244 - vel_loss: 0.0117 - time_loss: 9.6071e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9692 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1957\n",
            "Epoch 1221/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2461 - onoff_loss: 0.0197 - note_loss: 0.1251 - vel_loss: 0.0122 - time_loss: 8.9140e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9683 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1761\n",
            "Epoch 1222/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2326 - onoff_loss: 0.0179 - note_loss: 0.1072 - vel_loss: 0.0111 - time_loss: 9.6333e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1670\n",
            "Epoch 1223/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2337 - onoff_loss: 0.0176 - note_loss: 0.1143 - vel_loss: 0.0117 - time_loss: 9.0122e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1825\n",
            "Epoch 1224/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2394 - onoff_loss: 0.0198 - note_loss: 0.1147 - vel_loss: 0.0110 - time_loss: 9.3821e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9708 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1621\n",
            "Epoch 1225/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2431 - onoff_loss: 0.0199 - note_loss: 0.1148 - vel_loss: 0.0119 - time_loss: 9.6394e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1919\n",
            "Epoch 1226/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2308 - onoff_loss: 0.0182 - note_loss: 0.1151 - vel_loss: 0.0120 - time_loss: 8.5451e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9709 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1645\n",
            "Epoch 1227/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2281 - onoff_loss: 0.0197 - note_loss: 0.1142 - vel_loss: 0.0118 - time_loss: 8.2361e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9705 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 1228/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2308 - onoff_loss: 0.0190 - note_loss: 0.1097 - vel_loss: 0.0117 - time_loss: 9.0343e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1733\n",
            "Epoch 1229/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2349 - onoff_loss: 0.0193 - note_loss: 0.1224 - vel_loss: 0.0114 - time_loss: 8.1762e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1552\n",
            "Epoch 1230/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2377 - onoff_loss: 0.0194 - note_loss: 0.1153 - vel_loss: 0.0115 - time_loss: 9.1569e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1645\n",
            "Epoch 1231/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2574 - onoff_loss: 0.0195 - note_loss: 0.1212 - vel_loss: 0.0119 - time_loss: 1.0488e-04 - onoff_accuracy: 0.9911 - note_accuracy: 0.9690 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1719\n",
            "Epoch 1232/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2319 - onoff_loss: 0.0192 - note_loss: 0.1095 - vel_loss: 0.0116 - time_loss: 9.1531e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 1233/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2361 - onoff_loss: 0.0183 - note_loss: 0.1123 - vel_loss: 0.0113 - time_loss: 9.4160e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 1234/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2133 - onoff_loss: 0.0188 - note_loss: 0.1059 - vel_loss: 0.0119 - time_loss: 7.6622e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1809\n",
            "Epoch 1235/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2416 - onoff_loss: 0.0207 - note_loss: 0.1207 - vel_loss: 0.0117 - time_loss: 8.8518e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1802\n",
            "Epoch 1236/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2321 - onoff_loss: 0.0181 - note_loss: 0.1110 - vel_loss: 0.0112 - time_loss: 9.1831e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1655\n",
            "Epoch 1237/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2245 - onoff_loss: 0.0191 - note_loss: 0.1145 - vel_loss: 0.0115 - time_loss: 7.9419e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9710 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1659\n",
            "Epoch 1238/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2439 - onoff_loss: 0.0202 - note_loss: 0.1190 - vel_loss: 0.0120 - time_loss: 9.2654e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9697 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1705\n",
            "Epoch 1239/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2443 - onoff_loss: 0.0193 - note_loss: 0.1162 - vel_loss: 0.0108 - time_loss: 9.7977e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 1240/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2269 - onoff_loss: 0.0182 - note_loss: 0.1110 - vel_loss: 0.0107 - time_loss: 8.6938e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1541\n",
            "Epoch 1241/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2341 - onoff_loss: 0.0181 - note_loss: 0.1111 - vel_loss: 0.0121 - time_loss: 9.2798e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1792\n",
            "Epoch 1242/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2307 - onoff_loss: 0.0198 - note_loss: 0.1177 - vel_loss: 0.0117 - time_loss: 8.1458e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1824\n",
            "Epoch 1243/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2298 - onoff_loss: 0.0176 - note_loss: 0.1135 - vel_loss: 0.0117 - time_loss: 8.6968e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1668\n",
            "Epoch 1244/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2446 - onoff_loss: 0.0219 - note_loss: 0.1146 - vel_loss: 0.0109 - time_loss: 9.7178e-05 - onoff_accuracy: 0.9904 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 1245/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2348 - onoff_loss: 0.0198 - note_loss: 0.1190 - vel_loss: 0.0107 - time_loss: 8.5276e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 1246/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2534 - onoff_loss: 0.0185 - note_loss: 0.1174 - vel_loss: 0.0108 - time_loss: 1.0668e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9701 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 1247/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2114 - onoff_loss: 0.0197 - note_loss: 0.1074 - vel_loss: 0.0109 - time_loss: 7.3403e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1655\n",
            "Epoch 1248/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2215 - onoff_loss: 0.0181 - note_loss: 0.1087 - vel_loss: 0.0112 - time_loss: 8.3556e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1791\n",
            "Epoch 1249/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2303 - onoff_loss: 0.0184 - note_loss: 0.1141 - vel_loss: 0.0118 - time_loss: 8.6138e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9715 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 1250/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2462 - onoff_loss: 0.0173 - note_loss: 0.1116 - vel_loss: 0.0112 - time_loss: 1.0603e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1785\n",
            "Epoch 1251/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2333 - onoff_loss: 0.0178 - note_loss: 0.1117 - vel_loss: 0.0116 - time_loss: 9.2154e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1252/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2545 - onoff_loss: 0.0187 - note_loss: 0.1177 - vel_loss: 0.0113 - time_loss: 1.0678e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9700 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1930\n",
            "Epoch 1253/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2172 - onoff_loss: 0.0189 - note_loss: 0.1128 - vel_loss: 0.0109 - time_loss: 7.4553e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1697\n",
            "Epoch 1254/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2198 - onoff_loss: 0.0183 - note_loss: 0.1071 - vel_loss: 0.0117 - time_loss: 8.2681e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1704\n",
            "Epoch 1255/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2398 - onoff_loss: 0.0195 - note_loss: 0.1132 - vel_loss: 0.0110 - time_loss: 9.6098e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1850\n",
            "Epoch 1256/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2196 - onoff_loss: 0.0179 - note_loss: 0.1152 - vel_loss: 0.0114 - time_loss: 7.5114e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1769\n",
            "Epoch 1257/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2385 - onoff_loss: 0.0218 - note_loss: 0.1193 - vel_loss: 0.0106 - time_loss: 8.6760e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9696 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1502\n",
            "Epoch 1258/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2280 - onoff_loss: 0.0184 - note_loss: 0.1153 - vel_loss: 0.0119 - time_loss: 8.2426e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1888\n",
            "Epoch 1259/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2375 - onoff_loss: 0.0177 - note_loss: 0.1180 - vel_loss: 0.0112 - time_loss: 9.0644e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9697 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1260/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2270 - onoff_loss: 0.0182 - note_loss: 0.1097 - vel_loss: 0.0117 - time_loss: 8.7423e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 1261/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2240 - onoff_loss: 0.0179 - note_loss: 0.1103 - vel_loss: 0.0118 - time_loss: 8.3989e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1821\n",
            "Epoch 1262/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2304 - onoff_loss: 0.0187 - note_loss: 0.1135 - vel_loss: 0.0117 - time_loss: 8.6632e-05 - onoff_accuracy: 0.9907 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1647\n",
            "Epoch 1263/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2335 - onoff_loss: 0.0166 - note_loss: 0.1084 - vel_loss: 0.0117 - time_loss: 9.6782e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1675\n",
            "Epoch 1264/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2344 - onoff_loss: 0.0182 - note_loss: 0.1103 - vel_loss: 0.0120 - time_loss: 9.3902e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2025\n",
            "Epoch 1265/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2301 - onoff_loss: 0.0194 - note_loss: 0.1121 - vel_loss: 0.0109 - time_loss: 8.7639e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1753\n",
            "Epoch 1266/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2305 - onoff_loss: 0.0182 - note_loss: 0.1064 - vel_loss: 0.0109 - time_loss: 9.4966e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1571\n",
            "Epoch 1267/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2143 - onoff_loss: 0.0192 - note_loss: 0.1163 - vel_loss: 0.0114 - time_loss: 6.7380e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9703 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1676\n",
            "Epoch 1268/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2371 - onoff_loss: 0.0174 - note_loss: 0.1152 - vel_loss: 0.0112 - time_loss: 9.3322e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 1269/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2389 - onoff_loss: 0.0179 - note_loss: 0.1077 - vel_loss: 0.0114 - time_loss: 1.0180e-04 - onoff_accuracy: 0.9918 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1733\n",
            "Epoch 1270/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2307 - onoff_loss: 0.0182 - note_loss: 0.1108 - vel_loss: 0.0114 - time_loss: 9.0358e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1764\n",
            "Epoch 1271/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2308 - onoff_loss: 0.0175 - note_loss: 0.1107 - vel_loss: 0.0110 - time_loss: 9.1567e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9715 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1788\n",
            "Epoch 1272/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2410 - onoff_loss: 0.0186 - note_loss: 0.1109 - vel_loss: 0.0111 - time_loss: 1.0049e-04 - onoff_accuracy: 0.9920 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1667\n",
            "Epoch 1273/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2399 - onoff_loss: 0.0175 - note_loss: 0.1065 - vel_loss: 0.0117 - time_loss: 1.0421e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 1274/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2496 - onoff_loss: 0.0174 - note_loss: 0.1123 - vel_loss: 0.0115 - time_loss: 1.0845e-04 - onoff_accuracy: 0.9916 - note_accuracy: 0.9714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1878\n",
            "Epoch 1275/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2226 - onoff_loss: 0.0180 - note_loss: 0.1083 - vel_loss: 0.0109 - time_loss: 8.5405e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9723 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 1276/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2525 - onoff_loss: 0.0191 - note_loss: 0.1160 - vel_loss: 0.0108 - time_loss: 1.0663e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1606\n",
            "Epoch 1277/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2359 - onoff_loss: 0.0177 - note_loss: 0.1079 - vel_loss: 0.0117 - time_loss: 9.8623e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1871\n",
            "Epoch 1278/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2220 - onoff_loss: 0.0187 - note_loss: 0.1189 - vel_loss: 0.0107 - time_loss: 7.3738e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1815\n",
            "Epoch 1279/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1975 - onoff_loss: 0.0184 - note_loss: 0.1062 - vel_loss: 0.0112 - time_loss: 6.1675e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1699\n",
            "Epoch 1280/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2475 - onoff_loss: 0.0188 - note_loss: 0.1136 - vel_loss: 0.0113 - time_loss: 1.0381e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1845\n",
            "Epoch 1281/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2633 - onoff_loss: 0.0177 - note_loss: 0.1136 - vel_loss: 0.0115 - time_loss: 1.2038e-04 - onoff_accuracy: 0.9914 - note_accuracy: 0.9714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1580\n",
            "Epoch 1282/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2214 - onoff_loss: 0.0182 - note_loss: 0.1143 - vel_loss: 0.0118 - time_loss: 7.7115e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 1283/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3375 - onoff_loss: 0.0254 - note_loss: 0.2101 - vel_loss: 0.0118 - time_loss: 9.0248e-05 - onoff_accuracy: 0.9891 - note_accuracy: 0.9537 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1860\n",
            "Epoch 1284/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2351 - onoff_loss: 0.0171 - note_loss: 0.1077 - vel_loss: 0.0108 - time_loss: 9.9372e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1611\n",
            "Epoch 1285/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2408 - onoff_loss: 0.0193 - note_loss: 0.1081 - vel_loss: 0.0105 - time_loss: 1.0299e-04 - onoff_accuracy: 0.9912 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1537\n",
            "Epoch 1286/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2127 - onoff_loss: 0.0185 - note_loss: 0.1060 - vel_loss: 0.0108 - time_loss: 7.7344e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9728 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1287/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2541 - onoff_loss: 0.0176 - note_loss: 0.1168 - vel_loss: 0.0109 - time_loss: 1.0882e-04 - onoff_accuracy: 0.9918 - note_accuracy: 0.9707 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1872\n",
            "Epoch 1288/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2196 - onoff_loss: 0.0182 - note_loss: 0.1102 - vel_loss: 0.0105 - time_loss: 8.0644e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9721 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1817\n",
            "Epoch 1289/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2502 - onoff_loss: 0.0178 - note_loss: 0.1146 - vel_loss: 0.0115 - time_loss: 1.0631e-04 - onoff_accuracy: 0.9921 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1774\n",
            "Epoch 1290/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2197 - onoff_loss: 0.0187 - note_loss: 0.1114 - vel_loss: 0.0115 - time_loss: 7.8157e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9723 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1886\n",
            "Epoch 1291/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2434 - onoff_loss: 0.0194 - note_loss: 0.1129 - vel_loss: 0.0112 - time_loss: 9.9911e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 1292/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2311 - onoff_loss: 0.0181 - note_loss: 0.1076 - vel_loss: 0.0110 - time_loss: 9.4390e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1293/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2339 - onoff_loss: 0.0184 - note_loss: 0.1133 - vel_loss: 0.0108 - time_loss: 9.1292e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9713 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1861\n",
            "Epoch 1294/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2312 - onoff_loss: 0.0189 - note_loss: 0.1128 - vel_loss: 0.0107 - time_loss: 8.8725e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1651\n",
            "Epoch 1295/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2117 - onoff_loss: 0.0174 - note_loss: 0.1166 - vel_loss: 0.0109 - time_loss: 6.6871e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9709 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1927\n",
            "Epoch 1296/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2276 - onoff_loss: 0.0184 - note_loss: 0.1132 - vel_loss: 0.0109 - time_loss: 8.5105e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9712 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 1297/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2265 - onoff_loss: 0.0191 - note_loss: 0.1079 - vel_loss: 0.0114 - time_loss: 8.8076e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1833\n",
            "Epoch 1298/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2269 - onoff_loss: 0.0185 - note_loss: 0.1152 - vel_loss: 0.0111 - time_loss: 8.2136e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9708 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1832\n",
            "Epoch 1299/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2598 - onoff_loss: 0.0181 - note_loss: 0.1154 - vel_loss: 0.0108 - time_loss: 1.1538e-04 - onoff_accuracy: 0.9911 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 1300/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2430 - onoff_loss: 0.0204 - note_loss: 0.1057 - vel_loss: 0.0106 - time_loss: 1.0626e-04 - onoff_accuracy: 0.9901 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1640\n",
            "Epoch 1301/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2129 - onoff_loss: 0.0184 - note_loss: 0.1047 - vel_loss: 0.0110 - time_loss: 7.8837e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 1302/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1954 - onoff_loss: 0.0169 - note_loss: 0.1029 - vel_loss: 0.0108 - time_loss: 6.4835e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2018\n",
            "Epoch 1303/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2422 - onoff_loss: 0.0208 - note_loss: 0.1152 - vel_loss: 0.0105 - time_loss: 9.5699e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9706 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 1304/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2264 - onoff_loss: 0.0190 - note_loss: 0.1058 - vel_loss: 0.0108 - time_loss: 9.0781e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1544\n",
            "Epoch 1305/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2101 - onoff_loss: 0.0171 - note_loss: 0.1071 - vel_loss: 0.0111 - time_loss: 7.4865e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 1306/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2273 - onoff_loss: 0.0170 - note_loss: 0.1086 - vel_loss: 0.0102 - time_loss: 9.1422e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9721 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1570\n",
            "Epoch 1307/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2213 - onoff_loss: 0.0188 - note_loss: 0.1062 - vel_loss: 0.0108 - time_loss: 8.5512e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9728 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 1308/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2229 - onoff_loss: 0.0191 - note_loss: 0.1132 - vel_loss: 0.0107 - time_loss: 7.9963e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9713 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1309/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2496 - onoff_loss: 0.0180 - note_loss: 0.1101 - vel_loss: 0.0113 - time_loss: 1.1011e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9716 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 1310/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2148 - onoff_loss: 0.0174 - note_loss: 0.1027 - vel_loss: 0.0115 - time_loss: 8.3231e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1311/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2070 - onoff_loss: 0.0198 - note_loss: 0.1075 - vel_loss: 0.0108 - time_loss: 6.8906e-05 - onoff_accuracy: 0.9906 - note_accuracy: 0.9723 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1687\n",
            "Epoch 1312/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2100 - onoff_loss: 0.0164 - note_loss: 0.1012 - vel_loss: 0.0105 - time_loss: 8.1878e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1745\n",
            "Epoch 1313/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2257 - onoff_loss: 0.0204 - note_loss: 0.1164 - vel_loss: 0.0111 - time_loss: 7.7758e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1860\n",
            "Epoch 1314/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2261 - onoff_loss: 0.0188 - note_loss: 0.1094 - vel_loss: 0.0113 - time_loss: 8.6576e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1868\n",
            "Epoch 1315/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2091 - onoff_loss: 0.0191 - note_loss: 0.1089 - vel_loss: 0.0109 - time_loss: 7.0275e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9714 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1820\n",
            "Epoch 1316/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2416 - onoff_loss: 0.0175 - note_loss: 0.1042 - vel_loss: 0.0107 - time_loss: 1.0927e-04 - onoff_accuracy: 0.9918 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1918\n",
            "Epoch 1317/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2165 - onoff_loss: 0.0167 - note_loss: 0.1086 - vel_loss: 0.0106 - time_loss: 8.0550e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1591\n",
            "Epoch 1318/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2096 - onoff_loss: 0.0183 - note_loss: 0.1044 - vel_loss: 0.0101 - time_loss: 7.6872e-05 - onoff_accuracy: 0.9911 - note_accuracy: 0.9736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 1319/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2084 - onoff_loss: 0.0168 - note_loss: 0.1038 - vel_loss: 0.0105 - time_loss: 7.7291e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1320/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2222 - onoff_loss: 0.0164 - note_loss: 0.1051 - vel_loss: 0.0105 - time_loss: 9.0261e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1321/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2739 - onoff_loss: 0.0203 - note_loss: 0.1257 - vel_loss: 0.0114 - time_loss: 1.1649e-04 - onoff_accuracy: 0.9910 - note_accuracy: 0.9671 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1711\n",
            "Epoch 1322/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2231 - onoff_loss: 0.0178 - note_loss: 0.1081 - vel_loss: 0.0112 - time_loss: 8.6030e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9727 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1795\n",
            "Epoch 1323/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2253 - onoff_loss: 0.0174 - note_loss: 0.1078 - vel_loss: 0.0108 - time_loss: 8.9326e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1754\n",
            "Epoch 1324/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2320 - onoff_loss: 0.0182 - note_loss: 0.1081 - vel_loss: 0.0105 - time_loss: 9.5091e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 1325/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2313 - onoff_loss: 0.0184 - note_loss: 0.1099 - vel_loss: 0.0112 - time_loss: 9.1804e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9719 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 1326/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2204 - onoff_loss: 0.0169 - note_loss: 0.1044 - vel_loss: 0.0105 - time_loss: 8.8658e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1599\n",
            "Epoch 1327/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2151 - onoff_loss: 0.0193 - note_loss: 0.1076 - vel_loss: 0.0106 - time_loss: 7.7627e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9727 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 1328/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2385 - onoff_loss: 0.0179 - note_loss: 0.1069 - vel_loss: 0.0108 - time_loss: 1.0285e-04 - onoff_accuracy: 0.9914 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 1329/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2038 - onoff_loss: 0.0163 - note_loss: 0.1039 - vel_loss: 0.0103 - time_loss: 7.3357e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1881\n",
            "Epoch 1330/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2155 - onoff_loss: 0.0181 - note_loss: 0.1103 - vel_loss: 0.0110 - time_loss: 7.6183e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 1331/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2094 - onoff_loss: 0.0170 - note_loss: 0.1060 - vel_loss: 0.0109 - time_loss: 7.5505e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9731 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2006\n",
            "Epoch 1332/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2195 - onoff_loss: 0.0218 - note_loss: 0.1078 - vel_loss: 0.0101 - time_loss: 7.9873e-05 - onoff_accuracy: 0.9899 - note_accuracy: 0.9721 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1542\n",
            "Epoch 1333/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2235 - onoff_loss: 0.0185 - note_loss: 0.1071 - vel_loss: 0.0103 - time_loss: 8.7496e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1428\n",
            "Epoch 1334/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2059 - onoff_loss: 0.0165 - note_loss: 0.1005 - vel_loss: 0.0106 - time_loss: 7.8256e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1929\n",
            "Epoch 1335/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2276 - onoff_loss: 0.0168 - note_loss: 0.1031 - vel_loss: 0.0106 - time_loss: 9.7181e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1652\n",
            "Epoch 1336/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2333 - onoff_loss: 0.0186 - note_loss: 0.1065 - vel_loss: 0.0112 - time_loss: 9.6958e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1337/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2165 - onoff_loss: 0.0181 - note_loss: 0.1068 - vel_loss: 0.0107 - time_loss: 8.0916e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9731 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1567\n",
            "Epoch 1338/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2174 - onoff_loss: 0.0187 - note_loss: 0.1095 - vel_loss: 0.0104 - time_loss: 7.8896e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1730\n",
            "Epoch 1339/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2157 - onoff_loss: 0.0175 - note_loss: 0.1049 - vel_loss: 0.0111 - time_loss: 8.2226e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9723 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1820\n",
            "Epoch 1340/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2176 - onoff_loss: 0.0173 - note_loss: 0.1105 - vel_loss: 0.0103 - time_loss: 7.9453e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1845\n",
            "Epoch 1341/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2236 - onoff_loss: 0.0173 - note_loss: 0.1040 - vel_loss: 0.0112 - time_loss: 9.1042e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1707\n",
            "Epoch 1342/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2156 - onoff_loss: 0.0160 - note_loss: 0.1025 - vel_loss: 0.0107 - time_loss: 8.6545e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 1343/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2175 - onoff_loss: 0.0180 - note_loss: 0.1074 - vel_loss: 0.0103 - time_loss: 8.1835e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1758\n",
            "Epoch 1344/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2049 - onoff_loss: 0.0169 - note_loss: 0.1033 - vel_loss: 0.0106 - time_loss: 7.4009e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1871\n",
            "Epoch 1345/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2214 - onoff_loss: 0.0180 - note_loss: 0.1065 - vel_loss: 0.0105 - time_loss: 8.6370e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1807\n",
            "Epoch 1346/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2201 - onoff_loss: 0.0187 - note_loss: 0.1069 - vel_loss: 0.0106 - time_loss: 8.3906e-05 - onoff_accuracy: 0.9905 - note_accuracy: 0.9727 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1673\n",
            "Epoch 1347/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2338 - onoff_loss: 0.0175 - note_loss: 0.1028 - vel_loss: 0.0105 - time_loss: 1.0306e-04 - onoff_accuracy: 0.9919 - note_accuracy: 0.9734 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 1348/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2286 - onoff_loss: 0.0169 - note_loss: 0.1035 - vel_loss: 0.0101 - time_loss: 9.8081e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 1349/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2101 - onoff_loss: 0.0174 - note_loss: 0.1018 - vel_loss: 0.0106 - time_loss: 8.0253e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 1350/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2126 - onoff_loss: 0.0172 - note_loss: 0.1049 - vel_loss: 0.0109 - time_loss: 7.9648e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1818\n",
            "Epoch 1351/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2073 - onoff_loss: 0.0173 - note_loss: 0.1088 - vel_loss: 0.0105 - time_loss: 7.0727e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1840\n",
            "Epoch 1352/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2154 - onoff_loss: 0.0167 - note_loss: 0.1055 - vel_loss: 0.0103 - time_loss: 8.2894e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9728 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1353/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2143 - onoff_loss: 0.0173 - note_loss: 0.1096 - vel_loss: 0.0105 - time_loss: 7.6962e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1887\n",
            "Epoch 1354/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2502 - onoff_loss: 0.0175 - note_loss: 0.1083 - vel_loss: 0.0102 - time_loss: 1.1423e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9727 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1580\n",
            "Epoch 1355/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2069 - onoff_loss: 0.0169 - note_loss: 0.1094 - vel_loss: 0.0106 - time_loss: 7.0010e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1813\n",
            "Epoch 1356/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2040 - onoff_loss: 0.0164 - note_loss: 0.1021 - vel_loss: 0.0103 - time_loss: 7.5220e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1357/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2199 - onoff_loss: 0.0177 - note_loss: 0.1074 - vel_loss: 0.0109 - time_loss: 8.3877e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1801\n",
            "Epoch 1358/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2669 - onoff_loss: 0.0209 - note_loss: 0.1259 - vel_loss: 0.0112 - time_loss: 1.0893e-04 - onoff_accuracy: 0.9907 - note_accuracy: 0.9690 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 1359/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2084 - onoff_loss: 0.0162 - note_loss: 0.1068 - vel_loss: 0.0108 - time_loss: 7.4650e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1360/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2564 - onoff_loss: 0.0182 - note_loss: 0.1036 - vel_loss: 0.0107 - time_loss: 1.2387e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1519\n",
            "Epoch 1361/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1988 - onoff_loss: 0.0168 - note_loss: 0.1007 - vel_loss: 0.0104 - time_loss: 7.0911e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 1362/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2516 - onoff_loss: 0.0183 - note_loss: 0.1115 - vel_loss: 0.0103 - time_loss: 1.1151e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1543\n",
            "Epoch 1363/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2036 - onoff_loss: 0.0183 - note_loss: 0.0999 - vel_loss: 0.0103 - time_loss: 7.5058e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1531\n",
            "Epoch 1364/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2278 - onoff_loss: 0.0176 - note_loss: 0.1088 - vel_loss: 0.0105 - time_loss: 9.0788e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1664\n",
            "Epoch 1365/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2035 - onoff_loss: 0.0164 - note_loss: 0.1018 - vel_loss: 0.0106 - time_loss: 7.4732e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1366/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2319 - onoff_loss: 0.0182 - note_loss: 0.1143 - vel_loss: 0.0099 - time_loss: 8.9489e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9705 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1635\n",
            "Epoch 1367/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2095 - onoff_loss: 0.0172 - note_loss: 0.1058 - vel_loss: 0.0104 - time_loss: 7.6139e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9734 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1886\n",
            "Epoch 1368/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2041 - onoff_loss: 0.0167 - note_loss: 0.1027 - vel_loss: 0.0106 - time_loss: 7.4092e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1897\n",
            "Epoch 1369/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2127 - onoff_loss: 0.0173 - note_loss: 0.1014 - vel_loss: 0.0101 - time_loss: 8.3926e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2047\n",
            "Epoch 1370/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2264 - onoff_loss: 0.0182 - note_loss: 0.1086 - vel_loss: 0.0105 - time_loss: 8.9145e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1538\n",
            "Epoch 1371/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2114 - onoff_loss: 0.0174 - note_loss: 0.1051 - vel_loss: 0.0103 - time_loss: 7.8611e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9728 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1372/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2086 - onoff_loss: 0.0172 - note_loss: 0.1022 - vel_loss: 0.0102 - time_loss: 7.8924e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 1373/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2162 - onoff_loss: 0.0167 - note_loss: 0.1046 - vel_loss: 0.0110 - time_loss: 8.3928e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 1374/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2030 - onoff_loss: 0.0163 - note_loss: 0.1038 - vel_loss: 0.0104 - time_loss: 7.2612e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9727 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1958\n",
            "Epoch 1375/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2131 - onoff_loss: 0.0181 - note_loss: 0.1084 - vel_loss: 0.0103 - time_loss: 7.6409e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9723 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1635\n",
            "Epoch 1376/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2216 - onoff_loss: 0.0183 - note_loss: 0.1029 - vel_loss: 0.0101 - time_loss: 9.0248e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1769\n",
            "Epoch 1377/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2196 - onoff_loss: 0.0176 - note_loss: 0.1084 - vel_loss: 0.0102 - time_loss: 8.3333e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9724 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1619\n",
            "Epoch 1378/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2331 - onoff_loss: 0.0190 - note_loss: 0.1149 - vel_loss: 0.0105 - time_loss: 8.8594e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9702 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1621\n",
            "Epoch 1379/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2428 - onoff_loss: 0.0177 - note_loss: 0.1113 - vel_loss: 0.0101 - time_loss: 1.0358e-04 - onoff_accuracy: 0.9916 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1662\n",
            "Epoch 1380/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1981 - onoff_loss: 0.0158 - note_loss: 0.1015 - vel_loss: 0.0108 - time_loss: 7.0017e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1802\n",
            "Epoch 1381/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1972 - onoff_loss: 0.0165 - note_loss: 0.0985 - vel_loss: 0.0102 - time_loss: 7.2048e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 1382/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2227 - onoff_loss: 0.0167 - note_loss: 0.1032 - vel_loss: 0.0111 - time_loss: 9.1582e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1814\n",
            "Epoch 1383/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1979 - onoff_loss: 0.0173 - note_loss: 0.1059 - vel_loss: 0.0104 - time_loss: 6.4243e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1810\n",
            "Epoch 1384/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2335 - onoff_loss: 0.0176 - note_loss: 0.1025 - vel_loss: 0.0097 - time_loss: 1.0379e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1523\n",
            "Epoch 1385/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1924 - onoff_loss: 0.0169 - note_loss: 0.0971 - vel_loss: 0.0110 - time_loss: 6.7319e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1927\n",
            "Epoch 1386/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2141 - onoff_loss: 0.0177 - note_loss: 0.1070 - vel_loss: 0.0099 - time_loss: 7.9475e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 1387/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2198 - onoff_loss: 0.0171 - note_loss: 0.1041 - vel_loss: 0.0108 - time_loss: 8.7706e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1981\n",
            "Epoch 1388/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1907 - onoff_loss: 0.0165 - note_loss: 0.1002 - vel_loss: 0.0102 - time_loss: 6.3830e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9741 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 1389/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2269 - onoff_loss: 0.0166 - note_loss: 0.1069 - vel_loss: 0.0103 - time_loss: 9.3070e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9731 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1661\n",
            "Epoch 1390/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1974 - onoff_loss: 0.0183 - note_loss: 0.1039 - vel_loss: 0.0105 - time_loss: 6.4823e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9727 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1658\n",
            "Epoch 1391/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2310 - onoff_loss: 0.0176 - note_loss: 0.1324 - vel_loss: 0.0100 - time_loss: 7.0996e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9659 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1392/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2322 - onoff_loss: 0.0179 - note_loss: 0.1071 - vel_loss: 0.0104 - time_loss: 9.6830e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9731 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1864\n",
            "Epoch 1393/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2017 - onoff_loss: 0.0179 - note_loss: 0.1009 - vel_loss: 0.0106 - time_loss: 7.2241e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1765\n",
            "Epoch 1394/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1987 - onoff_loss: 0.0164 - note_loss: 0.0992 - vel_loss: 0.0107 - time_loss: 7.2463e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1885\n",
            "Epoch 1395/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2308 - onoff_loss: 0.0185 - note_loss: 0.1066 - vel_loss: 0.0107 - time_loss: 9.5047e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1701\n",
            "Epoch 1396/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2416 - onoff_loss: 0.0170 - note_loss: 0.1051 - vel_loss: 0.0104 - time_loss: 1.0916e-04 - onoff_accuracy: 0.9917 - note_accuracy: 0.9733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1743\n",
            "Epoch 1397/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2009 - onoff_loss: 0.0160 - note_loss: 0.0973 - vel_loss: 0.0101 - time_loss: 7.7554e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1674\n",
            "Epoch 1398/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2172 - onoff_loss: 0.0174 - note_loss: 0.1052 - vel_loss: 0.0105 - time_loss: 8.4086e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 1399/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2339 - onoff_loss: 0.0172 - note_loss: 0.1028 - vel_loss: 0.0105 - time_loss: 1.0339e-04 - onoff_accuracy: 0.9917 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1805\n",
            "Epoch 1400/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2070 - onoff_loss: 0.0164 - note_loss: 0.1016 - vel_loss: 0.0103 - time_loss: 7.8667e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9741 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1689\n",
            "Epoch 1401/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2184 - onoff_loss: 0.0184 - note_loss: 0.0990 - vel_loss: 0.0103 - time_loss: 9.0739e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9741 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1402/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2164 - onoff_loss: 0.0165 - note_loss: 0.1017 - vel_loss: 0.0104 - time_loss: 8.7684e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1819\n",
            "Epoch 1403/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1968 - onoff_loss: 0.0165 - note_loss: 0.1014 - vel_loss: 0.0108 - time_loss: 6.8064e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1643\n",
            "Epoch 1404/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2105 - onoff_loss: 0.0166 - note_loss: 0.0977 - vel_loss: 0.0101 - time_loss: 8.6140e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1771\n",
            "Epoch 1405/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2063 - onoff_loss: 0.0172 - note_loss: 0.1013 - vel_loss: 0.0104 - time_loss: 7.7443e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 1406/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2141 - onoff_loss: 0.0178 - note_loss: 0.1056 - vel_loss: 0.0101 - time_loss: 8.0607e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 1407/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2241 - onoff_loss: 0.0190 - note_loss: 0.1063 - vel_loss: 0.0102 - time_loss: 8.8563e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1706\n",
            "Epoch 1408/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2414 - onoff_loss: 0.0175 - note_loss: 0.1049 - vel_loss: 0.0099 - time_loss: 1.0923e-04 - onoff_accuracy: 0.9917 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 1409/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2292 - onoff_loss: 0.0189 - note_loss: 0.1141 - vel_loss: 0.0102 - time_loss: 8.6152e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9711 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1797\n",
            "Epoch 1410/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2078 - onoff_loss: 0.0173 - note_loss: 0.0960 - vel_loss: 0.0100 - time_loss: 8.4554e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 1411/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2039 - onoff_loss: 0.0169 - note_loss: 0.0998 - vel_loss: 0.0110 - time_loss: 7.6104e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 1412/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2513 - onoff_loss: 0.0326 - note_loss: 0.1084 - vel_loss: 0.0102 - time_loss: 1.0016e-04 - onoff_accuracy: 0.9865 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1751\n",
            "Epoch 1413/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2059 - onoff_loss: 0.0172 - note_loss: 0.0929 - vel_loss: 0.0105 - time_loss: 8.5277e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1737\n",
            "Epoch 1414/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1997 - onoff_loss: 0.0160 - note_loss: 0.0992 - vel_loss: 0.0097 - time_loss: 7.4737e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 1415/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2230 - onoff_loss: 0.0190 - note_loss: 0.1092 - vel_loss: 0.0101 - time_loss: 8.4792e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1694\n",
            "Epoch 1416/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2098 - onoff_loss: 0.0168 - note_loss: 0.1000 - vel_loss: 0.0100 - time_loss: 8.3119e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1794\n",
            "Epoch 1417/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2031 - onoff_loss: 0.0176 - note_loss: 0.1065 - vel_loss: 0.0099 - time_loss: 6.9091e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1638\n",
            "Epoch 1418/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2215 - onoff_loss: 0.0162 - note_loss: 0.0968 - vel_loss: 0.0101 - time_loss: 9.8263e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1932\n",
            "Epoch 1419/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2006 - onoff_loss: 0.0173 - note_loss: 0.0974 - vel_loss: 0.0105 - time_loss: 7.5277e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 1420/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2050 - onoff_loss: 0.0166 - note_loss: 0.1019 - vel_loss: 0.0099 - time_loss: 7.6564e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1700\n",
            "Epoch 1421/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2219 - onoff_loss: 0.0183 - note_loss: 0.1093 - vel_loss: 0.0100 - time_loss: 8.4284e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9725 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1674\n",
            "Epoch 1422/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2285 - onoff_loss: 0.0165 - note_loss: 0.1019 - vel_loss: 0.0099 - time_loss: 1.0016e-04 - onoff_accuracy: 0.9925 - note_accuracy: 0.9733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1649\n",
            "Epoch 1423/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2023 - onoff_loss: 0.0166 - note_loss: 0.0993 - vel_loss: 0.0100 - time_loss: 7.6428e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1741\n",
            "Epoch 1424/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2265 - onoff_loss: 0.0176 - note_loss: 0.1028 - vel_loss: 0.0106 - time_loss: 9.5488e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9734 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1691\n",
            "Epoch 1425/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2232 - onoff_loss: 0.0181 - note_loss: 0.1086 - vel_loss: 0.0108 - time_loss: 8.5851e-05 - onoff_accuracy: 0.9910 - note_accuracy: 0.9721 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1842\n",
            "Epoch 1426/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2085 - onoff_loss: 0.0169 - note_loss: 0.1039 - vel_loss: 0.0105 - time_loss: 7.7233e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1704\n",
            "Epoch 1427/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2015 - onoff_loss: 0.0159 - note_loss: 0.0969 - vel_loss: 0.0100 - time_loss: 7.8734e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1802\n",
            "Epoch 1428/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2071 - onoff_loss: 0.0173 - note_loss: 0.1056 - vel_loss: 0.0100 - time_loss: 7.4213e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 1429/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1904 - onoff_loss: 0.0159 - note_loss: 0.0964 - vel_loss: 0.0099 - time_loss: 6.8157e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9747 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1800\n",
            "Epoch 1430/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2462 - onoff_loss: 0.0192 - note_loss: 0.1105 - vel_loss: 0.0104 - time_loss: 1.0604e-04 - onoff_accuracy: 0.9913 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1689\n",
            "Epoch 1431/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1929 - onoff_loss: 0.0166 - note_loss: 0.1004 - vel_loss: 0.0096 - time_loss: 6.6270e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1793\n",
            "Epoch 1432/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2020 - onoff_loss: 0.0178 - note_loss: 0.0998 - vel_loss: 0.0098 - time_loss: 7.4616e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1678\n",
            "Epoch 1433/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2274 - onoff_loss: 0.0164 - note_loss: 0.0989 - vel_loss: 0.0100 - time_loss: 1.0208e-04 - onoff_accuracy: 0.9922 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 1434/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2038 - onoff_loss: 0.0171 - note_loss: 0.1025 - vel_loss: 0.0101 - time_loss: 7.4016e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1897\n",
            "Epoch 1435/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2291 - onoff_loss: 0.0179 - note_loss: 0.1017 - vel_loss: 0.0095 - time_loss: 1.0004e-04 - onoff_accuracy: 0.9915 - note_accuracy: 0.9736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 1436/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2099 - onoff_loss: 0.0165 - note_loss: 0.1045 - vel_loss: 0.0100 - time_loss: 7.8829e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9734 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1600\n",
            "Epoch 1437/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2163 - onoff_loss: 0.0164 - note_loss: 0.1032 - vel_loss: 0.0103 - time_loss: 8.6448e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 1438/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2269 - onoff_loss: 0.0172 - note_loss: 0.1107 - vel_loss: 0.0099 - time_loss: 8.9190e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9718 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1439/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2052 - onoff_loss: 0.0170 - note_loss: 0.0987 - vel_loss: 0.0100 - time_loss: 7.9501e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9747 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1855\n",
            "Epoch 1440/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2027 - onoff_loss: 0.0176 - note_loss: 0.1017 - vel_loss: 0.0097 - time_loss: 7.3755e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1770\n",
            "Epoch 1441/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2188 - onoff_loss: 0.0163 - note_loss: 0.1160 - vel_loss: 0.0106 - time_loss: 7.5962e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9704 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2029\n",
            "Epoch 1442/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2020 - onoff_loss: 0.0194 - note_loss: 0.1078 - vel_loss: 0.0098 - time_loss: 6.4983e-05 - onoff_accuracy: 0.9909 - note_accuracy: 0.9720 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 1443/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2176 - onoff_loss: 0.0170 - note_loss: 0.1031 - vel_loss: 0.0096 - time_loss: 8.7911e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1812\n",
            "Epoch 1444/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2065 - onoff_loss: 0.0174 - note_loss: 0.1020 - vel_loss: 0.0100 - time_loss: 7.7095e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1671\n",
            "Epoch 1445/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1878 - onoff_loss: 0.0174 - note_loss: 0.0976 - vel_loss: 0.0099 - time_loss: 6.3043e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1795\n",
            "Epoch 1446/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2081 - onoff_loss: 0.0163 - note_loss: 0.0989 - vel_loss: 0.0104 - time_loss: 8.2530e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9741 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1939\n",
            "Epoch 1447/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2093 - onoff_loss: 0.0181 - note_loss: 0.1021 - vel_loss: 0.0096 - time_loss: 7.9469e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1603\n",
            "Epoch 1448/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2123 - onoff_loss: 0.0172 - note_loss: 0.1064 - vel_loss: 0.0099 - time_loss: 7.8894e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 1449/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2148 - onoff_loss: 0.0171 - note_loss: 0.1036 - vel_loss: 0.0102 - time_loss: 8.3973e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1450/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2251 - onoff_loss: 0.0166 - note_loss: 0.1041 - vel_loss: 0.0102 - time_loss: 9.4232e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1613\n",
            "Epoch 1451/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2022 - onoff_loss: 0.0165 - note_loss: 0.1013 - vel_loss: 0.0098 - time_loss: 7.4600e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9741 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1669\n",
            "Epoch 1452/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2081 - onoff_loss: 0.0174 - note_loss: 0.1032 - vel_loss: 0.0099 - time_loss: 7.7580e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9731 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1699\n",
            "Epoch 1453/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1988 - onoff_loss: 0.0165 - note_loss: 0.0979 - vel_loss: 0.0099 - time_loss: 7.4470e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 1454/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2105 - onoff_loss: 0.0161 - note_loss: 0.0986 - vel_loss: 0.0102 - time_loss: 8.5583e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1808\n",
            "Epoch 1455/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1956 - onoff_loss: 0.0177 - note_loss: 0.1015 - vel_loss: 0.0101 - time_loss: 6.6261e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9736 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 1456/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2075 - onoff_loss: 0.0170 - note_loss: 0.1012 - vel_loss: 0.0102 - time_loss: 7.9121e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1544\n",
            "Epoch 1457/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1914 - onoff_loss: 0.0166 - note_loss: 0.1054 - vel_loss: 0.0097 - time_loss: 5.9602e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1501\n",
            "Epoch 1458/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1937 - onoff_loss: 0.0160 - note_loss: 0.0983 - vel_loss: 0.0093 - time_loss: 7.0216e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1682\n",
            "Epoch 1459/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2381 - onoff_loss: 0.0176 - note_loss: 0.1019 - vel_loss: 0.0099 - time_loss: 1.0870e-04 - onoff_accuracy: 0.9916 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1549\n",
            "Epoch 1460/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1881 - onoff_loss: 0.0161 - note_loss: 0.0996 - vel_loss: 0.0098 - time_loss: 6.2591e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9747 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1867\n",
            "Epoch 1461/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2063 - onoff_loss: 0.0164 - note_loss: 0.1000 - vel_loss: 0.0099 - time_loss: 7.9956e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9747 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 1462/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2024 - onoff_loss: 0.0170 - note_loss: 0.1021 - vel_loss: 0.0099 - time_loss: 7.3389e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1565\n",
            "Epoch 1463/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2101 - onoff_loss: 0.0168 - note_loss: 0.0985 - vel_loss: 0.0097 - time_loss: 8.5002e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1701\n",
            "Epoch 1464/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2105 - onoff_loss: 0.0170 - note_loss: 0.1004 - vel_loss: 0.0099 - time_loss: 8.3261e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 1465/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1946 - onoff_loss: 0.0166 - note_loss: 0.0949 - vel_loss: 0.0097 - time_loss: 7.3370e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1676\n",
            "Epoch 1466/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2345 - onoff_loss: 0.0169 - note_loss: 0.1054 - vel_loss: 0.0103 - time_loss: 1.0195e-04 - onoff_accuracy: 0.9918 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1840\n",
            "Epoch 1467/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2058 - onoff_loss: 0.0155 - note_loss: 0.0933 - vel_loss: 0.0101 - time_loss: 8.6955e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1710\n",
            "Epoch 1468/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2107 - onoff_loss: 0.0168 - note_loss: 0.0971 - vel_loss: 0.0095 - time_loss: 8.7246e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1517\n",
            "Epoch 1469/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2031 - onoff_loss: 0.0171 - note_loss: 0.0958 - vel_loss: 0.0100 - time_loss: 8.0294e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1685\n",
            "Epoch 1470/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2146 - onoff_loss: 0.0165 - note_loss: 0.1041 - vel_loss: 0.0102 - time_loss: 8.3716e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9732 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 1471/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2043 - onoff_loss: 0.0174 - note_loss: 0.1047 - vel_loss: 0.0096 - time_loss: 7.2585e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9733 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1726\n",
            "Epoch 1472/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2033 - onoff_loss: 0.0164 - note_loss: 0.1019 - vel_loss: 0.0098 - time_loss: 7.5240e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1943\n",
            "Epoch 1473/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2138 - onoff_loss: 0.0187 - note_loss: 0.1050 - vel_loss: 0.0097 - time_loss: 8.0406e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9722 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 1474/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1877 - onoff_loss: 0.0158 - note_loss: 0.0959 - vel_loss: 0.0101 - time_loss: 6.5973e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9747 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1852\n",
            "Epoch 1475/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1961 - onoff_loss: 0.0177 - note_loss: 0.1007 - vel_loss: 0.0096 - time_loss: 6.7998e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1670\n",
            "Epoch 1476/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2033 - onoff_loss: 0.0169 - note_loss: 0.0993 - vel_loss: 0.0099 - time_loss: 7.7296e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1590\n",
            "Epoch 1477/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2180 - onoff_loss: 0.0178 - note_loss: 0.0998 - vel_loss: 0.0098 - time_loss: 9.0568e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1735\n",
            "Epoch 1478/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2062 - onoff_loss: 0.0162 - note_loss: 0.1013 - vel_loss: 0.0096 - time_loss: 7.9110e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 1479/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2017 - onoff_loss: 0.0156 - note_loss: 0.0948 - vel_loss: 0.0096 - time_loss: 8.1580e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 1480/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2005 - onoff_loss: 0.0155 - note_loss: 0.0969 - vel_loss: 0.0092 - time_loss: 7.8951e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1706\n",
            "Epoch 1481/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1990 - onoff_loss: 0.0166 - note_loss: 0.0975 - vel_loss: 0.0096 - time_loss: 7.5346e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1831\n",
            "Epoch 1482/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2205 - onoff_loss: 0.0188 - note_loss: 0.1023 - vel_loss: 0.0101 - time_loss: 8.9263e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9737 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 1483/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2226 - onoff_loss: 0.0169 - note_loss: 0.0972 - vel_loss: 0.0095 - time_loss: 9.8967e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9746 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1740\n",
            "Epoch 1484/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2172 - onoff_loss: 0.0153 - note_loss: 0.0983 - vel_loss: 0.0094 - time_loss: 9.4141e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1719\n",
            "Epoch 1485/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2052 - onoff_loss: 0.0177 - note_loss: 0.1004 - vel_loss: 0.0099 - time_loss: 7.7243e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1628\n",
            "Epoch 1486/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1866 - onoff_loss: 0.0156 - note_loss: 0.0940 - vel_loss: 0.0095 - time_loss: 6.7493e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1799\n",
            "Epoch 1487/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2022 - onoff_loss: 0.0168 - note_loss: 0.0996 - vel_loss: 0.0101 - time_loss: 7.5748e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9741 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1584\n",
            "Epoch 1488/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2025 - onoff_loss: 0.0155 - note_loss: 0.0986 - vel_loss: 0.0093 - time_loss: 7.9126e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1626\n",
            "Epoch 1489/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2030 - onoff_loss: 0.0165 - note_loss: 0.0947 - vel_loss: 0.0101 - time_loss: 8.1695e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 1490/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1911 - onoff_loss: 0.0157 - note_loss: 0.0976 - vel_loss: 0.0094 - time_loss: 6.8413e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1767\n",
            "Epoch 1491/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2125 - onoff_loss: 0.0163 - note_loss: 0.0987 - vel_loss: 0.0100 - time_loss: 8.7502e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1633\n",
            "Epoch 1492/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.1992 - onoff_loss: 0.0166 - note_loss: 0.1024 - vel_loss: 0.0098 - time_loss: 7.0448e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1666\n",
            "Epoch 1493/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2094 - onoff_loss: 0.0164 - note_loss: 0.0988 - vel_loss: 0.0099 - time_loss: 8.4319e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 1494/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2105 - onoff_loss: 0.0161 - note_loss: 0.1000 - vel_loss: 0.0099 - time_loss: 8.4554e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1888\n",
            "Epoch 1495/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1902 - onoff_loss: 0.0154 - note_loss: 0.0964 - vel_loss: 0.0092 - time_loss: 6.9222e-05 - onoff_accuracy: 0.9931 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1756\n",
            "Epoch 1496/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2219 - onoff_loss: 0.0165 - note_loss: 0.0944 - vel_loss: 0.0099 - time_loss: 1.0107e-04 - onoff_accuracy: 0.9921 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 1497/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2107 - onoff_loss: 0.0165 - note_loss: 0.0970 - vel_loss: 0.0094 - time_loss: 8.7772e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9747 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1642\n",
            "Epoch 1498/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1857 - onoff_loss: 0.0166 - note_loss: 0.0936 - vel_loss: 0.0104 - time_loss: 6.5091e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1929\n",
            "Epoch 1499/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2142 - onoff_loss: 0.0161 - note_loss: 0.0990 - vel_loss: 0.0098 - time_loss: 8.9359e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 1500/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2107 - onoff_loss: 0.0157 - note_loss: 0.0998 - vel_loss: 0.0095 - time_loss: 8.5714e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1692\n",
            "Epoch 1501/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1901 - onoff_loss: 0.0167 - note_loss: 0.0995 - vel_loss: 0.0094 - time_loss: 6.4379e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1502/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2140 - onoff_loss: 0.0154 - note_loss: 0.0977 - vel_loss: 0.0095 - time_loss: 9.1462e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1712\n",
            "Epoch 1503/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1967 - onoff_loss: 0.0161 - note_loss: 0.0926 - vel_loss: 0.0102 - time_loss: 7.7812e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9761 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1668\n",
            "Epoch 1504/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2065 - onoff_loss: 0.0167 - note_loss: 0.0974 - vel_loss: 0.0100 - time_loss: 8.2397e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1802\n",
            "Epoch 1505/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2084 - onoff_loss: 0.0166 - note_loss: 0.0994 - vel_loss: 0.0093 - time_loss: 8.3033e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1577\n",
            "Epoch 1506/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1807 - onoff_loss: 0.0166 - note_loss: 0.0976 - vel_loss: 0.0094 - time_loss: 5.7092e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1807\n",
            "Epoch 1507/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2132 - onoff_loss: 0.0166 - note_loss: 0.1014 - vel_loss: 0.0100 - time_loss: 8.5220e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9735 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1928\n",
            "Epoch 1508/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1851 - onoff_loss: 0.0158 - note_loss: 0.0967 - vel_loss: 0.0093 - time_loss: 6.3338e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1667\n",
            "Epoch 1509/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2001 - onoff_loss: 0.0173 - note_loss: 0.0971 - vel_loss: 0.0091 - time_loss: 7.6643e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1620\n",
            "Epoch 1510/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2020 - onoff_loss: 0.0169 - note_loss: 0.1065 - vel_loss: 0.0092 - time_loss: 6.9395e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9726 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 1511/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2215 - onoff_loss: 0.0173 - note_loss: 0.1012 - vel_loss: 0.0099 - time_loss: 9.3070e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 1512/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1771 - onoff_loss: 0.0149 - note_loss: 0.0886 - vel_loss: 0.0093 - time_loss: 6.4424e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1607\n",
            "Epoch 1513/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1973 - onoff_loss: 0.0176 - note_loss: 0.0993 - vel_loss: 0.0096 - time_loss: 7.0745e-05 - onoff_accuracy: 0.9916 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1661\n",
            "Epoch 1514/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2188 - onoff_loss: 0.0170 - note_loss: 0.0975 - vel_loss: 0.0097 - time_loss: 9.4530e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9743 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1730\n",
            "Epoch 1515/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1966 - onoff_loss: 0.0161 - note_loss: 0.0953 - vel_loss: 0.0095 - time_loss: 7.5754e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1889\n",
            "Epoch 1516/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1854 - onoff_loss: 0.0162 - note_loss: 0.0981 - vel_loss: 0.0095 - time_loss: 6.1613e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1768\n",
            "Epoch 1517/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1960 - onoff_loss: 0.0165 - note_loss: 0.0957 - vel_loss: 0.0096 - time_loss: 7.4178e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1518/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2091 - onoff_loss: 0.0177 - note_loss: 0.0995 - vel_loss: 0.0099 - time_loss: 8.2056e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9743 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 1519/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1936 - onoff_loss: 0.0165 - note_loss: 0.0971 - vel_loss: 0.0089 - time_loss: 7.1054e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1586\n",
            "Epoch 1520/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1998 - onoff_loss: 0.0167 - note_loss: 0.0998 - vel_loss: 0.0097 - time_loss: 7.3612e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1680\n",
            "Epoch 1521/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1989 - onoff_loss: 0.0166 - note_loss: 0.0956 - vel_loss: 0.0093 - time_loss: 7.7336e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1787\n",
            "Epoch 1522/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1917 - onoff_loss: 0.0151 - note_loss: 0.0949 - vel_loss: 0.0098 - time_loss: 7.1825e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9758 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1843\n",
            "Epoch 1523/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2137 - onoff_loss: 0.0174 - note_loss: 0.1005 - vel_loss: 0.0101 - time_loss: 8.5652e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 1524/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1901 - onoff_loss: 0.0157 - note_loss: 0.0916 - vel_loss: 0.0096 - time_loss: 7.3234e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1815\n",
            "Epoch 1525/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1958 - onoff_loss: 0.0166 - note_loss: 0.0923 - vel_loss: 0.0096 - time_loss: 7.7201e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1761\n",
            "Epoch 1526/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1862 - onoff_loss: 0.0149 - note_loss: 0.0936 - vel_loss: 0.0094 - time_loss: 6.8298e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1635\n",
            "Epoch 1527/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1886 - onoff_loss: 0.0162 - note_loss: 0.0975 - vel_loss: 0.0098 - time_loss: 6.5129e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1914\n",
            "Epoch 1528/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2290 - onoff_loss: 0.0160 - note_loss: 0.1041 - vel_loss: 0.0093 - time_loss: 9.9618e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1591\n",
            "Epoch 1529/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1978 - onoff_loss: 0.0172 - note_loss: 0.0982 - vel_loss: 0.0096 - time_loss: 7.2861e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1778\n",
            "Epoch 1530/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2058 - onoff_loss: 0.0169 - note_loss: 0.0984 - vel_loss: 0.0096 - time_loss: 8.0947e-05 - onoff_accuracy: 0.9914 - note_accuracy: 0.9746 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 1531/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2178 - onoff_loss: 0.0158 - note_loss: 0.0980 - vel_loss: 0.0097 - time_loss: 9.4325e-05 - onoff_accuracy: 0.9930 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1855\n",
            "Epoch 1532/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2043 - onoff_loss: 0.0161 - note_loss: 0.0956 - vel_loss: 0.0094 - time_loss: 8.3237e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1925\n",
            "Epoch 1533/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2171 - onoff_loss: 0.0183 - note_loss: 0.0997 - vel_loss: 0.0097 - time_loss: 8.9343e-05 - onoff_accuracy: 0.9912 - note_accuracy: 0.9746 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1719\n",
            "Epoch 1534/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2124 - onoff_loss: 0.0166 - note_loss: 0.0951 - vel_loss: 0.0091 - time_loss: 9.1635e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1537\n",
            "Epoch 1535/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1913 - onoff_loss: 0.0153 - note_loss: 0.0943 - vel_loss: 0.0097 - time_loss: 7.2053e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1736\n",
            "Epoch 1536/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.2197 - onoff_loss: 0.0184 - note_loss: 0.1028 - vel_loss: 0.0091 - time_loss: 8.9356e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9730 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 1537/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1865 - onoff_loss: 0.0157 - note_loss: 0.0903 - vel_loss: 0.0100 - time_loss: 7.0514e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1828\n",
            "Epoch 1538/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2155 - onoff_loss: 0.0162 - note_loss: 0.0975 - vel_loss: 0.0095 - time_loss: 9.2271e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1769\n",
            "Epoch 1539/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1994 - onoff_loss: 0.0163 - note_loss: 0.0952 - vel_loss: 0.0091 - time_loss: 7.8819e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 1540/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2039 - onoff_loss: 0.0158 - note_loss: 0.0959 - vel_loss: 0.0094 - time_loss: 8.2736e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1707\n",
            "Epoch 1541/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2267 - onoff_loss: 0.0169 - note_loss: 0.1008 - vel_loss: 0.0097 - time_loss: 9.9315e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1926\n",
            "Epoch 1542/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.1825 - onoff_loss: 0.0159 - note_loss: 0.0930 - vel_loss: 0.0096 - time_loss: 6.3926e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1697\n",
            "Epoch 1543/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2016 - onoff_loss: 0.0162 - note_loss: 0.0937 - vel_loss: 0.0090 - time_loss: 8.2805e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1724\n",
            "Epoch 1544/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2126 - onoff_loss: 0.0174 - note_loss: 0.0988 - vel_loss: 0.0092 - time_loss: 8.7113e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9742 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1958\n",
            "Epoch 1545/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2050 - onoff_loss: 0.0166 - note_loss: 0.0999 - vel_loss: 0.0095 - time_loss: 7.9064e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9739 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1759\n",
            "Epoch 1546/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2022 - onoff_loss: 0.0160 - note_loss: 0.0932 - vel_loss: 0.0091 - time_loss: 8.3914e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1633\n",
            "Epoch 1547/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1845 - onoff_loss: 0.0160 - note_loss: 0.0982 - vel_loss: 0.0090 - time_loss: 6.1297e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1752\n",
            "Epoch 1548/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2008 - onoff_loss: 0.0172 - note_loss: 0.0992 - vel_loss: 0.0097 - time_loss: 7.4746e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1853\n",
            "Epoch 1549/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.2194 - onoff_loss: 0.0159 - note_loss: 0.0966 - vel_loss: 0.0089 - time_loss: 9.7955e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1630\n",
            "Epoch 1550/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1803 - onoff_loss: 0.0151 - note_loss: 0.0963 - vel_loss: 0.0093 - time_loss: 5.9648e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1828\n",
            "Epoch 1551/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1966 - onoff_loss: 0.0149 - note_loss: 0.0931 - vel_loss: 0.0093 - time_loss: 7.9285e-05 - onoff_accuracy: 0.9930 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 1552/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1795 - onoff_loss: 0.0155 - note_loss: 0.0924 - vel_loss: 0.0092 - time_loss: 6.2459e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9765 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1576\n",
            "Epoch 1553/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1872 - onoff_loss: 0.0179 - note_loss: 0.0978 - vel_loss: 0.0093 - time_loss: 6.2312e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1762\n",
            "Epoch 1554/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2030 - onoff_loss: 0.0161 - note_loss: 0.0983 - vel_loss: 0.0098 - time_loss: 7.8752e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1732\n",
            "Epoch 1555/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1885 - onoff_loss: 0.0160 - note_loss: 0.0967 - vel_loss: 0.0092 - time_loss: 6.6639e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1827\n",
            "Epoch 1556/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1935 - onoff_loss: 0.0159 - note_loss: 0.0925 - vel_loss: 0.0090 - time_loss: 7.6146e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 1557/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1741 - onoff_loss: 0.0146 - note_loss: 0.0919 - vel_loss: 0.0088 - time_loss: 5.8760e-05 - onoff_accuracy: 0.9932 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 1558/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2154 - onoff_loss: 0.0155 - note_loss: 0.0979 - vel_loss: 0.0096 - time_loss: 9.2417e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 1559/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2071 - onoff_loss: 0.0166 - note_loss: 0.0913 - vel_loss: 0.0096 - time_loss: 8.9534e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1560/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2204 - onoff_loss: 0.0159 - note_loss: 0.0957 - vel_loss: 0.0092 - time_loss: 9.9580e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1734\n",
            "Epoch 1561/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2023 - onoff_loss: 0.0162 - note_loss: 0.0984 - vel_loss: 0.0089 - time_loss: 7.8774e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1777\n",
            "Epoch 1562/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1854 - onoff_loss: 0.0170 - note_loss: 0.0900 - vel_loss: 0.0092 - time_loss: 6.9211e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 1563/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2013 - onoff_loss: 0.0161 - note_loss: 0.0955 - vel_loss: 0.0099 - time_loss: 7.9812e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1798\n",
            "Epoch 1564/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2060 - onoff_loss: 0.0162 - note_loss: 0.0958 - vel_loss: 0.0094 - time_loss: 8.4505e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9758 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1827\n",
            "Epoch 1565/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.2060 - onoff_loss: 0.0164 - note_loss: 0.0982 - vel_loss: 0.0093 - time_loss: 8.2108e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1658\n",
            "Epoch 1566/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2042 - onoff_loss: 0.0158 - note_loss: 0.0990 - vel_loss: 0.0094 - time_loss: 7.9988e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1729\n",
            "Epoch 1567/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2047 - onoff_loss: 0.0171 - note_loss: 0.1009 - vel_loss: 0.0093 - time_loss: 7.7432e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9738 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1639\n",
            "Epoch 1568/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2141 - onoff_loss: 0.0153 - note_loss: 0.0985 - vel_loss: 0.0093 - time_loss: 9.0912e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9744 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1625\n",
            "Epoch 1569/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1987 - onoff_loss: 0.0166 - note_loss: 0.1029 - vel_loss: 0.0094 - time_loss: 6.9771e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9740 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1838\n",
            "Epoch 1570/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1960 - onoff_loss: 0.0158 - note_loss: 0.0954 - vel_loss: 0.0098 - time_loss: 7.5101e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1796\n",
            "Epoch 1571/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1887 - onoff_loss: 0.0153 - note_loss: 0.0936 - vel_loss: 0.0094 - time_loss: 7.0385e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1749\n",
            "Epoch 1572/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1841 - onoff_loss: 0.0159 - note_loss: 0.0954 - vel_loss: 0.0097 - time_loss: 6.3113e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1714\n",
            "Epoch 1573/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1990 - onoff_loss: 0.0155 - note_loss: 0.0936 - vel_loss: 0.0094 - time_loss: 8.0501e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1681\n",
            "Epoch 1574/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2013 - onoff_loss: 0.0158 - note_loss: 0.0964 - vel_loss: 0.0098 - time_loss: 7.9313e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1900\n",
            "Epoch 1575/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2014 - onoff_loss: 0.0151 - note_loss: 0.0970 - vel_loss: 0.0092 - time_loss: 8.0170e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1722\n",
            "Epoch 1576/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2070 - onoff_loss: 0.0168 - note_loss: 0.1001 - vel_loss: 0.0092 - time_loss: 8.0896e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1613\n",
            "Epoch 1577/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.1962 - onoff_loss: 0.0163 - note_loss: 0.0948 - vel_loss: 0.0094 - time_loss: 7.5721e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1839\n",
            "Epoch 1578/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1905 - onoff_loss: 0.0152 - note_loss: 0.0927 - vel_loss: 0.0090 - time_loss: 7.3608e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 1579/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1921 - onoff_loss: 0.0171 - note_loss: 0.0988 - vel_loss: 0.0087 - time_loss: 6.7470e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1702\n",
            "Epoch 1580/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1911 - onoff_loss: 0.0156 - note_loss: 0.0935 - vel_loss: 0.0093 - time_loss: 7.2758e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1581/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.1865 - onoff_loss: 0.0158 - note_loss: 0.0991 - vel_loss: 0.0097 - time_loss: 6.1886e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.2020\n",
            "Epoch 1582/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1822 - onoff_loss: 0.0164 - note_loss: 0.0957 - vel_loss: 0.0097 - time_loss: 6.0381e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1769\n",
            "Epoch 1583/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1996 - onoff_loss: 0.0155 - note_loss: 0.0922 - vel_loss: 0.0099 - time_loss: 8.2086e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1750\n",
            "Epoch 1584/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2010 - onoff_loss: 0.0183 - note_loss: 0.0951 - vel_loss: 0.0090 - time_loss: 7.8508e-05 - onoff_accuracy: 0.9913 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 1585/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1906 - onoff_loss: 0.0167 - note_loss: 0.0957 - vel_loss: 0.0090 - time_loss: 6.9211e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1815\n",
            "Epoch 1586/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1998 - onoff_loss: 0.0153 - note_loss: 0.0945 - vel_loss: 0.0086 - time_loss: 8.1345e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9750 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1653\n",
            "Epoch 1587/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1973 - onoff_loss: 0.0164 - note_loss: 0.0983 - vel_loss: 0.0090 - time_loss: 7.3578e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1744\n",
            "Epoch 1588/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2069 - onoff_loss: 0.0162 - note_loss: 0.0963 - vel_loss: 0.0092 - time_loss: 8.5281e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1828\n",
            "Epoch 1589/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1967 - onoff_loss: 0.0167 - note_loss: 0.0959 - vel_loss: 0.0095 - time_loss: 7.4611e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1654\n",
            "Epoch 1590/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1866 - onoff_loss: 0.0155 - note_loss: 0.0927 - vel_loss: 0.0089 - time_loss: 6.9498e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1920\n",
            "Epoch 1591/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1927 - onoff_loss: 0.0149 - note_loss: 0.0929 - vel_loss: 0.0088 - time_loss: 7.6173e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823\n",
            "Epoch 1592/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2015 - onoff_loss: 0.0152 - note_loss: 0.0923 - vel_loss: 0.0092 - time_loss: 8.4699e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1797\n",
            "Epoch 1593/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1962 - onoff_loss: 0.0168 - note_loss: 0.0985 - vel_loss: 0.0091 - time_loss: 7.1795e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9746 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 1594/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2003 - onoff_loss: 0.0154 - note_loss: 0.0993 - vel_loss: 0.0092 - time_loss: 7.6380e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9745 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1776\n",
            "Epoch 1595/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1903 - onoff_loss: 0.0157 - note_loss: 0.0940 - vel_loss: 0.0087 - time_loss: 7.1894e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1660\n",
            "Epoch 1596/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1861 - onoff_loss: 0.0165 - note_loss: 0.0980 - vel_loss: 0.0090 - time_loss: 6.2544e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9743 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1904\n",
            "Epoch 1597/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1953 - onoff_loss: 0.0154 - note_loss: 0.0912 - vel_loss: 0.0094 - time_loss: 7.9378e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1761\n",
            "Epoch 1598/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1984 - onoff_loss: 0.0165 - note_loss: 0.0953 - vel_loss: 0.0094 - time_loss: 7.7253e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1713\n",
            "Epoch 1599/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1926 - onoff_loss: 0.0160 - note_loss: 0.0947 - vel_loss: 0.0089 - time_loss: 7.3021e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1582\n",
            "Epoch 1600/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1964 - onoff_loss: 0.0153 - note_loss: 0.0916 - vel_loss: 0.0095 - time_loss: 7.9941e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1697\n",
            "Epoch 1601/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2015 - onoff_loss: 0.0165 - note_loss: 0.0935 - vel_loss: 0.0088 - time_loss: 8.2626e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1677\n",
            "Epoch 1602/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1889 - onoff_loss: 0.0155 - note_loss: 0.0946 - vel_loss: 0.0089 - time_loss: 6.9901e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1634\n",
            "Epoch 1603/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2012 - onoff_loss: 0.0158 - note_loss: 0.0981 - vel_loss: 0.0090 - time_loss: 7.8224e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1834\n",
            "Epoch 1604/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2059 - onoff_loss: 0.0168 - note_loss: 0.0971 - vel_loss: 0.0095 - time_loss: 8.2418e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9752 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1711\n",
            "Epoch 1605/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1903 - onoff_loss: 0.0159 - note_loss: 0.0943 - vel_loss: 0.0093 - time_loss: 7.0825e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1848\n",
            "Epoch 1606/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1848 - onoff_loss: 0.0152 - note_loss: 0.0933 - vel_loss: 0.0087 - time_loss: 6.7526e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1607/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2082 - onoff_loss: 0.0165 - note_loss: 0.1014 - vel_loss: 0.0092 - time_loss: 8.1018e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9746 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1847\n",
            "Epoch 1608/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1957 - onoff_loss: 0.0171 - note_loss: 0.0996 - vel_loss: 0.0090 - time_loss: 7.0032e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9743 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1609/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1833 - onoff_loss: 0.0159 - note_loss: 0.0910 - vel_loss: 0.0091 - time_loss: 6.7243e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 1610/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2062 - onoff_loss: 0.0165 - note_loss: 0.0932 - vel_loss: 0.0089 - time_loss: 8.7562e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1697\n",
            "Epoch 1611/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1740 - onoff_loss: 0.0159 - note_loss: 0.0932 - vel_loss: 0.0088 - time_loss: 5.6004e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1811\n",
            "Epoch 1612/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1977 - onoff_loss: 0.0154 - note_loss: 0.0941 - vel_loss: 0.0088 - time_loss: 7.9359e-05 - onoff_accuracy: 0.9929 - note_accuracy: 0.9758 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1665\n",
            "Epoch 1613/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1821 - onoff_loss: 0.0149 - note_loss: 0.0942 - vel_loss: 0.0087 - time_loss: 6.4233e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9753 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1631\n",
            "Epoch 1614/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1915 - onoff_loss: 0.0166 - note_loss: 0.0965 - vel_loss: 0.0095 - time_loss: 6.8971e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1898\n",
            "Epoch 1615/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2083 - onoff_loss: 0.0171 - note_loss: 0.0967 - vel_loss: 0.0087 - time_loss: 8.5867e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1728\n",
            "Epoch 1616/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2167 - onoff_loss: 0.0161 - note_loss: 0.0929 - vel_loss: 0.0089 - time_loss: 9.8637e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1546\n",
            "Epoch 1617/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2008 - onoff_loss: 0.0150 - note_loss: 0.0912 - vel_loss: 0.0088 - time_loss: 8.5784e-05 - onoff_accuracy: 0.9931 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1775\n",
            "Epoch 1618/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1985 - onoff_loss: 0.0149 - note_loss: 0.0899 - vel_loss: 0.0086 - time_loss: 8.5184e-05 - onoff_accuracy: 0.9930 - note_accuracy: 0.9765 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1499\n",
            "Epoch 1619/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1723 - onoff_loss: 0.0149 - note_loss: 0.0927 - vel_loss: 0.0089 - time_loss: 5.5753e-05 - onoff_accuracy: 0.9932 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1773\n",
            "Epoch 1620/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1866 - onoff_loss: 0.0162 - note_loss: 0.0951 - vel_loss: 0.0090 - time_loss: 6.6358e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9755 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1719\n",
            "Epoch 1621/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1985 - onoff_loss: 0.0166 - note_loss: 0.0916 - vel_loss: 0.0088 - time_loss: 8.1489e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9766 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1695\n",
            "Epoch 1622/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1793 - onoff_loss: 0.0162 - note_loss: 0.0937 - vel_loss: 0.0091 - time_loss: 6.0259e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9755 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1879\n",
            "Epoch 1623/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1912 - onoff_loss: 0.0159 - note_loss: 0.0916 - vel_loss: 0.0089 - time_loss: 7.4786e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1704\n",
            "Epoch 1624/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1783 - onoff_loss: 0.0151 - note_loss: 0.0905 - vel_loss: 0.0089 - time_loss: 6.3760e-05 - onoff_accuracy: 0.9929 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1821\n",
            "Epoch 1625/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2018 - onoff_loss: 0.0152 - note_loss: 0.0951 - vel_loss: 0.0096 - time_loss: 8.1938e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9751 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1826\n",
            "Epoch 1626/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1911 - onoff_loss: 0.0161 - note_loss: 0.0954 - vel_loss: 0.0086 - time_loss: 7.1027e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9748 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1672\n",
            "Epoch 1627/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2016 - onoff_loss: 0.0167 - note_loss: 0.1020 - vel_loss: 0.0094 - time_loss: 7.3500e-05 - onoff_accuracy: 0.9920 - note_accuracy: 0.9734 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1984\n",
            "Epoch 1628/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1793 - onoff_loss: 0.0151 - note_loss: 0.0919 - vel_loss: 0.0087 - time_loss: 6.3672e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1885\n",
            "Epoch 1629/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2203 - onoff_loss: 0.0165 - note_loss: 0.0901 - vel_loss: 0.0084 - time_loss: 1.0526e-04 - onoff_accuracy: 0.9928 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1632\n",
            "Epoch 1630/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1885 - onoff_loss: 0.0153 - note_loss: 0.0946 - vel_loss: 0.0090 - time_loss: 6.9578e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9755 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1859\n",
            "Epoch 1631/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1870 - onoff_loss: 0.0144 - note_loss: 0.0899 - vel_loss: 0.0087 - time_loss: 7.4079e-05 - onoff_accuracy: 0.9930 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 1632/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1686 - onoff_loss: 0.0152 - note_loss: 0.0875 - vel_loss: 0.0088 - time_loss: 5.7085e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1772\n",
            "Epoch 1633/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2168 - onoff_loss: 0.0184 - note_loss: 0.1028 - vel_loss: 0.0089 - time_loss: 8.6696e-05 - onoff_accuracy: 0.9915 - note_accuracy: 0.9729 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1720\n",
            "Epoch 1634/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1829 - onoff_loss: 0.0167 - note_loss: 0.0937 - vel_loss: 0.0087 - time_loss: 6.3729e-05 - onoff_accuracy: 0.9918 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1791\n",
            "Epoch 1635/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2004 - onoff_loss: 0.0161 - note_loss: 0.0921 - vel_loss: 0.0093 - time_loss: 8.2869e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1807\n",
            "Epoch 1636/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1949 - onoff_loss: 0.0154 - note_loss: 0.0891 - vel_loss: 0.0091 - time_loss: 8.1237e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1690\n",
            "Epoch 1637/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1955 - onoff_loss: 0.0159 - note_loss: 0.0919 - vel_loss: 0.0088 - time_loss: 7.8830e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9761 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1747\n",
            "Epoch 1638/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1807 - onoff_loss: 0.0154 - note_loss: 0.0938 - vel_loss: 0.0090 - time_loss: 6.2450e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1842\n",
            "Epoch 1639/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1937 - onoff_loss: 0.0162 - note_loss: 0.0948 - vel_loss: 0.0087 - time_loss: 7.3964e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1688\n",
            "Epoch 1640/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1952 - onoff_loss: 0.0148 - note_loss: 0.0915 - vel_loss: 0.0092 - time_loss: 7.9756e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9766 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1917\n",
            "Epoch 1641/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1956 - onoff_loss: 0.0165 - note_loss: 0.0949 - vel_loss: 0.0094 - time_loss: 7.4795e-05 - onoff_accuracy: 0.9917 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1652\n",
            "Epoch 1642/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1822 - onoff_loss: 0.0155 - note_loss: 0.0897 - vel_loss: 0.0093 - time_loss: 6.7739e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9770 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1841\n",
            "Epoch 1643/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1946 - onoff_loss: 0.0169 - note_loss: 0.0962 - vel_loss: 0.0093 - time_loss: 7.2115e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1790\n",
            "Epoch 1644/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1971 - onoff_loss: 0.0152 - note_loss: 0.0928 - vel_loss: 0.0084 - time_loss: 8.0624e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9761 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1825\n",
            "Epoch 1645/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1765 - onoff_loss: 0.0149 - note_loss: 0.0909 - vel_loss: 0.0088 - time_loss: 6.1880e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9765 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1580\n",
            "Epoch 1646/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1893 - onoff_loss: 0.0158 - note_loss: 0.0923 - vel_loss: 0.0087 - time_loss: 7.2434e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9761 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1715\n",
            "Epoch 1647/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1896 - onoff_loss: 0.0154 - note_loss: 0.0881 - vel_loss: 0.0088 - time_loss: 7.7346e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1584\n",
            "Epoch 1648/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1896 - onoff_loss: 0.0155 - note_loss: 0.0872 - vel_loss: 0.0093 - time_loss: 7.7592e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9773 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1715\n",
            "Epoch 1649/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1881 - onoff_loss: 0.0157 - note_loss: 0.0906 - vel_loss: 0.0087 - time_loss: 7.3124e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9769 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 1650/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2082 - onoff_loss: 0.0159 - note_loss: 0.0959 - vel_loss: 0.0089 - time_loss: 8.7461e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1850\n",
            "Epoch 1651/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1981 - onoff_loss: 0.0161 - note_loss: 0.0984 - vel_loss: 0.0091 - time_loss: 7.4573e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9746 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1901\n",
            "Epoch 1652/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1855 - onoff_loss: 0.0165 - note_loss: 0.0915 - vel_loss: 0.0089 - time_loss: 6.8593e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9760 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1657\n",
            "Epoch 1653/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1698 - onoff_loss: 0.0143 - note_loss: 0.0898 - vel_loss: 0.0087 - time_loss: 5.6924e-05 - onoff_accuracy: 0.9929 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1781\n",
            "Epoch 1654/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1984 - onoff_loss: 0.0165 - note_loss: 0.0970 - vel_loss: 0.0090 - time_loss: 7.5799e-05 - onoff_accuracy: 0.9922 - note_accuracy: 0.9755 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1643\n",
            "Epoch 1655/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1980 - onoff_loss: 0.0151 - note_loss: 0.0916 - vel_loss: 0.0090 - time_loss: 8.2314e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1623\n",
            "Epoch 1656/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.2099 - onoff_loss: 0.0162 - note_loss: 0.0941 - vel_loss: 0.0089 - time_loss: 9.0764e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9756 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1579\n",
            "Epoch 1657/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1861 - onoff_loss: 0.0158 - note_loss: 0.0936 - vel_loss: 0.0089 - time_loss: 6.7907e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1804\n",
            "Epoch 1658/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1893 - onoff_loss: 0.0156 - note_loss: 0.0931 - vel_loss: 0.0084 - time_loss: 7.2214e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9757 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1679\n",
            "Epoch 1659/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1752 - onoff_loss: 0.0160 - note_loss: 0.0912 - vel_loss: 0.0088 - time_loss: 5.9179e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9765 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1602\n",
            "Epoch 1660/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2017 - onoff_loss: 0.0157 - note_loss: 0.0933 - vel_loss: 0.0084 - time_loss: 8.4316e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1796\n",
            "Epoch 1661/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1960 - onoff_loss: 0.0147 - note_loss: 0.0900 - vel_loss: 0.0090 - time_loss: 8.2274e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1854\n",
            "Epoch 1662/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1966 - onoff_loss: 0.0157 - note_loss: 0.0986 - vel_loss: 0.0086 - time_loss: 7.3604e-05 - onoff_accuracy: 0.9931 - note_accuracy: 0.9754 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1699\n",
            "Epoch 1663/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1901 - onoff_loss: 0.0159 - note_loss: 0.0935 - vel_loss: 0.0085 - time_loss: 7.2185e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1623\n",
            "Epoch 1664/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.2098 - onoff_loss: 0.0185 - note_loss: 0.1097 - vel_loss: 0.0089 - time_loss: 7.2671e-05 - onoff_accuracy: 0.9908 - note_accuracy: 0.9717 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1716\n",
            "Epoch 1665/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1957 - onoff_loss: 0.0156 - note_loss: 0.0932 - vel_loss: 0.0092 - time_loss: 7.7686e-05 - onoff_accuracy: 0.9924 - note_accuracy: 0.9761 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1708\n",
            "Epoch 1666/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1741 - onoff_loss: 0.0156 - note_loss: 0.0895 - vel_loss: 0.0087 - time_loss: 6.0210e-05 - onoff_accuracy: 0.9923 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1731\n",
            "Epoch 1667/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1750 - onoff_loss: 0.0149 - note_loss: 0.0876 - vel_loss: 0.0095 - time_loss: 6.2968e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9771 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1829\n",
            "Epoch 1668/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1686 - onoff_loss: 0.0151 - note_loss: 0.0883 - vel_loss: 0.0086 - time_loss: 5.6619e-05 - onoff_accuracy: 0.9928 - note_accuracy: 0.9775 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1721\n",
            "Epoch 1669/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.1928 - onoff_loss: 0.0162 - note_loss: 0.0891 - vel_loss: 0.0086 - time_loss: 7.8887e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9767 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1705\n",
            "Epoch 1670/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1924 - onoff_loss: 0.0164 - note_loss: 0.0922 - vel_loss: 0.0089 - time_loss: 7.4764e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9769 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1693\n",
            "Epoch 1671/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.1968 - onoff_loss: 0.0165 - note_loss: 0.0935 - vel_loss: 0.0089 - time_loss: 7.7829e-05 - onoff_accuracy: 0.9919 - note_accuracy: 0.9759 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1557\n",
            "Epoch 1672/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.1759 - onoff_loss: 0.0147 - note_loss: 0.0893 - vel_loss: 0.0088 - time_loss: 6.3205e-05 - onoff_accuracy: 0.9934 - note_accuracy: 0.9764 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1924\n",
            "Epoch 1673/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1770 - onoff_loss: 0.0145 - note_loss: 0.0922 - vel_loss: 0.0087 - time_loss: 6.1649e-05 - onoff_accuracy: 0.9925 - note_accuracy: 0.9762 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1665\n",
            "Epoch 1674/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.1996 - onoff_loss: 0.0161 - note_loss: 0.0933 - vel_loss: 0.0097 - time_loss: 8.0551e-05 - onoff_accuracy: 0.9921 - note_accuracy: 0.9755 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1986\n",
            "Epoch 1675/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1989 - onoff_loss: 0.0152 - note_loss: 0.1011 - vel_loss: 0.0086 - time_loss: 7.3927e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9749 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1782\n",
            "Epoch 1676/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1817 - onoff_loss: 0.0147 - note_loss: 0.0910 - vel_loss: 0.0087 - time_loss: 6.7306e-05 - onoff_accuracy: 0.9926 - note_accuracy: 0.9765 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1969\n",
            "Epoch 1677/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.1820 - onoff_loss: 0.0146 - note_loss: 0.0889 - vel_loss: 0.0090 - time_loss: 6.9447e-05 - onoff_accuracy: 0.9932 - note_accuracy: 0.9768 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1709\n",
            "Epoch 1678/2560\n",
            "n_samples =168\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.1724 - onoff_loss: 0.0150 - note_loss: 0.0866 - vel_loss: 0.0087 - time_loss: 6.2133e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9775 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1727\n",
            "Epoch 1679/2560\n",
            "n_samples =168\n",
            " 3/10 [========>.....................] - ETA: 0s - loss: 0.1822 - onoff_loss: 0.0161 - note_loss: 0.0917 - vel_loss: 0.0099 - time_loss: 6.4508e-05 - onoff_accuracy: 0.9927 - note_accuracy: 0.9763 - vel_accuracy: 0.0000e+00 - time_accuracy: 0.1823"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-22e61583f5a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logs/fit/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'trained_midi_{MidiNet.n_input}.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK0joTywicmZ"
      },
      "source": [
        "model.save(f'trained_midi_{MidiNet.n_input}.h5', save_format=\"h5\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDcXKrpFigJH"
      },
      "source": [
        "history = model.history"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pP98UmQl_gB",
        "outputId": "42811e6f-c843-4609-ac58-3c2d224d4099"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'onoff_loss', 'note_loss', 'vel_loss', 'time_loss', 'onoff_accuracy', 'note_accuracy', 'vel_accuracy', 'time_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dan-chKsvbU"
      },
      "source": [
        "def draw_history(hist):\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "  axs[0].plot(hist.epoch, hist.history['loss'])\n",
        "  axs[0].plot(hist.epoch, hist.history['onoff_loss'])\n",
        "  axs[0].plot(hist.epoch, hist.history['note_loss'])\n",
        "  axs[0].plot(hist.epoch, hist.history['vel_loss'])\n",
        "  axs[0].plot(hist.epoch, hist.history['time_loss'])\n",
        "  \n",
        "  if 'val_loss' in hist.history:\n",
        "    axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
        "  axs[0].legend(('training loss', 'validation loss'))\n",
        "  axs[1].plot(hist.epoch, hist.history['onoff_accuracy'])\n",
        "  axs[1].plot(hist.epoch, hist.history['note_accuracy'])\n",
        "  axs[1].plot(hist.epoch, hist.history['vel_accuracy'])\n",
        "  axs[1].plot(hist.epoch, hist.history['time_accuracy'])\n",
        "  if 'val_accuracy' in hist.history:\n",
        "    axs[1].plot(hist.epoch, hist.history['val_accuracy'])\n",
        "\n",
        "  axs[1].legend(('training accuracy', 'validation accuracy'))\n",
        "  plt.show()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAJu4rMys3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "51746a1a-675c-4657-a3c6-686224a91818"
      },
      "source": [
        "draw_history(history)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BldvImFYfm4"
      },
      "source": [
        "## 6. Generating text with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3kuXO1jYu-a"
      },
      "source": [
        "Take word sequence and generate the following 128 words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9jHhASWNSYW",
        "outputId": "f523ebda-8337-44ab-f933-be9c9c624d23"
      },
      "source": [
        "MidiNet.n_input, n_pars"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyTL_hrbxwj-"
      },
      "source": [
        "def gen_long(model, in_seq, n_smpl=4096):\n",
        "  out = list(in_seq.copy())\n",
        "  for i in range(n_smpl):\n",
        "      print(f'{i}/{n_smpl}')\n",
        "      keys = np.array(out[-MidiNet.n_input:])[np.newaxis]\n",
        "      #print(keys.shape)\n",
        "\n",
        "      pred_tf = model(keys)\n",
        "      pred = concat_pred(pred_tf)\n",
        "      #print(pred.shape)\n",
        "      \n",
        "      pred_next = pred[0, -1, :]\n",
        "      #print(pred_next.shape)\n",
        "\n",
        "      out.append(pred_next)\n",
        "    \n",
        "  return out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs1lc2Gun4yR"
      },
      "source": [
        "def gen_long_inf(model, in_seq, n_smpl=4096):\r\n",
        "  out = list(in_seq.copy())\r\n",
        "  for i in range(n_smpl):\r\n",
        "      print(f'{i}/{n_smpl}')\r\n",
        "      keys = np.array(out)[np.newaxis]\r\n",
        "      #print(keys.shape)\r\n",
        "\r\n",
        "      pred_tf = model(keys)\r\n",
        "      pred = concat_pred(pred_tf)\r\n",
        "      #print(pred.shape)\r\n",
        "      \r\n",
        "      pred_next = pred[0, -1, :]\r\n",
        "      #print(pred_next.shape)\r\n",
        "\r\n",
        "      out.append(pred_next)\r\n",
        "    \r\n",
        "  return out"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyzaQIkhj7v5",
        "outputId": "ed3d90ff-3a36-4be5-95e4-d67b40ad49f6"
      },
      "source": [
        "input_example_batch.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 512, 132])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7gzaQ1FyRCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044a87bf-5944-4b16-fa42-c45c3862a9b0"
      },
      "source": [
        "seqs = []\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  input_seq_n = input_example_batch.numpy()\n",
        "  for i, input_seq in enumerate(input_seq_n): # 1 sample\n",
        "    print(f'\\n\\nsample {i}:')\n",
        "    out_seq = gen_long(model, input_seq)\n",
        "    seqs.append(out_seq)\n",
        "    if i>=5:\n",
        "      break"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "3195/4096\n",
            "3196/4096\n",
            "3197/4096\n",
            "3198/4096\n",
            "3199/4096\n",
            "3200/4096\n",
            "3201/4096\n",
            "3202/4096\n",
            "3203/4096\n",
            "3204/4096\n",
            "3205/4096\n",
            "3206/4096\n",
            "3207/4096\n",
            "3208/4096\n",
            "3209/4096\n",
            "3210/4096\n",
            "3211/4096\n",
            "3212/4096\n",
            "3213/4096\n",
            "3214/4096\n",
            "3215/4096\n",
            "3216/4096\n",
            "3217/4096\n",
            "3218/4096\n",
            "3219/4096\n",
            "3220/4096\n",
            "3221/4096\n",
            "3222/4096\n",
            "3223/4096\n",
            "3224/4096\n",
            "3225/4096\n",
            "3226/4096\n",
            "3227/4096\n",
            "3228/4096\n",
            "3229/4096\n",
            "3230/4096\n",
            "3231/4096\n",
            "3232/4096\n",
            "3233/4096\n",
            "3234/4096\n",
            "3235/4096\n",
            "3236/4096\n",
            "3237/4096\n",
            "3238/4096\n",
            "3239/4096\n",
            "3240/4096\n",
            "3241/4096\n",
            "3242/4096\n",
            "3243/4096\n",
            "3244/4096\n",
            "3245/4096\n",
            "3246/4096\n",
            "3247/4096\n",
            "3248/4096\n",
            "3249/4096\n",
            "3250/4096\n",
            "3251/4096\n",
            "3252/4096\n",
            "3253/4096\n",
            "3254/4096\n",
            "3255/4096\n",
            "3256/4096\n",
            "3257/4096\n",
            "3258/4096\n",
            "3259/4096\n",
            "3260/4096\n",
            "3261/4096\n",
            "3262/4096\n",
            "3263/4096\n",
            "3264/4096\n",
            "3265/4096\n",
            "3266/4096\n",
            "3267/4096\n",
            "3268/4096\n",
            "3269/4096\n",
            "3270/4096\n",
            "3271/4096\n",
            "3272/4096\n",
            "3273/4096\n",
            "3274/4096\n",
            "3275/4096\n",
            "3276/4096\n",
            "3277/4096\n",
            "3278/4096\n",
            "3279/4096\n",
            "3280/4096\n",
            "3281/4096\n",
            "3282/4096\n",
            "3283/4096\n",
            "3284/4096\n",
            "3285/4096\n",
            "3286/4096\n",
            "3287/4096\n",
            "3288/4096\n",
            "3289/4096\n",
            "3290/4096\n",
            "3291/4096\n",
            "3292/4096\n",
            "3293/4096\n",
            "3294/4096\n",
            "3295/4096\n",
            "3296/4096\n",
            "3297/4096\n",
            "3298/4096\n",
            "3299/4096\n",
            "3300/4096\n",
            "3301/4096\n",
            "3302/4096\n",
            "3303/4096\n",
            "3304/4096\n",
            "3305/4096\n",
            "3306/4096\n",
            "3307/4096\n",
            "3308/4096\n",
            "3309/4096\n",
            "3310/4096\n",
            "3311/4096\n",
            "3312/4096\n",
            "3313/4096\n",
            "3314/4096\n",
            "3315/4096\n",
            "3316/4096\n",
            "3317/4096\n",
            "3318/4096\n",
            "3319/4096\n",
            "3320/4096\n",
            "3321/4096\n",
            "3322/4096\n",
            "3323/4096\n",
            "3324/4096\n",
            "3325/4096\n",
            "3326/4096\n",
            "3327/4096\n",
            "3328/4096\n",
            "3329/4096\n",
            "3330/4096\n",
            "3331/4096\n",
            "3332/4096\n",
            "3333/4096\n",
            "3334/4096\n",
            "3335/4096\n",
            "3336/4096\n",
            "3337/4096\n",
            "3338/4096\n",
            "3339/4096\n",
            "3340/4096\n",
            "3341/4096\n",
            "3342/4096\n",
            "3343/4096\n",
            "3344/4096\n",
            "3345/4096\n",
            "3346/4096\n",
            "3347/4096\n",
            "3348/4096\n",
            "3349/4096\n",
            "3350/4096\n",
            "3351/4096\n",
            "3352/4096\n",
            "3353/4096\n",
            "3354/4096\n",
            "3355/4096\n",
            "3356/4096\n",
            "3357/4096\n",
            "3358/4096\n",
            "3359/4096\n",
            "3360/4096\n",
            "3361/4096\n",
            "3362/4096\n",
            "3363/4096\n",
            "3364/4096\n",
            "3365/4096\n",
            "3366/4096\n",
            "3367/4096\n",
            "3368/4096\n",
            "3369/4096\n",
            "3370/4096\n",
            "3371/4096\n",
            "3372/4096\n",
            "3373/4096\n",
            "3374/4096\n",
            "3375/4096\n",
            "3376/4096\n",
            "3377/4096\n",
            "3378/4096\n",
            "3379/4096\n",
            "3380/4096\n",
            "3381/4096\n",
            "3382/4096\n",
            "3383/4096\n",
            "3384/4096\n",
            "3385/4096\n",
            "3386/4096\n",
            "3387/4096\n",
            "3388/4096\n",
            "3389/4096\n",
            "3390/4096\n",
            "3391/4096\n",
            "3392/4096\n",
            "3393/4096\n",
            "3394/4096\n",
            "3395/4096\n",
            "3396/4096\n",
            "3397/4096\n",
            "3398/4096\n",
            "3399/4096\n",
            "3400/4096\n",
            "3401/4096\n",
            "3402/4096\n",
            "3403/4096\n",
            "3404/4096\n",
            "3405/4096\n",
            "3406/4096\n",
            "3407/4096\n",
            "3408/4096\n",
            "3409/4096\n",
            "3410/4096\n",
            "3411/4096\n",
            "3412/4096\n",
            "3413/4096\n",
            "3414/4096\n",
            "3415/4096\n",
            "3416/4096\n",
            "3417/4096\n",
            "3418/4096\n",
            "3419/4096\n",
            "3420/4096\n",
            "3421/4096\n",
            "3422/4096\n",
            "3423/4096\n",
            "3424/4096\n",
            "3425/4096\n",
            "3426/4096\n",
            "3427/4096\n",
            "3428/4096\n",
            "3429/4096\n",
            "3430/4096\n",
            "3431/4096\n",
            "3432/4096\n",
            "3433/4096\n",
            "3434/4096\n",
            "3435/4096\n",
            "3436/4096\n",
            "3437/4096\n",
            "3438/4096\n",
            "3439/4096\n",
            "3440/4096\n",
            "3441/4096\n",
            "3442/4096\n",
            "3443/4096\n",
            "3444/4096\n",
            "3445/4096\n",
            "3446/4096\n",
            "3447/4096\n",
            "3448/4096\n",
            "3449/4096\n",
            "3450/4096\n",
            "3451/4096\n",
            "3452/4096\n",
            "3453/4096\n",
            "3454/4096\n",
            "3455/4096\n",
            "3456/4096\n",
            "3457/4096\n",
            "3458/4096\n",
            "3459/4096\n",
            "3460/4096\n",
            "3461/4096\n",
            "3462/4096\n",
            "3463/4096\n",
            "3464/4096\n",
            "3465/4096\n",
            "3466/4096\n",
            "3467/4096\n",
            "3468/4096\n",
            "3469/4096\n",
            "3470/4096\n",
            "3471/4096\n",
            "3472/4096\n",
            "3473/4096\n",
            "3474/4096\n",
            "3475/4096\n",
            "3476/4096\n",
            "3477/4096\n",
            "3478/4096\n",
            "3479/4096\n",
            "3480/4096\n",
            "3481/4096\n",
            "3482/4096\n",
            "3483/4096\n",
            "3484/4096\n",
            "3485/4096\n",
            "3486/4096\n",
            "3487/4096\n",
            "3488/4096\n",
            "3489/4096\n",
            "3490/4096\n",
            "3491/4096\n",
            "3492/4096\n",
            "3493/4096\n",
            "3494/4096\n",
            "3495/4096\n",
            "3496/4096\n",
            "3497/4096\n",
            "3498/4096\n",
            "3499/4096\n",
            "3500/4096\n",
            "3501/4096\n",
            "3502/4096\n",
            "3503/4096\n",
            "3504/4096\n",
            "3505/4096\n",
            "3506/4096\n",
            "3507/4096\n",
            "3508/4096\n",
            "3509/4096\n",
            "3510/4096\n",
            "3511/4096\n",
            "3512/4096\n",
            "3513/4096\n",
            "3514/4096\n",
            "3515/4096\n",
            "3516/4096\n",
            "3517/4096\n",
            "3518/4096\n",
            "3519/4096\n",
            "3520/4096\n",
            "3521/4096\n",
            "3522/4096\n",
            "3523/4096\n",
            "3524/4096\n",
            "3525/4096\n",
            "3526/4096\n",
            "3527/4096\n",
            "3528/4096\n",
            "3529/4096\n",
            "3530/4096\n",
            "3531/4096\n",
            "3532/4096\n",
            "3533/4096\n",
            "3534/4096\n",
            "3535/4096\n",
            "3536/4096\n",
            "3537/4096\n",
            "3538/4096\n",
            "3539/4096\n",
            "3540/4096\n",
            "3541/4096\n",
            "3542/4096\n",
            "3543/4096\n",
            "3544/4096\n",
            "3545/4096\n",
            "3546/4096\n",
            "3547/4096\n",
            "3548/4096\n",
            "3549/4096\n",
            "3550/4096\n",
            "3551/4096\n",
            "3552/4096\n",
            "3553/4096\n",
            "3554/4096\n",
            "3555/4096\n",
            "3556/4096\n",
            "3557/4096\n",
            "3558/4096\n",
            "3559/4096\n",
            "3560/4096\n",
            "3561/4096\n",
            "3562/4096\n",
            "3563/4096\n",
            "3564/4096\n",
            "3565/4096\n",
            "3566/4096\n",
            "3567/4096\n",
            "3568/4096\n",
            "3569/4096\n",
            "3570/4096\n",
            "3571/4096\n",
            "3572/4096\n",
            "3573/4096\n",
            "3574/4096\n",
            "3575/4096\n",
            "3576/4096\n",
            "3577/4096\n",
            "3578/4096\n",
            "3579/4096\n",
            "3580/4096\n",
            "3581/4096\n",
            "3582/4096\n",
            "3583/4096\n",
            "3584/4096\n",
            "3585/4096\n",
            "3586/4096\n",
            "3587/4096\n",
            "3588/4096\n",
            "3589/4096\n",
            "3590/4096\n",
            "3591/4096\n",
            "3592/4096\n",
            "3593/4096\n",
            "3594/4096\n",
            "3595/4096\n",
            "3596/4096\n",
            "3597/4096\n",
            "3598/4096\n",
            "3599/4096\n",
            "3600/4096\n",
            "3601/4096\n",
            "3602/4096\n",
            "3603/4096\n",
            "3604/4096\n",
            "3605/4096\n",
            "3606/4096\n",
            "3607/4096\n",
            "3608/4096\n",
            "3609/4096\n",
            "3610/4096\n",
            "3611/4096\n",
            "3612/4096\n",
            "3613/4096\n",
            "3614/4096\n",
            "3615/4096\n",
            "3616/4096\n",
            "3617/4096\n",
            "3618/4096\n",
            "3619/4096\n",
            "3620/4096\n",
            "3621/4096\n",
            "3622/4096\n",
            "3623/4096\n",
            "3624/4096\n",
            "3625/4096\n",
            "3626/4096\n",
            "3627/4096\n",
            "3628/4096\n",
            "3629/4096\n",
            "3630/4096\n",
            "3631/4096\n",
            "3632/4096\n",
            "3633/4096\n",
            "3634/4096\n",
            "3635/4096\n",
            "3636/4096\n",
            "3637/4096\n",
            "3638/4096\n",
            "3639/4096\n",
            "3640/4096\n",
            "3641/4096\n",
            "3642/4096\n",
            "3643/4096\n",
            "3644/4096\n",
            "3645/4096\n",
            "3646/4096\n",
            "3647/4096\n",
            "3648/4096\n",
            "3649/4096\n",
            "3650/4096\n",
            "3651/4096\n",
            "3652/4096\n",
            "3653/4096\n",
            "3654/4096\n",
            "3655/4096\n",
            "3656/4096\n",
            "3657/4096\n",
            "3658/4096\n",
            "3659/4096\n",
            "3660/4096\n",
            "3661/4096\n",
            "3662/4096\n",
            "3663/4096\n",
            "3664/4096\n",
            "3665/4096\n",
            "3666/4096\n",
            "3667/4096\n",
            "3668/4096\n",
            "3669/4096\n",
            "3670/4096\n",
            "3671/4096\n",
            "3672/4096\n",
            "3673/4096\n",
            "3674/4096\n",
            "3675/4096\n",
            "3676/4096\n",
            "3677/4096\n",
            "3678/4096\n",
            "3679/4096\n",
            "3680/4096\n",
            "3681/4096\n",
            "3682/4096\n",
            "3683/4096\n",
            "3684/4096\n",
            "3685/4096\n",
            "3686/4096\n",
            "3687/4096\n",
            "3688/4096\n",
            "3689/4096\n",
            "3690/4096\n",
            "3691/4096\n",
            "3692/4096\n",
            "3693/4096\n",
            "3694/4096\n",
            "3695/4096\n",
            "3696/4096\n",
            "3697/4096\n",
            "3698/4096\n",
            "3699/4096\n",
            "3700/4096\n",
            "3701/4096\n",
            "3702/4096\n",
            "3703/4096\n",
            "3704/4096\n",
            "3705/4096\n",
            "3706/4096\n",
            "3707/4096\n",
            "3708/4096\n",
            "3709/4096\n",
            "3710/4096\n",
            "3711/4096\n",
            "3712/4096\n",
            "3713/4096\n",
            "3714/4096\n",
            "3715/4096\n",
            "3716/4096\n",
            "3717/4096\n",
            "3718/4096\n",
            "3719/4096\n",
            "3720/4096\n",
            "3721/4096\n",
            "3722/4096\n",
            "3723/4096\n",
            "3724/4096\n",
            "3725/4096\n",
            "3726/4096\n",
            "3727/4096\n",
            "3728/4096\n",
            "3729/4096\n",
            "3730/4096\n",
            "3731/4096\n",
            "3732/4096\n",
            "3733/4096\n",
            "3734/4096\n",
            "3735/4096\n",
            "3736/4096\n",
            "3737/4096\n",
            "3738/4096\n",
            "3739/4096\n",
            "3740/4096\n",
            "3741/4096\n",
            "3742/4096\n",
            "3743/4096\n",
            "3744/4096\n",
            "3745/4096\n",
            "3746/4096\n",
            "3747/4096\n",
            "3748/4096\n",
            "3749/4096\n",
            "3750/4096\n",
            "3751/4096\n",
            "3752/4096\n",
            "3753/4096\n",
            "3754/4096\n",
            "3755/4096\n",
            "3756/4096\n",
            "3757/4096\n",
            "3758/4096\n",
            "3759/4096\n",
            "3760/4096\n",
            "3761/4096\n",
            "3762/4096\n",
            "3763/4096\n",
            "3764/4096\n",
            "3765/4096\n",
            "3766/4096\n",
            "3767/4096\n",
            "3768/4096\n",
            "3769/4096\n",
            "3770/4096\n",
            "3771/4096\n",
            "3772/4096\n",
            "3773/4096\n",
            "3774/4096\n",
            "3775/4096\n",
            "3776/4096\n",
            "3777/4096\n",
            "3778/4096\n",
            "3779/4096\n",
            "3780/4096\n",
            "3781/4096\n",
            "3782/4096\n",
            "3783/4096\n",
            "3784/4096\n",
            "3785/4096\n",
            "3786/4096\n",
            "3787/4096\n",
            "3788/4096\n",
            "3789/4096\n",
            "3790/4096\n",
            "3791/4096\n",
            "3792/4096\n",
            "3793/4096\n",
            "3794/4096\n",
            "3795/4096\n",
            "3796/4096\n",
            "3797/4096\n",
            "3798/4096\n",
            "3799/4096\n",
            "3800/4096\n",
            "3801/4096\n",
            "3802/4096\n",
            "3803/4096\n",
            "3804/4096\n",
            "3805/4096\n",
            "3806/4096\n",
            "3807/4096\n",
            "3808/4096\n",
            "3809/4096\n",
            "3810/4096\n",
            "3811/4096\n",
            "3812/4096\n",
            "3813/4096\n",
            "3814/4096\n",
            "3815/4096\n",
            "3816/4096\n",
            "3817/4096\n",
            "3818/4096\n",
            "3819/4096\n",
            "3820/4096\n",
            "3821/4096\n",
            "3822/4096\n",
            "3823/4096\n",
            "3824/4096\n",
            "3825/4096\n",
            "3826/4096\n",
            "3827/4096\n",
            "3828/4096\n",
            "3829/4096\n",
            "3830/4096\n",
            "3831/4096\n",
            "3832/4096\n",
            "3833/4096\n",
            "3834/4096\n",
            "3835/4096\n",
            "3836/4096\n",
            "3837/4096\n",
            "3838/4096\n",
            "3839/4096\n",
            "3840/4096\n",
            "3841/4096\n",
            "3842/4096\n",
            "3843/4096\n",
            "3844/4096\n",
            "3845/4096\n",
            "3846/4096\n",
            "3847/4096\n",
            "3848/4096\n",
            "3849/4096\n",
            "3850/4096\n",
            "3851/4096\n",
            "3852/4096\n",
            "3853/4096\n",
            "3854/4096\n",
            "3855/4096\n",
            "3856/4096\n",
            "3857/4096\n",
            "3858/4096\n",
            "3859/4096\n",
            "3860/4096\n",
            "3861/4096\n",
            "3862/4096\n",
            "3863/4096\n",
            "3864/4096\n",
            "3865/4096\n",
            "3866/4096\n",
            "3867/4096\n",
            "3868/4096\n",
            "3869/4096\n",
            "3870/4096\n",
            "3871/4096\n",
            "3872/4096\n",
            "3873/4096\n",
            "3874/4096\n",
            "3875/4096\n",
            "3876/4096\n",
            "3877/4096\n",
            "3878/4096\n",
            "3879/4096\n",
            "3880/4096\n",
            "3881/4096\n",
            "3882/4096\n",
            "3883/4096\n",
            "3884/4096\n",
            "3885/4096\n",
            "3886/4096\n",
            "3887/4096\n",
            "3888/4096\n",
            "3889/4096\n",
            "3890/4096\n",
            "3891/4096\n",
            "3892/4096\n",
            "3893/4096\n",
            "3894/4096\n",
            "3895/4096\n",
            "3896/4096\n",
            "3897/4096\n",
            "3898/4096\n",
            "3899/4096\n",
            "3900/4096\n",
            "3901/4096\n",
            "3902/4096\n",
            "3903/4096\n",
            "3904/4096\n",
            "3905/4096\n",
            "3906/4096\n",
            "3907/4096\n",
            "3908/4096\n",
            "3909/4096\n",
            "3910/4096\n",
            "3911/4096\n",
            "3912/4096\n",
            "3913/4096\n",
            "3914/4096\n",
            "3915/4096\n",
            "3916/4096\n",
            "3917/4096\n",
            "3918/4096\n",
            "3919/4096\n",
            "3920/4096\n",
            "3921/4096\n",
            "3922/4096\n",
            "3923/4096\n",
            "3924/4096\n",
            "3925/4096\n",
            "3926/4096\n",
            "3927/4096\n",
            "3928/4096\n",
            "3929/4096\n",
            "3930/4096\n",
            "3931/4096\n",
            "3932/4096\n",
            "3933/4096\n",
            "3934/4096\n",
            "3935/4096\n",
            "3936/4096\n",
            "3937/4096\n",
            "3938/4096\n",
            "3939/4096\n",
            "3940/4096\n",
            "3941/4096\n",
            "3942/4096\n",
            "3943/4096\n",
            "3944/4096\n",
            "3945/4096\n",
            "3946/4096\n",
            "3947/4096\n",
            "3948/4096\n",
            "3949/4096\n",
            "3950/4096\n",
            "3951/4096\n",
            "3952/4096\n",
            "3953/4096\n",
            "3954/4096\n",
            "3955/4096\n",
            "3956/4096\n",
            "3957/4096\n",
            "3958/4096\n",
            "3959/4096\n",
            "3960/4096\n",
            "3961/4096\n",
            "3962/4096\n",
            "3963/4096\n",
            "3964/4096\n",
            "3965/4096\n",
            "3966/4096\n",
            "3967/4096\n",
            "3968/4096\n",
            "3969/4096\n",
            "3970/4096\n",
            "3971/4096\n",
            "3972/4096\n",
            "3973/4096\n",
            "3974/4096\n",
            "3975/4096\n",
            "3976/4096\n",
            "3977/4096\n",
            "3978/4096\n",
            "3979/4096\n",
            "3980/4096\n",
            "3981/4096\n",
            "3982/4096\n",
            "3983/4096\n",
            "3984/4096\n",
            "3985/4096\n",
            "3986/4096\n",
            "3987/4096\n",
            "3988/4096\n",
            "3989/4096\n",
            "3990/4096\n",
            "3991/4096\n",
            "3992/4096\n",
            "3993/4096\n",
            "3994/4096\n",
            "3995/4096\n",
            "3996/4096\n",
            "3997/4096\n",
            "3998/4096\n",
            "3999/4096\n",
            "4000/4096\n",
            "4001/4096\n",
            "4002/4096\n",
            "4003/4096\n",
            "4004/4096\n",
            "4005/4096\n",
            "4006/4096\n",
            "4007/4096\n",
            "4008/4096\n",
            "4009/4096\n",
            "4010/4096\n",
            "4011/4096\n",
            "4012/4096\n",
            "4013/4096\n",
            "4014/4096\n",
            "4015/4096\n",
            "4016/4096\n",
            "4017/4096\n",
            "4018/4096\n",
            "4019/4096\n",
            "4020/4096\n",
            "4021/4096\n",
            "4022/4096\n",
            "4023/4096\n",
            "4024/4096\n",
            "4025/4096\n",
            "4026/4096\n",
            "4027/4096\n",
            "4028/4096\n",
            "4029/4096\n",
            "4030/4096\n",
            "4031/4096\n",
            "4032/4096\n",
            "4033/4096\n",
            "4034/4096\n",
            "4035/4096\n",
            "4036/4096\n",
            "4037/4096\n",
            "4038/4096\n",
            "4039/4096\n",
            "4040/4096\n",
            "4041/4096\n",
            "4042/4096\n",
            "4043/4096\n",
            "4044/4096\n",
            "4045/4096\n",
            "4046/4096\n",
            "4047/4096\n",
            "4048/4096\n",
            "4049/4096\n",
            "4050/4096\n",
            "4051/4096\n",
            "4052/4096\n",
            "4053/4096\n",
            "4054/4096\n",
            "4055/4096\n",
            "4056/4096\n",
            "4057/4096\n",
            "4058/4096\n",
            "4059/4096\n",
            "4060/4096\n",
            "4061/4096\n",
            "4062/4096\n",
            "4063/4096\n",
            "4064/4096\n",
            "4065/4096\n",
            "4066/4096\n",
            "4067/4096\n",
            "4068/4096\n",
            "4069/4096\n",
            "4070/4096\n",
            "4071/4096\n",
            "4072/4096\n",
            "4073/4096\n",
            "4074/4096\n",
            "4075/4096\n",
            "4076/4096\n",
            "4077/4096\n",
            "4078/4096\n",
            "4079/4096\n",
            "4080/4096\n",
            "4081/4096\n",
            "4082/4096\n",
            "4083/4096\n",
            "4084/4096\n",
            "4085/4096\n",
            "4086/4096\n",
            "4087/4096\n",
            "4088/4096\n",
            "4089/4096\n",
            "4090/4096\n",
            "4091/4096\n",
            "4092/4096\n",
            "4093/4096\n",
            "4094/4096\n",
            "4095/4096\n",
            "\n",
            "\n",
            "sample 5:\n",
            "0/4096\n",
            "1/4096\n",
            "2/4096\n",
            "3/4096\n",
            "4/4096\n",
            "5/4096\n",
            "6/4096\n",
            "7/4096\n",
            "8/4096\n",
            "9/4096\n",
            "10/4096\n",
            "11/4096\n",
            "12/4096\n",
            "13/4096\n",
            "14/4096\n",
            "15/4096\n",
            "16/4096\n",
            "17/4096\n",
            "18/4096\n",
            "19/4096\n",
            "20/4096\n",
            "21/4096\n",
            "22/4096\n",
            "23/4096\n",
            "24/4096\n",
            "25/4096\n",
            "26/4096\n",
            "27/4096\n",
            "28/4096\n",
            "29/4096\n",
            "30/4096\n",
            "31/4096\n",
            "32/4096\n",
            "33/4096\n",
            "34/4096\n",
            "35/4096\n",
            "36/4096\n",
            "37/4096\n",
            "38/4096\n",
            "39/4096\n",
            "40/4096\n",
            "41/4096\n",
            "42/4096\n",
            "43/4096\n",
            "44/4096\n",
            "45/4096\n",
            "46/4096\n",
            "47/4096\n",
            "48/4096\n",
            "49/4096\n",
            "50/4096\n",
            "51/4096\n",
            "52/4096\n",
            "53/4096\n",
            "54/4096\n",
            "55/4096\n",
            "56/4096\n",
            "57/4096\n",
            "58/4096\n",
            "59/4096\n",
            "60/4096\n",
            "61/4096\n",
            "62/4096\n",
            "63/4096\n",
            "64/4096\n",
            "65/4096\n",
            "66/4096\n",
            "67/4096\n",
            "68/4096\n",
            "69/4096\n",
            "70/4096\n",
            "71/4096\n",
            "72/4096\n",
            "73/4096\n",
            "74/4096\n",
            "75/4096\n",
            "76/4096\n",
            "77/4096\n",
            "78/4096\n",
            "79/4096\n",
            "80/4096\n",
            "81/4096\n",
            "82/4096\n",
            "83/4096\n",
            "84/4096\n",
            "85/4096\n",
            "86/4096\n",
            "87/4096\n",
            "88/4096\n",
            "89/4096\n",
            "90/4096\n",
            "91/4096\n",
            "92/4096\n",
            "93/4096\n",
            "94/4096\n",
            "95/4096\n",
            "96/4096\n",
            "97/4096\n",
            "98/4096\n",
            "99/4096\n",
            "100/4096\n",
            "101/4096\n",
            "102/4096\n",
            "103/4096\n",
            "104/4096\n",
            "105/4096\n",
            "106/4096\n",
            "107/4096\n",
            "108/4096\n",
            "109/4096\n",
            "110/4096\n",
            "111/4096\n",
            "112/4096\n",
            "113/4096\n",
            "114/4096\n",
            "115/4096\n",
            "116/4096\n",
            "117/4096\n",
            "118/4096\n",
            "119/4096\n",
            "120/4096\n",
            "121/4096\n",
            "122/4096\n",
            "123/4096\n",
            "124/4096\n",
            "125/4096\n",
            "126/4096\n",
            "127/4096\n",
            "128/4096\n",
            "129/4096\n",
            "130/4096\n",
            "131/4096\n",
            "132/4096\n",
            "133/4096\n",
            "134/4096\n",
            "135/4096\n",
            "136/4096\n",
            "137/4096\n",
            "138/4096\n",
            "139/4096\n",
            "140/4096\n",
            "141/4096\n",
            "142/4096\n",
            "143/4096\n",
            "144/4096\n",
            "145/4096\n",
            "146/4096\n",
            "147/4096\n",
            "148/4096\n",
            "149/4096\n",
            "150/4096\n",
            "151/4096\n",
            "152/4096\n",
            "153/4096\n",
            "154/4096\n",
            "155/4096\n",
            "156/4096\n",
            "157/4096\n",
            "158/4096\n",
            "159/4096\n",
            "160/4096\n",
            "161/4096\n",
            "162/4096\n",
            "163/4096\n",
            "164/4096\n",
            "165/4096\n",
            "166/4096\n",
            "167/4096\n",
            "168/4096\n",
            "169/4096\n",
            "170/4096\n",
            "171/4096\n",
            "172/4096\n",
            "173/4096\n",
            "174/4096\n",
            "175/4096\n",
            "176/4096\n",
            "177/4096\n",
            "178/4096\n",
            "179/4096\n",
            "180/4096\n",
            "181/4096\n",
            "182/4096\n",
            "183/4096\n",
            "184/4096\n",
            "185/4096\n",
            "186/4096\n",
            "187/4096\n",
            "188/4096\n",
            "189/4096\n",
            "190/4096\n",
            "191/4096\n",
            "192/4096\n",
            "193/4096\n",
            "194/4096\n",
            "195/4096\n",
            "196/4096\n",
            "197/4096\n",
            "198/4096\n",
            "199/4096\n",
            "200/4096\n",
            "201/4096\n",
            "202/4096\n",
            "203/4096\n",
            "204/4096\n",
            "205/4096\n",
            "206/4096\n",
            "207/4096\n",
            "208/4096\n",
            "209/4096\n",
            "210/4096\n",
            "211/4096\n",
            "212/4096\n",
            "213/4096\n",
            "214/4096\n",
            "215/4096\n",
            "216/4096\n",
            "217/4096\n",
            "218/4096\n",
            "219/4096\n",
            "220/4096\n",
            "221/4096\n",
            "222/4096\n",
            "223/4096\n",
            "224/4096\n",
            "225/4096\n",
            "226/4096\n",
            "227/4096\n",
            "228/4096\n",
            "229/4096\n",
            "230/4096\n",
            "231/4096\n",
            "232/4096\n",
            "233/4096\n",
            "234/4096\n",
            "235/4096\n",
            "236/4096\n",
            "237/4096\n",
            "238/4096\n",
            "239/4096\n",
            "240/4096\n",
            "241/4096\n",
            "242/4096\n",
            "243/4096\n",
            "244/4096\n",
            "245/4096\n",
            "246/4096\n",
            "247/4096\n",
            "248/4096\n",
            "249/4096\n",
            "250/4096\n",
            "251/4096\n",
            "252/4096\n",
            "253/4096\n",
            "254/4096\n",
            "255/4096\n",
            "256/4096\n",
            "257/4096\n",
            "258/4096\n",
            "259/4096\n",
            "260/4096\n",
            "261/4096\n",
            "262/4096\n",
            "263/4096\n",
            "264/4096\n",
            "265/4096\n",
            "266/4096\n",
            "267/4096\n",
            "268/4096\n",
            "269/4096\n",
            "270/4096\n",
            "271/4096\n",
            "272/4096\n",
            "273/4096\n",
            "274/4096\n",
            "275/4096\n",
            "276/4096\n",
            "277/4096\n",
            "278/4096\n",
            "279/4096\n",
            "280/4096\n",
            "281/4096\n",
            "282/4096\n",
            "283/4096\n",
            "284/4096\n",
            "285/4096\n",
            "286/4096\n",
            "287/4096\n",
            "288/4096\n",
            "289/4096\n",
            "290/4096\n",
            "291/4096\n",
            "292/4096\n",
            "293/4096\n",
            "294/4096\n",
            "295/4096\n",
            "296/4096\n",
            "297/4096\n",
            "298/4096\n",
            "299/4096\n",
            "300/4096\n",
            "301/4096\n",
            "302/4096\n",
            "303/4096\n",
            "304/4096\n",
            "305/4096\n",
            "306/4096\n",
            "307/4096\n",
            "308/4096\n",
            "309/4096\n",
            "310/4096\n",
            "311/4096\n",
            "312/4096\n",
            "313/4096\n",
            "314/4096\n",
            "315/4096\n",
            "316/4096\n",
            "317/4096\n",
            "318/4096\n",
            "319/4096\n",
            "320/4096\n",
            "321/4096\n",
            "322/4096\n",
            "323/4096\n",
            "324/4096\n",
            "325/4096\n",
            "326/4096\n",
            "327/4096\n",
            "328/4096\n",
            "329/4096\n",
            "330/4096\n",
            "331/4096\n",
            "332/4096\n",
            "333/4096\n",
            "334/4096\n",
            "335/4096\n",
            "336/4096\n",
            "337/4096\n",
            "338/4096\n",
            "339/4096\n",
            "340/4096\n",
            "341/4096\n",
            "342/4096\n",
            "343/4096\n",
            "344/4096\n",
            "345/4096\n",
            "346/4096\n",
            "347/4096\n",
            "348/4096\n",
            "349/4096\n",
            "350/4096\n",
            "351/4096\n",
            "352/4096\n",
            "353/4096\n",
            "354/4096\n",
            "355/4096\n",
            "356/4096\n",
            "357/4096\n",
            "358/4096\n",
            "359/4096\n",
            "360/4096\n",
            "361/4096\n",
            "362/4096\n",
            "363/4096\n",
            "364/4096\n",
            "365/4096\n",
            "366/4096\n",
            "367/4096\n",
            "368/4096\n",
            "369/4096\n",
            "370/4096\n",
            "371/4096\n",
            "372/4096\n",
            "373/4096\n",
            "374/4096\n",
            "375/4096\n",
            "376/4096\n",
            "377/4096\n",
            "378/4096\n",
            "379/4096\n",
            "380/4096\n",
            "381/4096\n",
            "382/4096\n",
            "383/4096\n",
            "384/4096\n",
            "385/4096\n",
            "386/4096\n",
            "387/4096\n",
            "388/4096\n",
            "389/4096\n",
            "390/4096\n",
            "391/4096\n",
            "392/4096\n",
            "393/4096\n",
            "394/4096\n",
            "395/4096\n",
            "396/4096\n",
            "397/4096\n",
            "398/4096\n",
            "399/4096\n",
            "400/4096\n",
            "401/4096\n",
            "402/4096\n",
            "403/4096\n",
            "404/4096\n",
            "405/4096\n",
            "406/4096\n",
            "407/4096\n",
            "408/4096\n",
            "409/4096\n",
            "410/4096\n",
            "411/4096\n",
            "412/4096\n",
            "413/4096\n",
            "414/4096\n",
            "415/4096\n",
            "416/4096\n",
            "417/4096\n",
            "418/4096\n",
            "419/4096\n",
            "420/4096\n",
            "421/4096\n",
            "422/4096\n",
            "423/4096\n",
            "424/4096\n",
            "425/4096\n",
            "426/4096\n",
            "427/4096\n",
            "428/4096\n",
            "429/4096\n",
            "430/4096\n",
            "431/4096\n",
            "432/4096\n",
            "433/4096\n",
            "434/4096\n",
            "435/4096\n",
            "436/4096\n",
            "437/4096\n",
            "438/4096\n",
            "439/4096\n",
            "440/4096\n",
            "441/4096\n",
            "442/4096\n",
            "443/4096\n",
            "444/4096\n",
            "445/4096\n",
            "446/4096\n",
            "447/4096\n",
            "448/4096\n",
            "449/4096\n",
            "450/4096\n",
            "451/4096\n",
            "452/4096\n",
            "453/4096\n",
            "454/4096\n",
            "455/4096\n",
            "456/4096\n",
            "457/4096\n",
            "458/4096\n",
            "459/4096\n",
            "460/4096\n",
            "461/4096\n",
            "462/4096\n",
            "463/4096\n",
            "464/4096\n",
            "465/4096\n",
            "466/4096\n",
            "467/4096\n",
            "468/4096\n",
            "469/4096\n",
            "470/4096\n",
            "471/4096\n",
            "472/4096\n",
            "473/4096\n",
            "474/4096\n",
            "475/4096\n",
            "476/4096\n",
            "477/4096\n",
            "478/4096\n",
            "479/4096\n",
            "480/4096\n",
            "481/4096\n",
            "482/4096\n",
            "483/4096\n",
            "484/4096\n",
            "485/4096\n",
            "486/4096\n",
            "487/4096\n",
            "488/4096\n",
            "489/4096\n",
            "490/4096\n",
            "491/4096\n",
            "492/4096\n",
            "493/4096\n",
            "494/4096\n",
            "495/4096\n",
            "496/4096\n",
            "497/4096\n",
            "498/4096\n",
            "499/4096\n",
            "500/4096\n",
            "501/4096\n",
            "502/4096\n",
            "503/4096\n",
            "504/4096\n",
            "505/4096\n",
            "506/4096\n",
            "507/4096\n",
            "508/4096\n",
            "509/4096\n",
            "510/4096\n",
            "511/4096\n",
            "512/4096\n",
            "513/4096\n",
            "514/4096\n",
            "515/4096\n",
            "516/4096\n",
            "517/4096\n",
            "518/4096\n",
            "519/4096\n",
            "520/4096\n",
            "521/4096\n",
            "522/4096\n",
            "523/4096\n",
            "524/4096\n",
            "525/4096\n",
            "526/4096\n",
            "527/4096\n",
            "528/4096\n",
            "529/4096\n",
            "530/4096\n",
            "531/4096\n",
            "532/4096\n",
            "533/4096\n",
            "534/4096\n",
            "535/4096\n",
            "536/4096\n",
            "537/4096\n",
            "538/4096\n",
            "539/4096\n",
            "540/4096\n",
            "541/4096\n",
            "542/4096\n",
            "543/4096\n",
            "544/4096\n",
            "545/4096\n",
            "546/4096\n",
            "547/4096\n",
            "548/4096\n",
            "549/4096\n",
            "550/4096\n",
            "551/4096\n",
            "552/4096\n",
            "553/4096\n",
            "554/4096\n",
            "555/4096\n",
            "556/4096\n",
            "557/4096\n",
            "558/4096\n",
            "559/4096\n",
            "560/4096\n",
            "561/4096\n",
            "562/4096\n",
            "563/4096\n",
            "564/4096\n",
            "565/4096\n",
            "566/4096\n",
            "567/4096\n",
            "568/4096\n",
            "569/4096\n",
            "570/4096\n",
            "571/4096\n",
            "572/4096\n",
            "573/4096\n",
            "574/4096\n",
            "575/4096\n",
            "576/4096\n",
            "577/4096\n",
            "578/4096\n",
            "579/4096\n",
            "580/4096\n",
            "581/4096\n",
            "582/4096\n",
            "583/4096\n",
            "584/4096\n",
            "585/4096\n",
            "586/4096\n",
            "587/4096\n",
            "588/4096\n",
            "589/4096\n",
            "590/4096\n",
            "591/4096\n",
            "592/4096\n",
            "593/4096\n",
            "594/4096\n",
            "595/4096\n",
            "596/4096\n",
            "597/4096\n",
            "598/4096\n",
            "599/4096\n",
            "600/4096\n",
            "601/4096\n",
            "602/4096\n",
            "603/4096\n",
            "604/4096\n",
            "605/4096\n",
            "606/4096\n",
            "607/4096\n",
            "608/4096\n",
            "609/4096\n",
            "610/4096\n",
            "611/4096\n",
            "612/4096\n",
            "613/4096\n",
            "614/4096\n",
            "615/4096\n",
            "616/4096\n",
            "617/4096\n",
            "618/4096\n",
            "619/4096\n",
            "620/4096\n",
            "621/4096\n",
            "622/4096\n",
            "623/4096\n",
            "624/4096\n",
            "625/4096\n",
            "626/4096\n",
            "627/4096\n",
            "628/4096\n",
            "629/4096\n",
            "630/4096\n",
            "631/4096\n",
            "632/4096\n",
            "633/4096\n",
            "634/4096\n",
            "635/4096\n",
            "636/4096\n",
            "637/4096\n",
            "638/4096\n",
            "639/4096\n",
            "640/4096\n",
            "641/4096\n",
            "642/4096\n",
            "643/4096\n",
            "644/4096\n",
            "645/4096\n",
            "646/4096\n",
            "647/4096\n",
            "648/4096\n",
            "649/4096\n",
            "650/4096\n",
            "651/4096\n",
            "652/4096\n",
            "653/4096\n",
            "654/4096\n",
            "655/4096\n",
            "656/4096\n",
            "657/4096\n",
            "658/4096\n",
            "659/4096\n",
            "660/4096\n",
            "661/4096\n",
            "662/4096\n",
            "663/4096\n",
            "664/4096\n",
            "665/4096\n",
            "666/4096\n",
            "667/4096\n",
            "668/4096\n",
            "669/4096\n",
            "670/4096\n",
            "671/4096\n",
            "672/4096\n",
            "673/4096\n",
            "674/4096\n",
            "675/4096\n",
            "676/4096\n",
            "677/4096\n",
            "678/4096\n",
            "679/4096\n",
            "680/4096\n",
            "681/4096\n",
            "682/4096\n",
            "683/4096\n",
            "684/4096\n",
            "685/4096\n",
            "686/4096\n",
            "687/4096\n",
            "688/4096\n",
            "689/4096\n",
            "690/4096\n",
            "691/4096\n",
            "692/4096\n",
            "693/4096\n",
            "694/4096\n",
            "695/4096\n",
            "696/4096\n",
            "697/4096\n",
            "698/4096\n",
            "699/4096\n",
            "700/4096\n",
            "701/4096\n",
            "702/4096\n",
            "703/4096\n",
            "704/4096\n",
            "705/4096\n",
            "706/4096\n",
            "707/4096\n",
            "708/4096\n",
            "709/4096\n",
            "710/4096\n",
            "711/4096\n",
            "712/4096\n",
            "713/4096\n",
            "714/4096\n",
            "715/4096\n",
            "716/4096\n",
            "717/4096\n",
            "718/4096\n",
            "719/4096\n",
            "720/4096\n",
            "721/4096\n",
            "722/4096\n",
            "723/4096\n",
            "724/4096\n",
            "725/4096\n",
            "726/4096\n",
            "727/4096\n",
            "728/4096\n",
            "729/4096\n",
            "730/4096\n",
            "731/4096\n",
            "732/4096\n",
            "733/4096\n",
            "734/4096\n",
            "735/4096\n",
            "736/4096\n",
            "737/4096\n",
            "738/4096\n",
            "739/4096\n",
            "740/4096\n",
            "741/4096\n",
            "742/4096\n",
            "743/4096\n",
            "744/4096\n",
            "745/4096\n",
            "746/4096\n",
            "747/4096\n",
            "748/4096\n",
            "749/4096\n",
            "750/4096\n",
            "751/4096\n",
            "752/4096\n",
            "753/4096\n",
            "754/4096\n",
            "755/4096\n",
            "756/4096\n",
            "757/4096\n",
            "758/4096\n",
            "759/4096\n",
            "760/4096\n",
            "761/4096\n",
            "762/4096\n",
            "763/4096\n",
            "764/4096\n",
            "765/4096\n",
            "766/4096\n",
            "767/4096\n",
            "768/4096\n",
            "769/4096\n",
            "770/4096\n",
            "771/4096\n",
            "772/4096\n",
            "773/4096\n",
            "774/4096\n",
            "775/4096\n",
            "776/4096\n",
            "777/4096\n",
            "778/4096\n",
            "779/4096\n",
            "780/4096\n",
            "781/4096\n",
            "782/4096\n",
            "783/4096\n",
            "784/4096\n",
            "785/4096\n",
            "786/4096\n",
            "787/4096\n",
            "788/4096\n",
            "789/4096\n",
            "790/4096\n",
            "791/4096\n",
            "792/4096\n",
            "793/4096\n",
            "794/4096\n",
            "795/4096\n",
            "796/4096\n",
            "797/4096\n",
            "798/4096\n",
            "799/4096\n",
            "800/4096\n",
            "801/4096\n",
            "802/4096\n",
            "803/4096\n",
            "804/4096\n",
            "805/4096\n",
            "806/4096\n",
            "807/4096\n",
            "808/4096\n",
            "809/4096\n",
            "810/4096\n",
            "811/4096\n",
            "812/4096\n",
            "813/4096\n",
            "814/4096\n",
            "815/4096\n",
            "816/4096\n",
            "817/4096\n",
            "818/4096\n",
            "819/4096\n",
            "820/4096\n",
            "821/4096\n",
            "822/4096\n",
            "823/4096\n",
            "824/4096\n",
            "825/4096\n",
            "826/4096\n",
            "827/4096\n",
            "828/4096\n",
            "829/4096\n",
            "830/4096\n",
            "831/4096\n",
            "832/4096\n",
            "833/4096\n",
            "834/4096\n",
            "835/4096\n",
            "836/4096\n",
            "837/4096\n",
            "838/4096\n",
            "839/4096\n",
            "840/4096\n",
            "841/4096\n",
            "842/4096\n",
            "843/4096\n",
            "844/4096\n",
            "845/4096\n",
            "846/4096\n",
            "847/4096\n",
            "848/4096\n",
            "849/4096\n",
            "850/4096\n",
            "851/4096\n",
            "852/4096\n",
            "853/4096\n",
            "854/4096\n",
            "855/4096\n",
            "856/4096\n",
            "857/4096\n",
            "858/4096\n",
            "859/4096\n",
            "860/4096\n",
            "861/4096\n",
            "862/4096\n",
            "863/4096\n",
            "864/4096\n",
            "865/4096\n",
            "866/4096\n",
            "867/4096\n",
            "868/4096\n",
            "869/4096\n",
            "870/4096\n",
            "871/4096\n",
            "872/4096\n",
            "873/4096\n",
            "874/4096\n",
            "875/4096\n",
            "876/4096\n",
            "877/4096\n",
            "878/4096\n",
            "879/4096\n",
            "880/4096\n",
            "881/4096\n",
            "882/4096\n",
            "883/4096\n",
            "884/4096\n",
            "885/4096\n",
            "886/4096\n",
            "887/4096\n",
            "888/4096\n",
            "889/4096\n",
            "890/4096\n",
            "891/4096\n",
            "892/4096\n",
            "893/4096\n",
            "894/4096\n",
            "895/4096\n",
            "896/4096\n",
            "897/4096\n",
            "898/4096\n",
            "899/4096\n",
            "900/4096\n",
            "901/4096\n",
            "902/4096\n",
            "903/4096\n",
            "904/4096\n",
            "905/4096\n",
            "906/4096\n",
            "907/4096\n",
            "908/4096\n",
            "909/4096\n",
            "910/4096\n",
            "911/4096\n",
            "912/4096\n",
            "913/4096\n",
            "914/4096\n",
            "915/4096\n",
            "916/4096\n",
            "917/4096\n",
            "918/4096\n",
            "919/4096\n",
            "920/4096\n",
            "921/4096\n",
            "922/4096\n",
            "923/4096\n",
            "924/4096\n",
            "925/4096\n",
            "926/4096\n",
            "927/4096\n",
            "928/4096\n",
            "929/4096\n",
            "930/4096\n",
            "931/4096\n",
            "932/4096\n",
            "933/4096\n",
            "934/4096\n",
            "935/4096\n",
            "936/4096\n",
            "937/4096\n",
            "938/4096\n",
            "939/4096\n",
            "940/4096\n",
            "941/4096\n",
            "942/4096\n",
            "943/4096\n",
            "944/4096\n",
            "945/4096\n",
            "946/4096\n",
            "947/4096\n",
            "948/4096\n",
            "949/4096\n",
            "950/4096\n",
            "951/4096\n",
            "952/4096\n",
            "953/4096\n",
            "954/4096\n",
            "955/4096\n",
            "956/4096\n",
            "957/4096\n",
            "958/4096\n",
            "959/4096\n",
            "960/4096\n",
            "961/4096\n",
            "962/4096\n",
            "963/4096\n",
            "964/4096\n",
            "965/4096\n",
            "966/4096\n",
            "967/4096\n",
            "968/4096\n",
            "969/4096\n",
            "970/4096\n",
            "971/4096\n",
            "972/4096\n",
            "973/4096\n",
            "974/4096\n",
            "975/4096\n",
            "976/4096\n",
            "977/4096\n",
            "978/4096\n",
            "979/4096\n",
            "980/4096\n",
            "981/4096\n",
            "982/4096\n",
            "983/4096\n",
            "984/4096\n",
            "985/4096\n",
            "986/4096\n",
            "987/4096\n",
            "988/4096\n",
            "989/4096\n",
            "990/4096\n",
            "991/4096\n",
            "992/4096\n",
            "993/4096\n",
            "994/4096\n",
            "995/4096\n",
            "996/4096\n",
            "997/4096\n",
            "998/4096\n",
            "999/4096\n",
            "1000/4096\n",
            "1001/4096\n",
            "1002/4096\n",
            "1003/4096\n",
            "1004/4096\n",
            "1005/4096\n",
            "1006/4096\n",
            "1007/4096\n",
            "1008/4096\n",
            "1009/4096\n",
            "1010/4096\n",
            "1011/4096\n",
            "1012/4096\n",
            "1013/4096\n",
            "1014/4096\n",
            "1015/4096\n",
            "1016/4096\n",
            "1017/4096\n",
            "1018/4096\n",
            "1019/4096\n",
            "1020/4096\n",
            "1021/4096\n",
            "1022/4096\n",
            "1023/4096\n",
            "1024/4096\n",
            "1025/4096\n",
            "1026/4096\n",
            "1027/4096\n",
            "1028/4096\n",
            "1029/4096\n",
            "1030/4096\n",
            "1031/4096\n",
            "1032/4096\n",
            "1033/4096\n",
            "1034/4096\n",
            "1035/4096\n",
            "1036/4096\n",
            "1037/4096\n",
            "1038/4096\n",
            "1039/4096\n",
            "1040/4096\n",
            "1041/4096\n",
            "1042/4096\n",
            "1043/4096\n",
            "1044/4096\n",
            "1045/4096\n",
            "1046/4096\n",
            "1047/4096\n",
            "1048/4096\n",
            "1049/4096\n",
            "1050/4096\n",
            "1051/4096\n",
            "1052/4096\n",
            "1053/4096\n",
            "1054/4096\n",
            "1055/4096\n",
            "1056/4096\n",
            "1057/4096\n",
            "1058/4096\n",
            "1059/4096\n",
            "1060/4096\n",
            "1061/4096\n",
            "1062/4096\n",
            "1063/4096\n",
            "1064/4096\n",
            "1065/4096\n",
            "1066/4096\n",
            "1067/4096\n",
            "1068/4096\n",
            "1069/4096\n",
            "1070/4096\n",
            "1071/4096\n",
            "1072/4096\n",
            "1073/4096\n",
            "1074/4096\n",
            "1075/4096\n",
            "1076/4096\n",
            "1077/4096\n",
            "1078/4096\n",
            "1079/4096\n",
            "1080/4096\n",
            "1081/4096\n",
            "1082/4096\n",
            "1083/4096\n",
            "1084/4096\n",
            "1085/4096\n",
            "1086/4096\n",
            "1087/4096\n",
            "1088/4096\n",
            "1089/4096\n",
            "1090/4096\n",
            "1091/4096\n",
            "1092/4096\n",
            "1093/4096\n",
            "1094/4096\n",
            "1095/4096\n",
            "1096/4096\n",
            "1097/4096\n",
            "1098/4096\n",
            "1099/4096\n",
            "1100/4096\n",
            "1101/4096\n",
            "1102/4096\n",
            "1103/4096\n",
            "1104/4096\n",
            "1105/4096\n",
            "1106/4096\n",
            "1107/4096\n",
            "1108/4096\n",
            "1109/4096\n",
            "1110/4096\n",
            "1111/4096\n",
            "1112/4096\n",
            "1113/4096\n",
            "1114/4096\n",
            "1115/4096\n",
            "1116/4096\n",
            "1117/4096\n",
            "1118/4096\n",
            "1119/4096\n",
            "1120/4096\n",
            "1121/4096\n",
            "1122/4096\n",
            "1123/4096\n",
            "1124/4096\n",
            "1125/4096\n",
            "1126/4096\n",
            "1127/4096\n",
            "1128/4096\n",
            "1129/4096\n",
            "1130/4096\n",
            "1131/4096\n",
            "1132/4096\n",
            "1133/4096\n",
            "1134/4096\n",
            "1135/4096\n",
            "1136/4096\n",
            "1137/4096\n",
            "1138/4096\n",
            "1139/4096\n",
            "1140/4096\n",
            "1141/4096\n",
            "1142/4096\n",
            "1143/4096\n",
            "1144/4096\n",
            "1145/4096\n",
            "1146/4096\n",
            "1147/4096\n",
            "1148/4096\n",
            "1149/4096\n",
            "1150/4096\n",
            "1151/4096\n",
            "1152/4096\n",
            "1153/4096\n",
            "1154/4096\n",
            "1155/4096\n",
            "1156/4096\n",
            "1157/4096\n",
            "1158/4096\n",
            "1159/4096\n",
            "1160/4096\n",
            "1161/4096\n",
            "1162/4096\n",
            "1163/4096\n",
            "1164/4096\n",
            "1165/4096\n",
            "1166/4096\n",
            "1167/4096\n",
            "1168/4096\n",
            "1169/4096\n",
            "1170/4096\n",
            "1171/4096\n",
            "1172/4096\n",
            "1173/4096\n",
            "1174/4096\n",
            "1175/4096\n",
            "1176/4096\n",
            "1177/4096\n",
            "1178/4096\n",
            "1179/4096\n",
            "1180/4096\n",
            "1181/4096\n",
            "1182/4096\n",
            "1183/4096\n",
            "1184/4096\n",
            "1185/4096\n",
            "1186/4096\n",
            "1187/4096\n",
            "1188/4096\n",
            "1189/4096\n",
            "1190/4096\n",
            "1191/4096\n",
            "1192/4096\n",
            "1193/4096\n",
            "1194/4096\n",
            "1195/4096\n",
            "1196/4096\n",
            "1197/4096\n",
            "1198/4096\n",
            "1199/4096\n",
            "1200/4096\n",
            "1201/4096\n",
            "1202/4096\n",
            "1203/4096\n",
            "1204/4096\n",
            "1205/4096\n",
            "1206/4096\n",
            "1207/4096\n",
            "1208/4096\n",
            "1209/4096\n",
            "1210/4096\n",
            "1211/4096\n",
            "1212/4096\n",
            "1213/4096\n",
            "1214/4096\n",
            "1215/4096\n",
            "1216/4096\n",
            "1217/4096\n",
            "1218/4096\n",
            "1219/4096\n",
            "1220/4096\n",
            "1221/4096\n",
            "1222/4096\n",
            "1223/4096\n",
            "1224/4096\n",
            "1225/4096\n",
            "1226/4096\n",
            "1227/4096\n",
            "1228/4096\n",
            "1229/4096\n",
            "1230/4096\n",
            "1231/4096\n",
            "1232/4096\n",
            "1233/4096\n",
            "1234/4096\n",
            "1235/4096\n",
            "1236/4096\n",
            "1237/4096\n",
            "1238/4096\n",
            "1239/4096\n",
            "1240/4096\n",
            "1241/4096\n",
            "1242/4096\n",
            "1243/4096\n",
            "1244/4096\n",
            "1245/4096\n",
            "1246/4096\n",
            "1247/4096\n",
            "1248/4096\n",
            "1249/4096\n",
            "1250/4096\n",
            "1251/4096\n",
            "1252/4096\n",
            "1253/4096\n",
            "1254/4096\n",
            "1255/4096\n",
            "1256/4096\n",
            "1257/4096\n",
            "1258/4096\n",
            "1259/4096\n",
            "1260/4096\n",
            "1261/4096\n",
            "1262/4096\n",
            "1263/4096\n",
            "1264/4096\n",
            "1265/4096\n",
            "1266/4096\n",
            "1267/4096\n",
            "1268/4096\n",
            "1269/4096\n",
            "1270/4096\n",
            "1271/4096\n",
            "1272/4096\n",
            "1273/4096\n",
            "1274/4096\n",
            "1275/4096\n",
            "1276/4096\n",
            "1277/4096\n",
            "1278/4096\n",
            "1279/4096\n",
            "1280/4096\n",
            "1281/4096\n",
            "1282/4096\n",
            "1283/4096\n",
            "1284/4096\n",
            "1285/4096\n",
            "1286/4096\n",
            "1287/4096\n",
            "1288/4096\n",
            "1289/4096\n",
            "1290/4096\n",
            "1291/4096\n",
            "1292/4096\n",
            "1293/4096\n",
            "1294/4096\n",
            "1295/4096\n",
            "1296/4096\n",
            "1297/4096\n",
            "1298/4096\n",
            "1299/4096\n",
            "1300/4096\n",
            "1301/4096\n",
            "1302/4096\n",
            "1303/4096\n",
            "1304/4096\n",
            "1305/4096\n",
            "1306/4096\n",
            "1307/4096\n",
            "1308/4096\n",
            "1309/4096\n",
            "1310/4096\n",
            "1311/4096\n",
            "1312/4096\n",
            "1313/4096\n",
            "1314/4096\n",
            "1315/4096\n",
            "1316/4096\n",
            "1317/4096\n",
            "1318/4096\n",
            "1319/4096\n",
            "1320/4096\n",
            "1321/4096\n",
            "1322/4096\n",
            "1323/4096\n",
            "1324/4096\n",
            "1325/4096\n",
            "1326/4096\n",
            "1327/4096\n",
            "1328/4096\n",
            "1329/4096\n",
            "1330/4096\n",
            "1331/4096\n",
            "1332/4096\n",
            "1333/4096\n",
            "1334/4096\n",
            "1335/4096\n",
            "1336/4096\n",
            "1337/4096\n",
            "1338/4096\n",
            "1339/4096\n",
            "1340/4096\n",
            "1341/4096\n",
            "1342/4096\n",
            "1343/4096\n",
            "1344/4096\n",
            "1345/4096\n",
            "1346/4096\n",
            "1347/4096\n",
            "1348/4096\n",
            "1349/4096\n",
            "1350/4096\n",
            "1351/4096\n",
            "1352/4096\n",
            "1353/4096\n",
            "1354/4096\n",
            "1355/4096\n",
            "1356/4096\n",
            "1357/4096\n",
            "1358/4096\n",
            "1359/4096\n",
            "1360/4096\n",
            "1361/4096\n",
            "1362/4096\n",
            "1363/4096\n",
            "1364/4096\n",
            "1365/4096\n",
            "1366/4096\n",
            "1367/4096\n",
            "1368/4096\n",
            "1369/4096\n",
            "1370/4096\n",
            "1371/4096\n",
            "1372/4096\n",
            "1373/4096\n",
            "1374/4096\n",
            "1375/4096\n",
            "1376/4096\n",
            "1377/4096\n",
            "1378/4096\n",
            "1379/4096\n",
            "1380/4096\n",
            "1381/4096\n",
            "1382/4096\n",
            "1383/4096\n",
            "1384/4096\n",
            "1385/4096\n",
            "1386/4096\n",
            "1387/4096\n",
            "1388/4096\n",
            "1389/4096\n",
            "1390/4096\n",
            "1391/4096\n",
            "1392/4096\n",
            "1393/4096\n",
            "1394/4096\n",
            "1395/4096\n",
            "1396/4096\n",
            "1397/4096\n",
            "1398/4096\n",
            "1399/4096\n",
            "1400/4096\n",
            "1401/4096\n",
            "1402/4096\n",
            "1403/4096\n",
            "1404/4096\n",
            "1405/4096\n",
            "1406/4096\n",
            "1407/4096\n",
            "1408/4096\n",
            "1409/4096\n",
            "1410/4096\n",
            "1411/4096\n",
            "1412/4096\n",
            "1413/4096\n",
            "1414/4096\n",
            "1415/4096\n",
            "1416/4096\n",
            "1417/4096\n",
            "1418/4096\n",
            "1419/4096\n",
            "1420/4096\n",
            "1421/4096\n",
            "1422/4096\n",
            "1423/4096\n",
            "1424/4096\n",
            "1425/4096\n",
            "1426/4096\n",
            "1427/4096\n",
            "1428/4096\n",
            "1429/4096\n",
            "1430/4096\n",
            "1431/4096\n",
            "1432/4096\n",
            "1433/4096\n",
            "1434/4096\n",
            "1435/4096\n",
            "1436/4096\n",
            "1437/4096\n",
            "1438/4096\n",
            "1439/4096\n",
            "1440/4096\n",
            "1441/4096\n",
            "1442/4096\n",
            "1443/4096\n",
            "1444/4096\n",
            "1445/4096\n",
            "1446/4096\n",
            "1447/4096\n",
            "1448/4096\n",
            "1449/4096\n",
            "1450/4096\n",
            "1451/4096\n",
            "1452/4096\n",
            "1453/4096\n",
            "1454/4096\n",
            "1455/4096\n",
            "1456/4096\n",
            "1457/4096\n",
            "1458/4096\n",
            "1459/4096\n",
            "1460/4096\n",
            "1461/4096\n",
            "1462/4096\n",
            "1463/4096\n",
            "1464/4096\n",
            "1465/4096\n",
            "1466/4096\n",
            "1467/4096\n",
            "1468/4096\n",
            "1469/4096\n",
            "1470/4096\n",
            "1471/4096\n",
            "1472/4096\n",
            "1473/4096\n",
            "1474/4096\n",
            "1475/4096\n",
            "1476/4096\n",
            "1477/4096\n",
            "1478/4096\n",
            "1479/4096\n",
            "1480/4096\n",
            "1481/4096\n",
            "1482/4096\n",
            "1483/4096\n",
            "1484/4096\n",
            "1485/4096\n",
            "1486/4096\n",
            "1487/4096\n",
            "1488/4096\n",
            "1489/4096\n",
            "1490/4096\n",
            "1491/4096\n",
            "1492/4096\n",
            "1493/4096\n",
            "1494/4096\n",
            "1495/4096\n",
            "1496/4096\n",
            "1497/4096\n",
            "1498/4096\n",
            "1499/4096\n",
            "1500/4096\n",
            "1501/4096\n",
            "1502/4096\n",
            "1503/4096\n",
            "1504/4096\n",
            "1505/4096\n",
            "1506/4096\n",
            "1507/4096\n",
            "1508/4096\n",
            "1509/4096\n",
            "1510/4096\n",
            "1511/4096\n",
            "1512/4096\n",
            "1513/4096\n",
            "1514/4096\n",
            "1515/4096\n",
            "1516/4096\n",
            "1517/4096\n",
            "1518/4096\n",
            "1519/4096\n",
            "1520/4096\n",
            "1521/4096\n",
            "1522/4096\n",
            "1523/4096\n",
            "1524/4096\n",
            "1525/4096\n",
            "1526/4096\n",
            "1527/4096\n",
            "1528/4096\n",
            "1529/4096\n",
            "1530/4096\n",
            "1531/4096\n",
            "1532/4096\n",
            "1533/4096\n",
            "1534/4096\n",
            "1535/4096\n",
            "1536/4096\n",
            "1537/4096\n",
            "1538/4096\n",
            "1539/4096\n",
            "1540/4096\n",
            "1541/4096\n",
            "1542/4096\n",
            "1543/4096\n",
            "1544/4096\n",
            "1545/4096\n",
            "1546/4096\n",
            "1547/4096\n",
            "1548/4096\n",
            "1549/4096\n",
            "1550/4096\n",
            "1551/4096\n",
            "1552/4096\n",
            "1553/4096\n",
            "1554/4096\n",
            "1555/4096\n",
            "1556/4096\n",
            "1557/4096\n",
            "1558/4096\n",
            "1559/4096\n",
            "1560/4096\n",
            "1561/4096\n",
            "1562/4096\n",
            "1563/4096\n",
            "1564/4096\n",
            "1565/4096\n",
            "1566/4096\n",
            "1567/4096\n",
            "1568/4096\n",
            "1569/4096\n",
            "1570/4096\n",
            "1571/4096\n",
            "1572/4096\n",
            "1573/4096\n",
            "1574/4096\n",
            "1575/4096\n",
            "1576/4096\n",
            "1577/4096\n",
            "1578/4096\n",
            "1579/4096\n",
            "1580/4096\n",
            "1581/4096\n",
            "1582/4096\n",
            "1583/4096\n",
            "1584/4096\n",
            "1585/4096\n",
            "1586/4096\n",
            "1587/4096\n",
            "1588/4096\n",
            "1589/4096\n",
            "1590/4096\n",
            "1591/4096\n",
            "1592/4096\n",
            "1593/4096\n",
            "1594/4096\n",
            "1595/4096\n",
            "1596/4096\n",
            "1597/4096\n",
            "1598/4096\n",
            "1599/4096\n",
            "1600/4096\n",
            "1601/4096\n",
            "1602/4096\n",
            "1603/4096\n",
            "1604/4096\n",
            "1605/4096\n",
            "1606/4096\n",
            "1607/4096\n",
            "1608/4096\n",
            "1609/4096\n",
            "1610/4096\n",
            "1611/4096\n",
            "1612/4096\n",
            "1613/4096\n",
            "1614/4096\n",
            "1615/4096\n",
            "1616/4096\n",
            "1617/4096\n",
            "1618/4096\n",
            "1619/4096\n",
            "1620/4096\n",
            "1621/4096\n",
            "1622/4096\n",
            "1623/4096\n",
            "1624/4096\n",
            "1625/4096\n",
            "1626/4096\n",
            "1627/4096\n",
            "1628/4096\n",
            "1629/4096\n",
            "1630/4096\n",
            "1631/4096\n",
            "1632/4096\n",
            "1633/4096\n",
            "1634/4096\n",
            "1635/4096\n",
            "1636/4096\n",
            "1637/4096\n",
            "1638/4096\n",
            "1639/4096\n",
            "1640/4096\n",
            "1641/4096\n",
            "1642/4096\n",
            "1643/4096\n",
            "1644/4096\n",
            "1645/4096\n",
            "1646/4096\n",
            "1647/4096\n",
            "1648/4096\n",
            "1649/4096\n",
            "1650/4096\n",
            "1651/4096\n",
            "1652/4096\n",
            "1653/4096\n",
            "1654/4096\n",
            "1655/4096\n",
            "1656/4096\n",
            "1657/4096\n",
            "1658/4096\n",
            "1659/4096\n",
            "1660/4096\n",
            "1661/4096\n",
            "1662/4096\n",
            "1663/4096\n",
            "1664/4096\n",
            "1665/4096\n",
            "1666/4096\n",
            "1667/4096\n",
            "1668/4096\n",
            "1669/4096\n",
            "1670/4096\n",
            "1671/4096\n",
            "1672/4096\n",
            "1673/4096\n",
            "1674/4096\n",
            "1675/4096\n",
            "1676/4096\n",
            "1677/4096\n",
            "1678/4096\n",
            "1679/4096\n",
            "1680/4096\n",
            "1681/4096\n",
            "1682/4096\n",
            "1683/4096\n",
            "1684/4096\n",
            "1685/4096\n",
            "1686/4096\n",
            "1687/4096\n",
            "1688/4096\n",
            "1689/4096\n",
            "1690/4096\n",
            "1691/4096\n",
            "1692/4096\n",
            "1693/4096\n",
            "1694/4096\n",
            "1695/4096\n",
            "1696/4096\n",
            "1697/4096\n",
            "1698/4096\n",
            "1699/4096\n",
            "1700/4096\n",
            "1701/4096\n",
            "1702/4096\n",
            "1703/4096\n",
            "1704/4096\n",
            "1705/4096\n",
            "1706/4096\n",
            "1707/4096\n",
            "1708/4096\n",
            "1709/4096\n",
            "1710/4096\n",
            "1711/4096\n",
            "1712/4096\n",
            "1713/4096\n",
            "1714/4096\n",
            "1715/4096\n",
            "1716/4096\n",
            "1717/4096\n",
            "1718/4096\n",
            "1719/4096\n",
            "1720/4096\n",
            "1721/4096\n",
            "1722/4096\n",
            "1723/4096\n",
            "1724/4096\n",
            "1725/4096\n",
            "1726/4096\n",
            "1727/4096\n",
            "1728/4096\n",
            "1729/4096\n",
            "1730/4096\n",
            "1731/4096\n",
            "1732/4096\n",
            "1733/4096\n",
            "1734/4096\n",
            "1735/4096\n",
            "1736/4096\n",
            "1737/4096\n",
            "1738/4096\n",
            "1739/4096\n",
            "1740/4096\n",
            "1741/4096\n",
            "1742/4096\n",
            "1743/4096\n",
            "1744/4096\n",
            "1745/4096\n",
            "1746/4096\n",
            "1747/4096\n",
            "1748/4096\n",
            "1749/4096\n",
            "1750/4096\n",
            "1751/4096\n",
            "1752/4096\n",
            "1753/4096\n",
            "1754/4096\n",
            "1755/4096\n",
            "1756/4096\n",
            "1757/4096\n",
            "1758/4096\n",
            "1759/4096\n",
            "1760/4096\n",
            "1761/4096\n",
            "1762/4096\n",
            "1763/4096\n",
            "1764/4096\n",
            "1765/4096\n",
            "1766/4096\n",
            "1767/4096\n",
            "1768/4096\n",
            "1769/4096\n",
            "1770/4096\n",
            "1771/4096\n",
            "1772/4096\n",
            "1773/4096\n",
            "1774/4096\n",
            "1775/4096\n",
            "1776/4096\n",
            "1777/4096\n",
            "1778/4096\n",
            "1779/4096\n",
            "1780/4096\n",
            "1781/4096\n",
            "1782/4096\n",
            "1783/4096\n",
            "1784/4096\n",
            "1785/4096\n",
            "1786/4096\n",
            "1787/4096\n",
            "1788/4096\n",
            "1789/4096\n",
            "1790/4096\n",
            "1791/4096\n",
            "1792/4096\n",
            "1793/4096\n",
            "1794/4096\n",
            "1795/4096\n",
            "1796/4096\n",
            "1797/4096\n",
            "1798/4096\n",
            "1799/4096\n",
            "1800/4096\n",
            "1801/4096\n",
            "1802/4096\n",
            "1803/4096\n",
            "1804/4096\n",
            "1805/4096\n",
            "1806/4096\n",
            "1807/4096\n",
            "1808/4096\n",
            "1809/4096\n",
            "1810/4096\n",
            "1811/4096\n",
            "1812/4096\n",
            "1813/4096\n",
            "1814/4096\n",
            "1815/4096\n",
            "1816/4096\n",
            "1817/4096\n",
            "1818/4096\n",
            "1819/4096\n",
            "1820/4096\n",
            "1821/4096\n",
            "1822/4096\n",
            "1823/4096\n",
            "1824/4096\n",
            "1825/4096\n",
            "1826/4096\n",
            "1827/4096\n",
            "1828/4096\n",
            "1829/4096\n",
            "1830/4096\n",
            "1831/4096\n",
            "1832/4096\n",
            "1833/4096\n",
            "1834/4096\n",
            "1835/4096\n",
            "1836/4096\n",
            "1837/4096\n",
            "1838/4096\n",
            "1839/4096\n",
            "1840/4096\n",
            "1841/4096\n",
            "1842/4096\n",
            "1843/4096\n",
            "1844/4096\n",
            "1845/4096\n",
            "1846/4096\n",
            "1847/4096\n",
            "1848/4096\n",
            "1849/4096\n",
            "1850/4096\n",
            "1851/4096\n",
            "1852/4096\n",
            "1853/4096\n",
            "1854/4096\n",
            "1855/4096\n",
            "1856/4096\n",
            "1857/4096\n",
            "1858/4096\n",
            "1859/4096\n",
            "1860/4096\n",
            "1861/4096\n",
            "1862/4096\n",
            "1863/4096\n",
            "1864/4096\n",
            "1865/4096\n",
            "1866/4096\n",
            "1867/4096\n",
            "1868/4096\n",
            "1869/4096\n",
            "1870/4096\n",
            "1871/4096\n",
            "1872/4096\n",
            "1873/4096\n",
            "1874/4096\n",
            "1875/4096\n",
            "1876/4096\n",
            "1877/4096\n",
            "1878/4096\n",
            "1879/4096\n",
            "1880/4096\n",
            "1881/4096\n",
            "1882/4096\n",
            "1883/4096\n",
            "1884/4096\n",
            "1885/4096\n",
            "1886/4096\n",
            "1887/4096\n",
            "1888/4096\n",
            "1889/4096\n",
            "1890/4096\n",
            "1891/4096\n",
            "1892/4096\n",
            "1893/4096\n",
            "1894/4096\n",
            "1895/4096\n",
            "1896/4096\n",
            "1897/4096\n",
            "1898/4096\n",
            "1899/4096\n",
            "1900/4096\n",
            "1901/4096\n",
            "1902/4096\n",
            "1903/4096\n",
            "1904/4096\n",
            "1905/4096\n",
            "1906/4096\n",
            "1907/4096\n",
            "1908/4096\n",
            "1909/4096\n",
            "1910/4096\n",
            "1911/4096\n",
            "1912/4096\n",
            "1913/4096\n",
            "1914/4096\n",
            "1915/4096\n",
            "1916/4096\n",
            "1917/4096\n",
            "1918/4096\n",
            "1919/4096\n",
            "1920/4096\n",
            "1921/4096\n",
            "1922/4096\n",
            "1923/4096\n",
            "1924/4096\n",
            "1925/4096\n",
            "1926/4096\n",
            "1927/4096\n",
            "1928/4096\n",
            "1929/4096\n",
            "1930/4096\n",
            "1931/4096\n",
            "1932/4096\n",
            "1933/4096\n",
            "1934/4096\n",
            "1935/4096\n",
            "1936/4096\n",
            "1937/4096\n",
            "1938/4096\n",
            "1939/4096\n",
            "1940/4096\n",
            "1941/4096\n",
            "1942/4096\n",
            "1943/4096\n",
            "1944/4096\n",
            "1945/4096\n",
            "1946/4096\n",
            "1947/4096\n",
            "1948/4096\n",
            "1949/4096\n",
            "1950/4096\n",
            "1951/4096\n",
            "1952/4096\n",
            "1953/4096\n",
            "1954/4096\n",
            "1955/4096\n",
            "1956/4096\n",
            "1957/4096\n",
            "1958/4096\n",
            "1959/4096\n",
            "1960/4096\n",
            "1961/4096\n",
            "1962/4096\n",
            "1963/4096\n",
            "1964/4096\n",
            "1965/4096\n",
            "1966/4096\n",
            "1967/4096\n",
            "1968/4096\n",
            "1969/4096\n",
            "1970/4096\n",
            "1971/4096\n",
            "1972/4096\n",
            "1973/4096\n",
            "1974/4096\n",
            "1975/4096\n",
            "1976/4096\n",
            "1977/4096\n",
            "1978/4096\n",
            "1979/4096\n",
            "1980/4096\n",
            "1981/4096\n",
            "1982/4096\n",
            "1983/4096\n",
            "1984/4096\n",
            "1985/4096\n",
            "1986/4096\n",
            "1987/4096\n",
            "1988/4096\n",
            "1989/4096\n",
            "1990/4096\n",
            "1991/4096\n",
            "1992/4096\n",
            "1993/4096\n",
            "1994/4096\n",
            "1995/4096\n",
            "1996/4096\n",
            "1997/4096\n",
            "1998/4096\n",
            "1999/4096\n",
            "2000/4096\n",
            "2001/4096\n",
            "2002/4096\n",
            "2003/4096\n",
            "2004/4096\n",
            "2005/4096\n",
            "2006/4096\n",
            "2007/4096\n",
            "2008/4096\n",
            "2009/4096\n",
            "2010/4096\n",
            "2011/4096\n",
            "2012/4096\n",
            "2013/4096\n",
            "2014/4096\n",
            "2015/4096\n",
            "2016/4096\n",
            "2017/4096\n",
            "2018/4096\n",
            "2019/4096\n",
            "2020/4096\n",
            "2021/4096\n",
            "2022/4096\n",
            "2023/4096\n",
            "2024/4096\n",
            "2025/4096\n",
            "2026/4096\n",
            "2027/4096\n",
            "2028/4096\n",
            "2029/4096\n",
            "2030/4096\n",
            "2031/4096\n",
            "2032/4096\n",
            "2033/4096\n",
            "2034/4096\n",
            "2035/4096\n",
            "2036/4096\n",
            "2037/4096\n",
            "2038/4096\n",
            "2039/4096\n",
            "2040/4096\n",
            "2041/4096\n",
            "2042/4096\n",
            "2043/4096\n",
            "2044/4096\n",
            "2045/4096\n",
            "2046/4096\n",
            "2047/4096\n",
            "2048/4096\n",
            "2049/4096\n",
            "2050/4096\n",
            "2051/4096\n",
            "2052/4096\n",
            "2053/4096\n",
            "2054/4096\n",
            "2055/4096\n",
            "2056/4096\n",
            "2057/4096\n",
            "2058/4096\n",
            "2059/4096\n",
            "2060/4096\n",
            "2061/4096\n",
            "2062/4096\n",
            "2063/4096\n",
            "2064/4096\n",
            "2065/4096\n",
            "2066/4096\n",
            "2067/4096\n",
            "2068/4096\n",
            "2069/4096\n",
            "2070/4096\n",
            "2071/4096\n",
            "2072/4096\n",
            "2073/4096\n",
            "2074/4096\n",
            "2075/4096\n",
            "2076/4096\n",
            "2077/4096\n",
            "2078/4096\n",
            "2079/4096\n",
            "2080/4096\n",
            "2081/4096\n",
            "2082/4096\n",
            "2083/4096\n",
            "2084/4096\n",
            "2085/4096\n",
            "2086/4096\n",
            "2087/4096\n",
            "2088/4096\n",
            "2089/4096\n",
            "2090/4096\n",
            "2091/4096\n",
            "2092/4096\n",
            "2093/4096\n",
            "2094/4096\n",
            "2095/4096\n",
            "2096/4096\n",
            "2097/4096\n",
            "2098/4096\n",
            "2099/4096\n",
            "2100/4096\n",
            "2101/4096\n",
            "2102/4096\n",
            "2103/4096\n",
            "2104/4096\n",
            "2105/4096\n",
            "2106/4096\n",
            "2107/4096\n",
            "2108/4096\n",
            "2109/4096\n",
            "2110/4096\n",
            "2111/4096\n",
            "2112/4096\n",
            "2113/4096\n",
            "2114/4096\n",
            "2115/4096\n",
            "2116/4096\n",
            "2117/4096\n",
            "2118/4096\n",
            "2119/4096\n",
            "2120/4096\n",
            "2121/4096\n",
            "2122/4096\n",
            "2123/4096\n",
            "2124/4096\n",
            "2125/4096\n",
            "2126/4096\n",
            "2127/4096\n",
            "2128/4096\n",
            "2129/4096\n",
            "2130/4096\n",
            "2131/4096\n",
            "2132/4096\n",
            "2133/4096\n",
            "2134/4096\n",
            "2135/4096\n",
            "2136/4096\n",
            "2137/4096\n",
            "2138/4096\n",
            "2139/4096\n",
            "2140/4096\n",
            "2141/4096\n",
            "2142/4096\n",
            "2143/4096\n",
            "2144/4096\n",
            "2145/4096\n",
            "2146/4096\n",
            "2147/4096\n",
            "2148/4096\n",
            "2149/4096\n",
            "2150/4096\n",
            "2151/4096\n",
            "2152/4096\n",
            "2153/4096\n",
            "2154/4096\n",
            "2155/4096\n",
            "2156/4096\n",
            "2157/4096\n",
            "2158/4096\n",
            "2159/4096\n",
            "2160/4096\n",
            "2161/4096\n",
            "2162/4096\n",
            "2163/4096\n",
            "2164/4096\n",
            "2165/4096\n",
            "2166/4096\n",
            "2167/4096\n",
            "2168/4096\n",
            "2169/4096\n",
            "2170/4096\n",
            "2171/4096\n",
            "2172/4096\n",
            "2173/4096\n",
            "2174/4096\n",
            "2175/4096\n",
            "2176/4096\n",
            "2177/4096\n",
            "2178/4096\n",
            "2179/4096\n",
            "2180/4096\n",
            "2181/4096\n",
            "2182/4096\n",
            "2183/4096\n",
            "2184/4096\n",
            "2185/4096\n",
            "2186/4096\n",
            "2187/4096\n",
            "2188/4096\n",
            "2189/4096\n",
            "2190/4096\n",
            "2191/4096\n",
            "2192/4096\n",
            "2193/4096\n",
            "2194/4096\n",
            "2195/4096\n",
            "2196/4096\n",
            "2197/4096\n",
            "2198/4096\n",
            "2199/4096\n",
            "2200/4096\n",
            "2201/4096\n",
            "2202/4096\n",
            "2203/4096\n",
            "2204/4096\n",
            "2205/4096\n",
            "2206/4096\n",
            "2207/4096\n",
            "2208/4096\n",
            "2209/4096\n",
            "2210/4096\n",
            "2211/4096\n",
            "2212/4096\n",
            "2213/4096\n",
            "2214/4096\n",
            "2215/4096\n",
            "2216/4096\n",
            "2217/4096\n",
            "2218/4096\n",
            "2219/4096\n",
            "2220/4096\n",
            "2221/4096\n",
            "2222/4096\n",
            "2223/4096\n",
            "2224/4096\n",
            "2225/4096\n",
            "2226/4096\n",
            "2227/4096\n",
            "2228/4096\n",
            "2229/4096\n",
            "2230/4096\n",
            "2231/4096\n",
            "2232/4096\n",
            "2233/4096\n",
            "2234/4096\n",
            "2235/4096\n",
            "2236/4096\n",
            "2237/4096\n",
            "2238/4096\n",
            "2239/4096\n",
            "2240/4096\n",
            "2241/4096\n",
            "2242/4096\n",
            "2243/4096\n",
            "2244/4096\n",
            "2245/4096\n",
            "2246/4096\n",
            "2247/4096\n",
            "2248/4096\n",
            "2249/4096\n",
            "2250/4096\n",
            "2251/4096\n",
            "2252/4096\n",
            "2253/4096\n",
            "2254/4096\n",
            "2255/4096\n",
            "2256/4096\n",
            "2257/4096\n",
            "2258/4096\n",
            "2259/4096\n",
            "2260/4096\n",
            "2261/4096\n",
            "2262/4096\n",
            "2263/4096\n",
            "2264/4096\n",
            "2265/4096\n",
            "2266/4096\n",
            "2267/4096\n",
            "2268/4096\n",
            "2269/4096\n",
            "2270/4096\n",
            "2271/4096\n",
            "2272/4096\n",
            "2273/4096\n",
            "2274/4096\n",
            "2275/4096\n",
            "2276/4096\n",
            "2277/4096\n",
            "2278/4096\n",
            "2279/4096\n",
            "2280/4096\n",
            "2281/4096\n",
            "2282/4096\n",
            "2283/4096\n",
            "2284/4096\n",
            "2285/4096\n",
            "2286/4096\n",
            "2287/4096\n",
            "2288/4096\n",
            "2289/4096\n",
            "2290/4096\n",
            "2291/4096\n",
            "2292/4096\n",
            "2293/4096\n",
            "2294/4096\n",
            "2295/4096\n",
            "2296/4096\n",
            "2297/4096\n",
            "2298/4096\n",
            "2299/4096\n",
            "2300/4096\n",
            "2301/4096\n",
            "2302/4096\n",
            "2303/4096\n",
            "2304/4096\n",
            "2305/4096\n",
            "2306/4096\n",
            "2307/4096\n",
            "2308/4096\n",
            "2309/4096\n",
            "2310/4096\n",
            "2311/4096\n",
            "2312/4096\n",
            "2313/4096\n",
            "2314/4096\n",
            "2315/4096\n",
            "2316/4096\n",
            "2317/4096\n",
            "2318/4096\n",
            "2319/4096\n",
            "2320/4096\n",
            "2321/4096\n",
            "2322/4096\n",
            "2323/4096\n",
            "2324/4096\n",
            "2325/4096\n",
            "2326/4096\n",
            "2327/4096\n",
            "2328/4096\n",
            "2329/4096\n",
            "2330/4096\n",
            "2331/4096\n",
            "2332/4096\n",
            "2333/4096\n",
            "2334/4096\n",
            "2335/4096\n",
            "2336/4096\n",
            "2337/4096\n",
            "2338/4096\n",
            "2339/4096\n",
            "2340/4096\n",
            "2341/4096\n",
            "2342/4096\n",
            "2343/4096\n",
            "2344/4096\n",
            "2345/4096\n",
            "2346/4096\n",
            "2347/4096\n",
            "2348/4096\n",
            "2349/4096\n",
            "2350/4096\n",
            "2351/4096\n",
            "2352/4096\n",
            "2353/4096\n",
            "2354/4096\n",
            "2355/4096\n",
            "2356/4096\n",
            "2357/4096\n",
            "2358/4096\n",
            "2359/4096\n",
            "2360/4096\n",
            "2361/4096\n",
            "2362/4096\n",
            "2363/4096\n",
            "2364/4096\n",
            "2365/4096\n",
            "2366/4096\n",
            "2367/4096\n",
            "2368/4096\n",
            "2369/4096\n",
            "2370/4096\n",
            "2371/4096\n",
            "2372/4096\n",
            "2373/4096\n",
            "2374/4096\n",
            "2375/4096\n",
            "2376/4096\n",
            "2377/4096\n",
            "2378/4096\n",
            "2379/4096\n",
            "2380/4096\n",
            "2381/4096\n",
            "2382/4096\n",
            "2383/4096\n",
            "2384/4096\n",
            "2385/4096\n",
            "2386/4096\n",
            "2387/4096\n",
            "2388/4096\n",
            "2389/4096\n",
            "2390/4096\n",
            "2391/4096\n",
            "2392/4096\n",
            "2393/4096\n",
            "2394/4096\n",
            "2395/4096\n",
            "2396/4096\n",
            "2397/4096\n",
            "2398/4096\n",
            "2399/4096\n",
            "2400/4096\n",
            "2401/4096\n",
            "2402/4096\n",
            "2403/4096\n",
            "2404/4096\n",
            "2405/4096\n",
            "2406/4096\n",
            "2407/4096\n",
            "2408/4096\n",
            "2409/4096\n",
            "2410/4096\n",
            "2411/4096\n",
            "2412/4096\n",
            "2413/4096\n",
            "2414/4096\n",
            "2415/4096\n",
            "2416/4096\n",
            "2417/4096\n",
            "2418/4096\n",
            "2419/4096\n",
            "2420/4096\n",
            "2421/4096\n",
            "2422/4096\n",
            "2423/4096\n",
            "2424/4096\n",
            "2425/4096\n",
            "2426/4096\n",
            "2427/4096\n",
            "2428/4096\n",
            "2429/4096\n",
            "2430/4096\n",
            "2431/4096\n",
            "2432/4096\n",
            "2433/4096\n",
            "2434/4096\n",
            "2435/4096\n",
            "2436/4096\n",
            "2437/4096\n",
            "2438/4096\n",
            "2439/4096\n",
            "2440/4096\n",
            "2441/4096\n",
            "2442/4096\n",
            "2443/4096\n",
            "2444/4096\n",
            "2445/4096\n",
            "2446/4096\n",
            "2447/4096\n",
            "2448/4096\n",
            "2449/4096\n",
            "2450/4096\n",
            "2451/4096\n",
            "2452/4096\n",
            "2453/4096\n",
            "2454/4096\n",
            "2455/4096\n",
            "2456/4096\n",
            "2457/4096\n",
            "2458/4096\n",
            "2459/4096\n",
            "2460/4096\n",
            "2461/4096\n",
            "2462/4096\n",
            "2463/4096\n",
            "2464/4096\n",
            "2465/4096\n",
            "2466/4096\n",
            "2467/4096\n",
            "2468/4096\n",
            "2469/4096\n",
            "2470/4096\n",
            "2471/4096\n",
            "2472/4096\n",
            "2473/4096\n",
            "2474/4096\n",
            "2475/4096\n",
            "2476/4096\n",
            "2477/4096\n",
            "2478/4096\n",
            "2479/4096\n",
            "2480/4096\n",
            "2481/4096\n",
            "2482/4096\n",
            "2483/4096\n",
            "2484/4096\n",
            "2485/4096\n",
            "2486/4096\n",
            "2487/4096\n",
            "2488/4096\n",
            "2489/4096\n",
            "2490/4096\n",
            "2491/4096\n",
            "2492/4096\n",
            "2493/4096\n",
            "2494/4096\n",
            "2495/4096\n",
            "2496/4096\n",
            "2497/4096\n",
            "2498/4096\n",
            "2499/4096\n",
            "2500/4096\n",
            "2501/4096\n",
            "2502/4096\n",
            "2503/4096\n",
            "2504/4096\n",
            "2505/4096\n",
            "2506/4096\n",
            "2507/4096\n",
            "2508/4096\n",
            "2509/4096\n",
            "2510/4096\n",
            "2511/4096\n",
            "2512/4096\n",
            "2513/4096\n",
            "2514/4096\n",
            "2515/4096\n",
            "2516/4096\n",
            "2517/4096\n",
            "2518/4096\n",
            "2519/4096\n",
            "2520/4096\n",
            "2521/4096\n",
            "2522/4096\n",
            "2523/4096\n",
            "2524/4096\n",
            "2525/4096\n",
            "2526/4096\n",
            "2527/4096\n",
            "2528/4096\n",
            "2529/4096\n",
            "2530/4096\n",
            "2531/4096\n",
            "2532/4096\n",
            "2533/4096\n",
            "2534/4096\n",
            "2535/4096\n",
            "2536/4096\n",
            "2537/4096\n",
            "2538/4096\n",
            "2539/4096\n",
            "2540/4096\n",
            "2541/4096\n",
            "2542/4096\n",
            "2543/4096\n",
            "2544/4096\n",
            "2545/4096\n",
            "2546/4096\n",
            "2547/4096\n",
            "2548/4096\n",
            "2549/4096\n",
            "2550/4096\n",
            "2551/4096\n",
            "2552/4096\n",
            "2553/4096\n",
            "2554/4096\n",
            "2555/4096\n",
            "2556/4096\n",
            "2557/4096\n",
            "2558/4096\n",
            "2559/4096\n",
            "2560/4096\n",
            "2561/4096\n",
            "2562/4096\n",
            "2563/4096\n",
            "2564/4096\n",
            "2565/4096\n",
            "2566/4096\n",
            "2567/4096\n",
            "2568/4096\n",
            "2569/4096\n",
            "2570/4096\n",
            "2571/4096\n",
            "2572/4096\n",
            "2573/4096\n",
            "2574/4096\n",
            "2575/4096\n",
            "2576/4096\n",
            "2577/4096\n",
            "2578/4096\n",
            "2579/4096\n",
            "2580/4096\n",
            "2581/4096\n",
            "2582/4096\n",
            "2583/4096\n",
            "2584/4096\n",
            "2585/4096\n",
            "2586/4096\n",
            "2587/4096\n",
            "2588/4096\n",
            "2589/4096\n",
            "2590/4096\n",
            "2591/4096\n",
            "2592/4096\n",
            "2593/4096\n",
            "2594/4096\n",
            "2595/4096\n",
            "2596/4096\n",
            "2597/4096\n",
            "2598/4096\n",
            "2599/4096\n",
            "2600/4096\n",
            "2601/4096\n",
            "2602/4096\n",
            "2603/4096\n",
            "2604/4096\n",
            "2605/4096\n",
            "2606/4096\n",
            "2607/4096\n",
            "2608/4096\n",
            "2609/4096\n",
            "2610/4096\n",
            "2611/4096\n",
            "2612/4096\n",
            "2613/4096\n",
            "2614/4096\n",
            "2615/4096\n",
            "2616/4096\n",
            "2617/4096\n",
            "2618/4096\n",
            "2619/4096\n",
            "2620/4096\n",
            "2621/4096\n",
            "2622/4096\n",
            "2623/4096\n",
            "2624/4096\n",
            "2625/4096\n",
            "2626/4096\n",
            "2627/4096\n",
            "2628/4096\n",
            "2629/4096\n",
            "2630/4096\n",
            "2631/4096\n",
            "2632/4096\n",
            "2633/4096\n",
            "2634/4096\n",
            "2635/4096\n",
            "2636/4096\n",
            "2637/4096\n",
            "2638/4096\n",
            "2639/4096\n",
            "2640/4096\n",
            "2641/4096\n",
            "2642/4096\n",
            "2643/4096\n",
            "2644/4096\n",
            "2645/4096\n",
            "2646/4096\n",
            "2647/4096\n",
            "2648/4096\n",
            "2649/4096\n",
            "2650/4096\n",
            "2651/4096\n",
            "2652/4096\n",
            "2653/4096\n",
            "2654/4096\n",
            "2655/4096\n",
            "2656/4096\n",
            "2657/4096\n",
            "2658/4096\n",
            "2659/4096\n",
            "2660/4096\n",
            "2661/4096\n",
            "2662/4096\n",
            "2663/4096\n",
            "2664/4096\n",
            "2665/4096\n",
            "2666/4096\n",
            "2667/4096\n",
            "2668/4096\n",
            "2669/4096\n",
            "2670/4096\n",
            "2671/4096\n",
            "2672/4096\n",
            "2673/4096\n",
            "2674/4096\n",
            "2675/4096\n",
            "2676/4096\n",
            "2677/4096\n",
            "2678/4096\n",
            "2679/4096\n",
            "2680/4096\n",
            "2681/4096\n",
            "2682/4096\n",
            "2683/4096\n",
            "2684/4096\n",
            "2685/4096\n",
            "2686/4096\n",
            "2687/4096\n",
            "2688/4096\n",
            "2689/4096\n",
            "2690/4096\n",
            "2691/4096\n",
            "2692/4096\n",
            "2693/4096\n",
            "2694/4096\n",
            "2695/4096\n",
            "2696/4096\n",
            "2697/4096\n",
            "2698/4096\n",
            "2699/4096\n",
            "2700/4096\n",
            "2701/4096\n",
            "2702/4096\n",
            "2703/4096\n",
            "2704/4096\n",
            "2705/4096\n",
            "2706/4096\n",
            "2707/4096\n",
            "2708/4096\n",
            "2709/4096\n",
            "2710/4096\n",
            "2711/4096\n",
            "2712/4096\n",
            "2713/4096\n",
            "2714/4096\n",
            "2715/4096\n",
            "2716/4096\n",
            "2717/4096\n",
            "2718/4096\n",
            "2719/4096\n",
            "2720/4096\n",
            "2721/4096\n",
            "2722/4096\n",
            "2723/4096\n",
            "2724/4096\n",
            "2725/4096\n",
            "2726/4096\n",
            "2727/4096\n",
            "2728/4096\n",
            "2729/4096\n",
            "2730/4096\n",
            "2731/4096\n",
            "2732/4096\n",
            "2733/4096\n",
            "2734/4096\n",
            "2735/4096\n",
            "2736/4096\n",
            "2737/4096\n",
            "2738/4096\n",
            "2739/4096\n",
            "2740/4096\n",
            "2741/4096\n",
            "2742/4096\n",
            "2743/4096\n",
            "2744/4096\n",
            "2745/4096\n",
            "2746/4096\n",
            "2747/4096\n",
            "2748/4096\n",
            "2749/4096\n",
            "2750/4096\n",
            "2751/4096\n",
            "2752/4096\n",
            "2753/4096\n",
            "2754/4096\n",
            "2755/4096\n",
            "2756/4096\n",
            "2757/4096\n",
            "2758/4096\n",
            "2759/4096\n",
            "2760/4096\n",
            "2761/4096\n",
            "2762/4096\n",
            "2763/4096\n",
            "2764/4096\n",
            "2765/4096\n",
            "2766/4096\n",
            "2767/4096\n",
            "2768/4096\n",
            "2769/4096\n",
            "2770/4096\n",
            "2771/4096\n",
            "2772/4096\n",
            "2773/4096\n",
            "2774/4096\n",
            "2775/4096\n",
            "2776/4096\n",
            "2777/4096\n",
            "2778/4096\n",
            "2779/4096\n",
            "2780/4096\n",
            "2781/4096\n",
            "2782/4096\n",
            "2783/4096\n",
            "2784/4096\n",
            "2785/4096\n",
            "2786/4096\n",
            "2787/4096\n",
            "2788/4096\n",
            "2789/4096\n",
            "2790/4096\n",
            "2791/4096\n",
            "2792/4096\n",
            "2793/4096\n",
            "2794/4096\n",
            "2795/4096\n",
            "2796/4096\n",
            "2797/4096\n",
            "2798/4096\n",
            "2799/4096\n",
            "2800/4096\n",
            "2801/4096\n",
            "2802/4096\n",
            "2803/4096\n",
            "2804/4096\n",
            "2805/4096\n",
            "2806/4096\n",
            "2807/4096\n",
            "2808/4096\n",
            "2809/4096\n",
            "2810/4096\n",
            "2811/4096\n",
            "2812/4096\n",
            "2813/4096\n",
            "2814/4096\n",
            "2815/4096\n",
            "2816/4096\n",
            "2817/4096\n",
            "2818/4096\n",
            "2819/4096\n",
            "2820/4096\n",
            "2821/4096\n",
            "2822/4096\n",
            "2823/4096\n",
            "2824/4096\n",
            "2825/4096\n",
            "2826/4096\n",
            "2827/4096\n",
            "2828/4096\n",
            "2829/4096\n",
            "2830/4096\n",
            "2831/4096\n",
            "2832/4096\n",
            "2833/4096\n",
            "2834/4096\n",
            "2835/4096\n",
            "2836/4096\n",
            "2837/4096\n",
            "2838/4096\n",
            "2839/4096\n",
            "2840/4096\n",
            "2841/4096\n",
            "2842/4096\n",
            "2843/4096\n",
            "2844/4096\n",
            "2845/4096\n",
            "2846/4096\n",
            "2847/4096\n",
            "2848/4096\n",
            "2849/4096\n",
            "2850/4096\n",
            "2851/4096\n",
            "2852/4096\n",
            "2853/4096\n",
            "2854/4096\n",
            "2855/4096\n",
            "2856/4096\n",
            "2857/4096\n",
            "2858/4096\n",
            "2859/4096\n",
            "2860/4096\n",
            "2861/4096\n",
            "2862/4096\n",
            "2863/4096\n",
            "2864/4096\n",
            "2865/4096\n",
            "2866/4096\n",
            "2867/4096\n",
            "2868/4096\n",
            "2869/4096\n",
            "2870/4096\n",
            "2871/4096\n",
            "2872/4096\n",
            "2873/4096\n",
            "2874/4096\n",
            "2875/4096\n",
            "2876/4096\n",
            "2877/4096\n",
            "2878/4096\n",
            "2879/4096\n",
            "2880/4096\n",
            "2881/4096\n",
            "2882/4096\n",
            "2883/4096\n",
            "2884/4096\n",
            "2885/4096\n",
            "2886/4096\n",
            "2887/4096\n",
            "2888/4096\n",
            "2889/4096\n",
            "2890/4096\n",
            "2891/4096\n",
            "2892/4096\n",
            "2893/4096\n",
            "2894/4096\n",
            "2895/4096\n",
            "2896/4096\n",
            "2897/4096\n",
            "2898/4096\n",
            "2899/4096\n",
            "2900/4096\n",
            "2901/4096\n",
            "2902/4096\n",
            "2903/4096\n",
            "2904/4096\n",
            "2905/4096\n",
            "2906/4096\n",
            "2907/4096\n",
            "2908/4096\n",
            "2909/4096\n",
            "2910/4096\n",
            "2911/4096\n",
            "2912/4096\n",
            "2913/4096\n",
            "2914/4096\n",
            "2915/4096\n",
            "2916/4096\n",
            "2917/4096\n",
            "2918/4096\n",
            "2919/4096\n",
            "2920/4096\n",
            "2921/4096\n",
            "2922/4096\n",
            "2923/4096\n",
            "2924/4096\n",
            "2925/4096\n",
            "2926/4096\n",
            "2927/4096\n",
            "2928/4096\n",
            "2929/4096\n",
            "2930/4096\n",
            "2931/4096\n",
            "2932/4096\n",
            "2933/4096\n",
            "2934/4096\n",
            "2935/4096\n",
            "2936/4096\n",
            "2937/4096\n",
            "2938/4096\n",
            "2939/4096\n",
            "2940/4096\n",
            "2941/4096\n",
            "2942/4096\n",
            "2943/4096\n",
            "2944/4096\n",
            "2945/4096\n",
            "2946/4096\n",
            "2947/4096\n",
            "2948/4096\n",
            "2949/4096\n",
            "2950/4096\n",
            "2951/4096\n",
            "2952/4096\n",
            "2953/4096\n",
            "2954/4096\n",
            "2955/4096\n",
            "2956/4096\n",
            "2957/4096\n",
            "2958/4096\n",
            "2959/4096\n",
            "2960/4096\n",
            "2961/4096\n",
            "2962/4096\n",
            "2963/4096\n",
            "2964/4096\n",
            "2965/4096\n",
            "2966/4096\n",
            "2967/4096\n",
            "2968/4096\n",
            "2969/4096\n",
            "2970/4096\n",
            "2971/4096\n",
            "2972/4096\n",
            "2973/4096\n",
            "2974/4096\n",
            "2975/4096\n",
            "2976/4096\n",
            "2977/4096\n",
            "2978/4096\n",
            "2979/4096\n",
            "2980/4096\n",
            "2981/4096\n",
            "2982/4096\n",
            "2983/4096\n",
            "2984/4096\n",
            "2985/4096\n",
            "2986/4096\n",
            "2987/4096\n",
            "2988/4096\n",
            "2989/4096\n",
            "2990/4096\n",
            "2991/4096\n",
            "2992/4096\n",
            "2993/4096\n",
            "2994/4096\n",
            "2995/4096\n",
            "2996/4096\n",
            "2997/4096\n",
            "2998/4096\n",
            "2999/4096\n",
            "3000/4096\n",
            "3001/4096\n",
            "3002/4096\n",
            "3003/4096\n",
            "3004/4096\n",
            "3005/4096\n",
            "3006/4096\n",
            "3007/4096\n",
            "3008/4096\n",
            "3009/4096\n",
            "3010/4096\n",
            "3011/4096\n",
            "3012/4096\n",
            "3013/4096\n",
            "3014/4096\n",
            "3015/4096\n",
            "3016/4096\n",
            "3017/4096\n",
            "3018/4096\n",
            "3019/4096\n",
            "3020/4096\n",
            "3021/4096\n",
            "3022/4096\n",
            "3023/4096\n",
            "3024/4096\n",
            "3025/4096\n",
            "3026/4096\n",
            "3027/4096\n",
            "3028/4096\n",
            "3029/4096\n",
            "3030/4096\n",
            "3031/4096\n",
            "3032/4096\n",
            "3033/4096\n",
            "3034/4096\n",
            "3035/4096\n",
            "3036/4096\n",
            "3037/4096\n",
            "3038/4096\n",
            "3039/4096\n",
            "3040/4096\n",
            "3041/4096\n",
            "3042/4096\n",
            "3043/4096\n",
            "3044/4096\n",
            "3045/4096\n",
            "3046/4096\n",
            "3047/4096\n",
            "3048/4096\n",
            "3049/4096\n",
            "3050/4096\n",
            "3051/4096\n",
            "3052/4096\n",
            "3053/4096\n",
            "3054/4096\n",
            "3055/4096\n",
            "3056/4096\n",
            "3057/4096\n",
            "3058/4096\n",
            "3059/4096\n",
            "3060/4096\n",
            "3061/4096\n",
            "3062/4096\n",
            "3063/4096\n",
            "3064/4096\n",
            "3065/4096\n",
            "3066/4096\n",
            "3067/4096\n",
            "3068/4096\n",
            "3069/4096\n",
            "3070/4096\n",
            "3071/4096\n",
            "3072/4096\n",
            "3073/4096\n",
            "3074/4096\n",
            "3075/4096\n",
            "3076/4096\n",
            "3077/4096\n",
            "3078/4096\n",
            "3079/4096\n",
            "3080/4096\n",
            "3081/4096\n",
            "3082/4096\n",
            "3083/4096\n",
            "3084/4096\n",
            "3085/4096\n",
            "3086/4096\n",
            "3087/4096\n",
            "3088/4096\n",
            "3089/4096\n",
            "3090/4096\n",
            "3091/4096\n",
            "3092/4096\n",
            "3093/4096\n",
            "3094/4096\n",
            "3095/4096\n",
            "3096/4096\n",
            "3097/4096\n",
            "3098/4096\n",
            "3099/4096\n",
            "3100/4096\n",
            "3101/4096\n",
            "3102/4096\n",
            "3103/4096\n",
            "3104/4096\n",
            "3105/4096\n",
            "3106/4096\n",
            "3107/4096\n",
            "3108/4096\n",
            "3109/4096\n",
            "3110/4096\n",
            "3111/4096\n",
            "3112/4096\n",
            "3113/4096\n",
            "3114/4096\n",
            "3115/4096\n",
            "3116/4096\n",
            "3117/4096\n",
            "3118/4096\n",
            "3119/4096\n",
            "3120/4096\n",
            "3121/4096\n",
            "3122/4096\n",
            "3123/4096\n",
            "3124/4096\n",
            "3125/4096\n",
            "3126/4096\n",
            "3127/4096\n",
            "3128/4096\n",
            "3129/4096\n",
            "3130/4096\n",
            "3131/4096\n",
            "3132/4096\n",
            "3133/4096\n",
            "3134/4096\n",
            "3135/4096\n",
            "3136/4096\n",
            "3137/4096\n",
            "3138/4096\n",
            "3139/4096\n",
            "3140/4096\n",
            "3141/4096\n",
            "3142/4096\n",
            "3143/4096\n",
            "3144/4096\n",
            "3145/4096\n",
            "3146/4096\n",
            "3147/4096\n",
            "3148/4096\n",
            "3149/4096\n",
            "3150/4096\n",
            "3151/4096\n",
            "3152/4096\n",
            "3153/4096\n",
            "3154/4096\n",
            "3155/4096\n",
            "3156/4096\n",
            "3157/4096\n",
            "3158/4096\n",
            "3159/4096\n",
            "3160/4096\n",
            "3161/4096\n",
            "3162/4096\n",
            "3163/4096\n",
            "3164/4096\n",
            "3165/4096\n",
            "3166/4096\n",
            "3167/4096\n",
            "3168/4096\n",
            "3169/4096\n",
            "3170/4096\n",
            "3171/4096\n",
            "3172/4096\n",
            "3173/4096\n",
            "3174/4096\n",
            "3175/4096\n",
            "3176/4096\n",
            "3177/4096\n",
            "3178/4096\n",
            "3179/4096\n",
            "3180/4096\n",
            "3181/4096\n",
            "3182/4096\n",
            "3183/4096\n",
            "3184/4096\n",
            "3185/4096\n",
            "3186/4096\n",
            "3187/4096\n",
            "3188/4096\n",
            "3189/4096\n",
            "3190/4096\n",
            "3191/4096\n",
            "3192/4096\n",
            "3193/4096\n",
            "3194/4096\n",
            "3195/4096\n",
            "3196/4096\n",
            "3197/4096\n",
            "3198/4096\n",
            "3199/4096\n",
            "3200/4096\n",
            "3201/4096\n",
            "3202/4096\n",
            "3203/4096\n",
            "3204/4096\n",
            "3205/4096\n",
            "3206/4096\n",
            "3207/4096\n",
            "3208/4096\n",
            "3209/4096\n",
            "3210/4096\n",
            "3211/4096\n",
            "3212/4096\n",
            "3213/4096\n",
            "3214/4096\n",
            "3215/4096\n",
            "3216/4096\n",
            "3217/4096\n",
            "3218/4096\n",
            "3219/4096\n",
            "3220/4096\n",
            "3221/4096\n",
            "3222/4096\n",
            "3223/4096\n",
            "3224/4096\n",
            "3225/4096\n",
            "3226/4096\n",
            "3227/4096\n",
            "3228/4096\n",
            "3229/4096\n",
            "3230/4096\n",
            "3231/4096\n",
            "3232/4096\n",
            "3233/4096\n",
            "3234/4096\n",
            "3235/4096\n",
            "3236/4096\n",
            "3237/4096\n",
            "3238/4096\n",
            "3239/4096\n",
            "3240/4096\n",
            "3241/4096\n",
            "3242/4096\n",
            "3243/4096\n",
            "3244/4096\n",
            "3245/4096\n",
            "3246/4096\n",
            "3247/4096\n",
            "3248/4096\n",
            "3249/4096\n",
            "3250/4096\n",
            "3251/4096\n",
            "3252/4096\n",
            "3253/4096\n",
            "3254/4096\n",
            "3255/4096\n",
            "3256/4096\n",
            "3257/4096\n",
            "3258/4096\n",
            "3259/4096\n",
            "3260/4096\n",
            "3261/4096\n",
            "3262/4096\n",
            "3263/4096\n",
            "3264/4096\n",
            "3265/4096\n",
            "3266/4096\n",
            "3267/4096\n",
            "3268/4096\n",
            "3269/4096\n",
            "3270/4096\n",
            "3271/4096\n",
            "3272/4096\n",
            "3273/4096\n",
            "3274/4096\n",
            "3275/4096\n",
            "3276/4096\n",
            "3277/4096\n",
            "3278/4096\n",
            "3279/4096\n",
            "3280/4096\n",
            "3281/4096\n",
            "3282/4096\n",
            "3283/4096\n",
            "3284/4096\n",
            "3285/4096\n",
            "3286/4096\n",
            "3287/4096\n",
            "3288/4096\n",
            "3289/4096\n",
            "3290/4096\n",
            "3291/4096\n",
            "3292/4096\n",
            "3293/4096\n",
            "3294/4096\n",
            "3295/4096\n",
            "3296/4096\n",
            "3297/4096\n",
            "3298/4096\n",
            "3299/4096\n",
            "3300/4096\n",
            "3301/4096\n",
            "3302/4096\n",
            "3303/4096\n",
            "3304/4096\n",
            "3305/4096\n",
            "3306/4096\n",
            "3307/4096\n",
            "3308/4096\n",
            "3309/4096\n",
            "3310/4096\n",
            "3311/4096\n",
            "3312/4096\n",
            "3313/4096\n",
            "3314/4096\n",
            "3315/4096\n",
            "3316/4096\n",
            "3317/4096\n",
            "3318/4096\n",
            "3319/4096\n",
            "3320/4096\n",
            "3321/4096\n",
            "3322/4096\n",
            "3323/4096\n",
            "3324/4096\n",
            "3325/4096\n",
            "3326/4096\n",
            "3327/4096\n",
            "3328/4096\n",
            "3329/4096\n",
            "3330/4096\n",
            "3331/4096\n",
            "3332/4096\n",
            "3333/4096\n",
            "3334/4096\n",
            "3335/4096\n",
            "3336/4096\n",
            "3337/4096\n",
            "3338/4096\n",
            "3339/4096\n",
            "3340/4096\n",
            "3341/4096\n",
            "3342/4096\n",
            "3343/4096\n",
            "3344/4096\n",
            "3345/4096\n",
            "3346/4096\n",
            "3347/4096\n",
            "3348/4096\n",
            "3349/4096\n",
            "3350/4096\n",
            "3351/4096\n",
            "3352/4096\n",
            "3353/4096\n",
            "3354/4096\n",
            "3355/4096\n",
            "3356/4096\n",
            "3357/4096\n",
            "3358/4096\n",
            "3359/4096\n",
            "3360/4096\n",
            "3361/4096\n",
            "3362/4096\n",
            "3363/4096\n",
            "3364/4096\n",
            "3365/4096\n",
            "3366/4096\n",
            "3367/4096\n",
            "3368/4096\n",
            "3369/4096\n",
            "3370/4096\n",
            "3371/4096\n",
            "3372/4096\n",
            "3373/4096\n",
            "3374/4096\n",
            "3375/4096\n",
            "3376/4096\n",
            "3377/4096\n",
            "3378/4096\n",
            "3379/4096\n",
            "3380/4096\n",
            "3381/4096\n",
            "3382/4096\n",
            "3383/4096\n",
            "3384/4096\n",
            "3385/4096\n",
            "3386/4096\n",
            "3387/4096\n",
            "3388/4096\n",
            "3389/4096\n",
            "3390/4096\n",
            "3391/4096\n",
            "3392/4096\n",
            "3393/4096\n",
            "3394/4096\n",
            "3395/4096\n",
            "3396/4096\n",
            "3397/4096\n",
            "3398/4096\n",
            "3399/4096\n",
            "3400/4096\n",
            "3401/4096\n",
            "3402/4096\n",
            "3403/4096\n",
            "3404/4096\n",
            "3405/4096\n",
            "3406/4096\n",
            "3407/4096\n",
            "3408/4096\n",
            "3409/4096\n",
            "3410/4096\n",
            "3411/4096\n",
            "3412/4096\n",
            "3413/4096\n",
            "3414/4096\n",
            "3415/4096\n",
            "3416/4096\n",
            "3417/4096\n",
            "3418/4096\n",
            "3419/4096\n",
            "3420/4096\n",
            "3421/4096\n",
            "3422/4096\n",
            "3423/4096\n",
            "3424/4096\n",
            "3425/4096\n",
            "3426/4096\n",
            "3427/4096\n",
            "3428/4096\n",
            "3429/4096\n",
            "3430/4096\n",
            "3431/4096\n",
            "3432/4096\n",
            "3433/4096\n",
            "3434/4096\n",
            "3435/4096\n",
            "3436/4096\n",
            "3437/4096\n",
            "3438/4096\n",
            "3439/4096\n",
            "3440/4096\n",
            "3441/4096\n",
            "3442/4096\n",
            "3443/4096\n",
            "3444/4096\n",
            "3445/4096\n",
            "3446/4096\n",
            "3447/4096\n",
            "3448/4096\n",
            "3449/4096\n",
            "3450/4096\n",
            "3451/4096\n",
            "3452/4096\n",
            "3453/4096\n",
            "3454/4096\n",
            "3455/4096\n",
            "3456/4096\n",
            "3457/4096\n",
            "3458/4096\n",
            "3459/4096\n",
            "3460/4096\n",
            "3461/4096\n",
            "3462/4096\n",
            "3463/4096\n",
            "3464/4096\n",
            "3465/4096\n",
            "3466/4096\n",
            "3467/4096\n",
            "3468/4096\n",
            "3469/4096\n",
            "3470/4096\n",
            "3471/4096\n",
            "3472/4096\n",
            "3473/4096\n",
            "3474/4096\n",
            "3475/4096\n",
            "3476/4096\n",
            "3477/4096\n",
            "3478/4096\n",
            "3479/4096\n",
            "3480/4096\n",
            "3481/4096\n",
            "3482/4096\n",
            "3483/4096\n",
            "3484/4096\n",
            "3485/4096\n",
            "3486/4096\n",
            "3487/4096\n",
            "3488/4096\n",
            "3489/4096\n",
            "3490/4096\n",
            "3491/4096\n",
            "3492/4096\n",
            "3493/4096\n",
            "3494/4096\n",
            "3495/4096\n",
            "3496/4096\n",
            "3497/4096\n",
            "3498/4096\n",
            "3499/4096\n",
            "3500/4096\n",
            "3501/4096\n",
            "3502/4096\n",
            "3503/4096\n",
            "3504/4096\n",
            "3505/4096\n",
            "3506/4096\n",
            "3507/4096\n",
            "3508/4096\n",
            "3509/4096\n",
            "3510/4096\n",
            "3511/4096\n",
            "3512/4096\n",
            "3513/4096\n",
            "3514/4096\n",
            "3515/4096\n",
            "3516/4096\n",
            "3517/4096\n",
            "3518/4096\n",
            "3519/4096\n",
            "3520/4096\n",
            "3521/4096\n",
            "3522/4096\n",
            "3523/4096\n",
            "3524/4096\n",
            "3525/4096\n",
            "3526/4096\n",
            "3527/4096\n",
            "3528/4096\n",
            "3529/4096\n",
            "3530/4096\n",
            "3531/4096\n",
            "3532/4096\n",
            "3533/4096\n",
            "3534/4096\n",
            "3535/4096\n",
            "3536/4096\n",
            "3537/4096\n",
            "3538/4096\n",
            "3539/4096\n",
            "3540/4096\n",
            "3541/4096\n",
            "3542/4096\n",
            "3543/4096\n",
            "3544/4096\n",
            "3545/4096\n",
            "3546/4096\n",
            "3547/4096\n",
            "3548/4096\n",
            "3549/4096\n",
            "3550/4096\n",
            "3551/4096\n",
            "3552/4096\n",
            "3553/4096\n",
            "3554/4096\n",
            "3555/4096\n",
            "3556/4096\n",
            "3557/4096\n",
            "3558/4096\n",
            "3559/4096\n",
            "3560/4096\n",
            "3561/4096\n",
            "3562/4096\n",
            "3563/4096\n",
            "3564/4096\n",
            "3565/4096\n",
            "3566/4096\n",
            "3567/4096\n",
            "3568/4096\n",
            "3569/4096\n",
            "3570/4096\n",
            "3571/4096\n",
            "3572/4096\n",
            "3573/4096\n",
            "3574/4096\n",
            "3575/4096\n",
            "3576/4096\n",
            "3577/4096\n",
            "3578/4096\n",
            "3579/4096\n",
            "3580/4096\n",
            "3581/4096\n",
            "3582/4096\n",
            "3583/4096\n",
            "3584/4096\n",
            "3585/4096\n",
            "3586/4096\n",
            "3587/4096\n",
            "3588/4096\n",
            "3589/4096\n",
            "3590/4096\n",
            "3591/4096\n",
            "3592/4096\n",
            "3593/4096\n",
            "3594/4096\n",
            "3595/4096\n",
            "3596/4096\n",
            "3597/4096\n",
            "3598/4096\n",
            "3599/4096\n",
            "3600/4096\n",
            "3601/4096\n",
            "3602/4096\n",
            "3603/4096\n",
            "3604/4096\n",
            "3605/4096\n",
            "3606/4096\n",
            "3607/4096\n",
            "3608/4096\n",
            "3609/4096\n",
            "3610/4096\n",
            "3611/4096\n",
            "3612/4096\n",
            "3613/4096\n",
            "3614/4096\n",
            "3615/4096\n",
            "3616/4096\n",
            "3617/4096\n",
            "3618/4096\n",
            "3619/4096\n",
            "3620/4096\n",
            "3621/4096\n",
            "3622/4096\n",
            "3623/4096\n",
            "3624/4096\n",
            "3625/4096\n",
            "3626/4096\n",
            "3627/4096\n",
            "3628/4096\n",
            "3629/4096\n",
            "3630/4096\n",
            "3631/4096\n",
            "3632/4096\n",
            "3633/4096\n",
            "3634/4096\n",
            "3635/4096\n",
            "3636/4096\n",
            "3637/4096\n",
            "3638/4096\n",
            "3639/4096\n",
            "3640/4096\n",
            "3641/4096\n",
            "3642/4096\n",
            "3643/4096\n",
            "3644/4096\n",
            "3645/4096\n",
            "3646/4096\n",
            "3647/4096\n",
            "3648/4096\n",
            "3649/4096\n",
            "3650/4096\n",
            "3651/4096\n",
            "3652/4096\n",
            "3653/4096\n",
            "3654/4096\n",
            "3655/4096\n",
            "3656/4096\n",
            "3657/4096\n",
            "3658/4096\n",
            "3659/4096\n",
            "3660/4096\n",
            "3661/4096\n",
            "3662/4096\n",
            "3663/4096\n",
            "3664/4096\n",
            "3665/4096\n",
            "3666/4096\n",
            "3667/4096\n",
            "3668/4096\n",
            "3669/4096\n",
            "3670/4096\n",
            "3671/4096\n",
            "3672/4096\n",
            "3673/4096\n",
            "3674/4096\n",
            "3675/4096\n",
            "3676/4096\n",
            "3677/4096\n",
            "3678/4096\n",
            "3679/4096\n",
            "3680/4096\n",
            "3681/4096\n",
            "3682/4096\n",
            "3683/4096\n",
            "3684/4096\n",
            "3685/4096\n",
            "3686/4096\n",
            "3687/4096\n",
            "3688/4096\n",
            "3689/4096\n",
            "3690/4096\n",
            "3691/4096\n",
            "3692/4096\n",
            "3693/4096\n",
            "3694/4096\n",
            "3695/4096\n",
            "3696/4096\n",
            "3697/4096\n",
            "3698/4096\n",
            "3699/4096\n",
            "3700/4096\n",
            "3701/4096\n",
            "3702/4096\n",
            "3703/4096\n",
            "3704/4096\n",
            "3705/4096\n",
            "3706/4096\n",
            "3707/4096\n",
            "3708/4096\n",
            "3709/4096\n",
            "3710/4096\n",
            "3711/4096\n",
            "3712/4096\n",
            "3713/4096\n",
            "3714/4096\n",
            "3715/4096\n",
            "3716/4096\n",
            "3717/4096\n",
            "3718/4096\n",
            "3719/4096\n",
            "3720/4096\n",
            "3721/4096\n",
            "3722/4096\n",
            "3723/4096\n",
            "3724/4096\n",
            "3725/4096\n",
            "3726/4096\n",
            "3727/4096\n",
            "3728/4096\n",
            "3729/4096\n",
            "3730/4096\n",
            "3731/4096\n",
            "3732/4096\n",
            "3733/4096\n",
            "3734/4096\n",
            "3735/4096\n",
            "3736/4096\n",
            "3737/4096\n",
            "3738/4096\n",
            "3739/4096\n",
            "3740/4096\n",
            "3741/4096\n",
            "3742/4096\n",
            "3743/4096\n",
            "3744/4096\n",
            "3745/4096\n",
            "3746/4096\n",
            "3747/4096\n",
            "3748/4096\n",
            "3749/4096\n",
            "3750/4096\n",
            "3751/4096\n",
            "3752/4096\n",
            "3753/4096\n",
            "3754/4096\n",
            "3755/4096\n",
            "3756/4096\n",
            "3757/4096\n",
            "3758/4096\n",
            "3759/4096\n",
            "3760/4096\n",
            "3761/4096\n",
            "3762/4096\n",
            "3763/4096\n",
            "3764/4096\n",
            "3765/4096\n",
            "3766/4096\n",
            "3767/4096\n",
            "3768/4096\n",
            "3769/4096\n",
            "3770/4096\n",
            "3771/4096\n",
            "3772/4096\n",
            "3773/4096\n",
            "3774/4096\n",
            "3775/4096\n",
            "3776/4096\n",
            "3777/4096\n",
            "3778/4096\n",
            "3779/4096\n",
            "3780/4096\n",
            "3781/4096\n",
            "3782/4096\n",
            "3783/4096\n",
            "3784/4096\n",
            "3785/4096\n",
            "3786/4096\n",
            "3787/4096\n",
            "3788/4096\n",
            "3789/4096\n",
            "3790/4096\n",
            "3791/4096\n",
            "3792/4096\n",
            "3793/4096\n",
            "3794/4096\n",
            "3795/4096\n",
            "3796/4096\n",
            "3797/4096\n",
            "3798/4096\n",
            "3799/4096\n",
            "3800/4096\n",
            "3801/4096\n",
            "3802/4096\n",
            "3803/4096\n",
            "3804/4096\n",
            "3805/4096\n",
            "3806/4096\n",
            "3807/4096\n",
            "3808/4096\n",
            "3809/4096\n",
            "3810/4096\n",
            "3811/4096\n",
            "3812/4096\n",
            "3813/4096\n",
            "3814/4096\n",
            "3815/4096\n",
            "3816/4096\n",
            "3817/4096\n",
            "3818/4096\n",
            "3819/4096\n",
            "3820/4096\n",
            "3821/4096\n",
            "3822/4096\n",
            "3823/4096\n",
            "3824/4096\n",
            "3825/4096\n",
            "3826/4096\n",
            "3827/4096\n",
            "3828/4096\n",
            "3829/4096\n",
            "3830/4096\n",
            "3831/4096\n",
            "3832/4096\n",
            "3833/4096\n",
            "3834/4096\n",
            "3835/4096\n",
            "3836/4096\n",
            "3837/4096\n",
            "3838/4096\n",
            "3839/4096\n",
            "3840/4096\n",
            "3841/4096\n",
            "3842/4096\n",
            "3843/4096\n",
            "3844/4096\n",
            "3845/4096\n",
            "3846/4096\n",
            "3847/4096\n",
            "3848/4096\n",
            "3849/4096\n",
            "3850/4096\n",
            "3851/4096\n",
            "3852/4096\n",
            "3853/4096\n",
            "3854/4096\n",
            "3855/4096\n",
            "3856/4096\n",
            "3857/4096\n",
            "3858/4096\n",
            "3859/4096\n",
            "3860/4096\n",
            "3861/4096\n",
            "3862/4096\n",
            "3863/4096\n",
            "3864/4096\n",
            "3865/4096\n",
            "3866/4096\n",
            "3867/4096\n",
            "3868/4096\n",
            "3869/4096\n",
            "3870/4096\n",
            "3871/4096\n",
            "3872/4096\n",
            "3873/4096\n",
            "3874/4096\n",
            "3875/4096\n",
            "3876/4096\n",
            "3877/4096\n",
            "3878/4096\n",
            "3879/4096\n",
            "3880/4096\n",
            "3881/4096\n",
            "3882/4096\n",
            "3883/4096\n",
            "3884/4096\n",
            "3885/4096\n",
            "3886/4096\n",
            "3887/4096\n",
            "3888/4096\n",
            "3889/4096\n",
            "3890/4096\n",
            "3891/4096\n",
            "3892/4096\n",
            "3893/4096\n",
            "3894/4096\n",
            "3895/4096\n",
            "3896/4096\n",
            "3897/4096\n",
            "3898/4096\n",
            "3899/4096\n",
            "3900/4096\n",
            "3901/4096\n",
            "3902/4096\n",
            "3903/4096\n",
            "3904/4096\n",
            "3905/4096\n",
            "3906/4096\n",
            "3907/4096\n",
            "3908/4096\n",
            "3909/4096\n",
            "3910/4096\n",
            "3911/4096\n",
            "3912/4096\n",
            "3913/4096\n",
            "3914/4096\n",
            "3915/4096\n",
            "3916/4096\n",
            "3917/4096\n",
            "3918/4096\n",
            "3919/4096\n",
            "3920/4096\n",
            "3921/4096\n",
            "3922/4096\n",
            "3923/4096\n",
            "3924/4096\n",
            "3925/4096\n",
            "3926/4096\n",
            "3927/4096\n",
            "3928/4096\n",
            "3929/4096\n",
            "3930/4096\n",
            "3931/4096\n",
            "3932/4096\n",
            "3933/4096\n",
            "3934/4096\n",
            "3935/4096\n",
            "3936/4096\n",
            "3937/4096\n",
            "3938/4096\n",
            "3939/4096\n",
            "3940/4096\n",
            "3941/4096\n",
            "3942/4096\n",
            "3943/4096\n",
            "3944/4096\n",
            "3945/4096\n",
            "3946/4096\n",
            "3947/4096\n",
            "3948/4096\n",
            "3949/4096\n",
            "3950/4096\n",
            "3951/4096\n",
            "3952/4096\n",
            "3953/4096\n",
            "3954/4096\n",
            "3955/4096\n",
            "3956/4096\n",
            "3957/4096\n",
            "3958/4096\n",
            "3959/4096\n",
            "3960/4096\n",
            "3961/4096\n",
            "3962/4096\n",
            "3963/4096\n",
            "3964/4096\n",
            "3965/4096\n",
            "3966/4096\n",
            "3967/4096\n",
            "3968/4096\n",
            "3969/4096\n",
            "3970/4096\n",
            "3971/4096\n",
            "3972/4096\n",
            "3973/4096\n",
            "3974/4096\n",
            "3975/4096\n",
            "3976/4096\n",
            "3977/4096\n",
            "3978/4096\n",
            "3979/4096\n",
            "3980/4096\n",
            "3981/4096\n",
            "3982/4096\n",
            "3983/4096\n",
            "3984/4096\n",
            "3985/4096\n",
            "3986/4096\n",
            "3987/4096\n",
            "3988/4096\n",
            "3989/4096\n",
            "3990/4096\n",
            "3991/4096\n",
            "3992/4096\n",
            "3993/4096\n",
            "3994/4096\n",
            "3995/4096\n",
            "3996/4096\n",
            "3997/4096\n",
            "3998/4096\n",
            "3999/4096\n",
            "4000/4096\n",
            "4001/4096\n",
            "4002/4096\n",
            "4003/4096\n",
            "4004/4096\n",
            "4005/4096\n",
            "4006/4096\n",
            "4007/4096\n",
            "4008/4096\n",
            "4009/4096\n",
            "4010/4096\n",
            "4011/4096\n",
            "4012/4096\n",
            "4013/4096\n",
            "4014/4096\n",
            "4015/4096\n",
            "4016/4096\n",
            "4017/4096\n",
            "4018/4096\n",
            "4019/4096\n",
            "4020/4096\n",
            "4021/4096\n",
            "4022/4096\n",
            "4023/4096\n",
            "4024/4096\n",
            "4025/4096\n",
            "4026/4096\n",
            "4027/4096\n",
            "4028/4096\n",
            "4029/4096\n",
            "4030/4096\n",
            "4031/4096\n",
            "4032/4096\n",
            "4033/4096\n",
            "4034/4096\n",
            "4035/4096\n",
            "4036/4096\n",
            "4037/4096\n",
            "4038/4096\n",
            "4039/4096\n",
            "4040/4096\n",
            "4041/4096\n",
            "4042/4096\n",
            "4043/4096\n",
            "4044/4096\n",
            "4045/4096\n",
            "4046/4096\n",
            "4047/4096\n",
            "4048/4096\n",
            "4049/4096\n",
            "4050/4096\n",
            "4051/4096\n",
            "4052/4096\n",
            "4053/4096\n",
            "4054/4096\n",
            "4055/4096\n",
            "4056/4096\n",
            "4057/4096\n",
            "4058/4096\n",
            "4059/4096\n",
            "4060/4096\n",
            "4061/4096\n",
            "4062/4096\n",
            "4063/4096\n",
            "4064/4096\n",
            "4065/4096\n",
            "4066/4096\n",
            "4067/4096\n",
            "4068/4096\n",
            "4069/4096\n",
            "4070/4096\n",
            "4071/4096\n",
            "4072/4096\n",
            "4073/4096\n",
            "4074/4096\n",
            "4075/4096\n",
            "4076/4096\n",
            "4077/4096\n",
            "4078/4096\n",
            "4079/4096\n",
            "4080/4096\n",
            "4081/4096\n",
            "4082/4096\n",
            "4083/4096\n",
            "4084/4096\n",
            "4085/4096\n",
            "4086/4096\n",
            "4087/4096\n",
            "4088/4096\n",
            "4089/4096\n",
            "4090/4096\n",
            "4091/4096\n",
            "4092/4096\n",
            "4093/4096\n",
            "4094/4096\n",
            "4095/4096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9tNo4kSoBUD",
        "outputId": "03e244ac-a9bc-495d-9a38-99184e410799"
      },
      "source": [
        "seqs = []\r\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\r\n",
        "  input_seq_n = input_example_batch.numpy()\r\n",
        "  for i, input_seq in enumerate(input_seq_n): # 1 sample\r\n",
        "    print(f'\\n\\nsample {i}:')\r\n",
        "    out_seq = gen_long_inf(model, input_seq)\r\n",
        "    seqs.append(out_seq)\r\n",
        "    if i>=1:\r\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2673/4096\n",
            "2674/4096\n",
            "2675/4096\n",
            "2676/4096\n",
            "2677/4096\n",
            "2678/4096\n",
            "2679/4096\n",
            "2680/4096\n",
            "2681/4096\n",
            "2682/4096\n",
            "2683/4096\n",
            "2684/4096\n",
            "2685/4096\n",
            "2686/4096\n",
            "2687/4096\n",
            "2688/4096\n",
            "2689/4096\n",
            "2690/4096\n",
            "2691/4096\n",
            "2692/4096\n",
            "2693/4096\n",
            "2694/4096\n",
            "2695/4096\n",
            "2696/4096\n",
            "2697/4096\n",
            "2698/4096\n",
            "2699/4096\n",
            "2700/4096\n",
            "2701/4096\n",
            "2702/4096\n",
            "2703/4096\n",
            "2704/4096\n",
            "2705/4096\n",
            "2706/4096\n",
            "2707/4096\n",
            "2708/4096\n",
            "2709/4096\n",
            "2710/4096\n",
            "2711/4096\n",
            "2712/4096\n",
            "2713/4096\n",
            "2714/4096\n",
            "2715/4096\n",
            "2716/4096\n",
            "2717/4096\n",
            "2718/4096\n",
            "2719/4096\n",
            "2720/4096\n",
            "2721/4096\n",
            "2722/4096\n",
            "2723/4096\n",
            "2724/4096\n",
            "2725/4096\n",
            "2726/4096\n",
            "2727/4096\n",
            "2728/4096\n",
            "2729/4096\n",
            "2730/4096\n",
            "2731/4096\n",
            "2732/4096\n",
            "2733/4096\n",
            "2734/4096\n",
            "2735/4096\n",
            "2736/4096\n",
            "2737/4096\n",
            "2738/4096\n",
            "2739/4096\n",
            "2740/4096\n",
            "2741/4096\n",
            "2742/4096\n",
            "2743/4096\n",
            "2744/4096\n",
            "2745/4096\n",
            "2746/4096\n",
            "2747/4096\n",
            "2748/4096\n",
            "2749/4096\n",
            "2750/4096\n",
            "2751/4096\n",
            "2752/4096\n",
            "2753/4096\n",
            "2754/4096\n",
            "2755/4096\n",
            "2756/4096\n",
            "2757/4096\n",
            "2758/4096\n",
            "2759/4096\n",
            "2760/4096\n",
            "2761/4096\n",
            "2762/4096\n",
            "2763/4096\n",
            "2764/4096\n",
            "2765/4096\n",
            "2766/4096\n",
            "2767/4096\n",
            "2768/4096\n",
            "2769/4096\n",
            "2770/4096\n",
            "2771/4096\n",
            "2772/4096\n",
            "2773/4096\n",
            "2774/4096\n",
            "2775/4096\n",
            "2776/4096\n",
            "2777/4096\n",
            "2778/4096\n",
            "2779/4096\n",
            "2780/4096\n",
            "2781/4096\n",
            "2782/4096\n",
            "2783/4096\n",
            "2784/4096\n",
            "2785/4096\n",
            "2786/4096\n",
            "2787/4096\n",
            "2788/4096\n",
            "2789/4096\n",
            "2790/4096\n",
            "2791/4096\n",
            "2792/4096\n",
            "2793/4096\n",
            "2794/4096\n",
            "2795/4096\n",
            "2796/4096\n",
            "2797/4096\n",
            "2798/4096\n",
            "2799/4096\n",
            "2800/4096\n",
            "2801/4096\n",
            "2802/4096\n",
            "2803/4096\n",
            "2804/4096\n",
            "2805/4096\n",
            "2806/4096\n",
            "2807/4096\n",
            "2808/4096\n",
            "2809/4096\n",
            "2810/4096\n",
            "2811/4096\n",
            "2812/4096\n",
            "2813/4096\n",
            "2814/4096\n",
            "2815/4096\n",
            "2816/4096\n",
            "2817/4096\n",
            "2818/4096\n",
            "2819/4096\n",
            "2820/4096\n",
            "2821/4096\n",
            "2822/4096\n",
            "2823/4096\n",
            "2824/4096\n",
            "2825/4096\n",
            "2826/4096\n",
            "2827/4096\n",
            "2828/4096\n",
            "2829/4096\n",
            "2830/4096\n",
            "2831/4096\n",
            "2832/4096\n",
            "2833/4096\n",
            "2834/4096\n",
            "2835/4096\n",
            "2836/4096\n",
            "2837/4096\n",
            "2838/4096\n",
            "2839/4096\n",
            "2840/4096\n",
            "2841/4096\n",
            "2842/4096\n",
            "2843/4096\n",
            "2844/4096\n",
            "2845/4096\n",
            "2846/4096\n",
            "2847/4096\n",
            "2848/4096\n",
            "2849/4096\n",
            "2850/4096\n",
            "2851/4096\n",
            "2852/4096\n",
            "2853/4096\n",
            "2854/4096\n",
            "2855/4096\n",
            "2856/4096\n",
            "2857/4096\n",
            "2858/4096\n",
            "2859/4096\n",
            "2860/4096\n",
            "2861/4096\n",
            "2862/4096\n",
            "2863/4096\n",
            "2864/4096\n",
            "2865/4096\n",
            "2866/4096\n",
            "2867/4096\n",
            "2868/4096\n",
            "2869/4096\n",
            "2870/4096\n",
            "2871/4096\n",
            "2872/4096\n",
            "2873/4096\n",
            "2874/4096\n",
            "2875/4096\n",
            "2876/4096\n",
            "2877/4096\n",
            "2878/4096\n",
            "2879/4096\n",
            "2880/4096\n",
            "2881/4096\n",
            "2882/4096\n",
            "2883/4096\n",
            "2884/4096\n",
            "2885/4096\n",
            "2886/4096\n",
            "2887/4096\n",
            "2888/4096\n",
            "2889/4096\n",
            "2890/4096\n",
            "2891/4096\n",
            "2892/4096\n",
            "2893/4096\n",
            "2894/4096\n",
            "2895/4096\n",
            "2896/4096\n",
            "2897/4096\n",
            "2898/4096\n",
            "2899/4096\n",
            "2900/4096\n",
            "2901/4096\n",
            "2902/4096\n",
            "2903/4096\n",
            "2904/4096\n",
            "2905/4096\n",
            "2906/4096\n",
            "2907/4096\n",
            "2908/4096\n",
            "2909/4096\n",
            "2910/4096\n",
            "2911/4096\n",
            "2912/4096\n",
            "2913/4096\n",
            "2914/4096\n",
            "2915/4096\n",
            "2916/4096\n",
            "2917/4096\n",
            "2918/4096\n",
            "2919/4096\n",
            "2920/4096\n",
            "2921/4096\n",
            "2922/4096\n",
            "2923/4096\n",
            "2924/4096\n",
            "2925/4096\n",
            "2926/4096\n",
            "2927/4096\n",
            "2928/4096\n",
            "2929/4096\n",
            "2930/4096\n",
            "2931/4096\n",
            "2932/4096\n",
            "2933/4096\n",
            "2934/4096\n",
            "2935/4096\n",
            "2936/4096\n",
            "2937/4096\n",
            "2938/4096\n",
            "2939/4096\n",
            "2940/4096\n",
            "2941/4096\n",
            "2942/4096\n",
            "2943/4096\n",
            "2944/4096\n",
            "2945/4096\n",
            "2946/4096\n",
            "2947/4096\n",
            "2948/4096\n",
            "2949/4096\n",
            "2950/4096\n",
            "2951/4096\n",
            "2952/4096\n",
            "2953/4096\n",
            "2954/4096\n",
            "2955/4096\n",
            "2956/4096\n",
            "2957/4096\n",
            "2958/4096\n",
            "2959/4096\n",
            "2960/4096\n",
            "2961/4096\n",
            "2962/4096\n",
            "2963/4096\n",
            "2964/4096\n",
            "2965/4096\n",
            "2966/4096\n",
            "2967/4096\n",
            "2968/4096\n",
            "2969/4096\n",
            "2970/4096\n",
            "2971/4096\n",
            "2972/4096\n",
            "2973/4096\n",
            "2974/4096\n",
            "2975/4096\n",
            "2976/4096\n",
            "2977/4096\n",
            "2978/4096\n",
            "2979/4096\n",
            "2980/4096\n",
            "2981/4096\n",
            "2982/4096\n",
            "2983/4096\n",
            "2984/4096\n",
            "2985/4096\n",
            "2986/4096\n",
            "2987/4096\n",
            "2988/4096\n",
            "2989/4096\n",
            "2990/4096\n",
            "2991/4096\n",
            "2992/4096\n",
            "2993/4096\n",
            "2994/4096\n",
            "2995/4096\n",
            "2996/4096\n",
            "2997/4096\n",
            "2998/4096\n",
            "2999/4096\n",
            "3000/4096\n",
            "3001/4096\n",
            "3002/4096\n",
            "3003/4096\n",
            "3004/4096\n",
            "3005/4096\n",
            "3006/4096\n",
            "3007/4096\n",
            "3008/4096\n",
            "3009/4096\n",
            "3010/4096\n",
            "3011/4096\n",
            "3012/4096\n",
            "3013/4096\n",
            "3014/4096\n",
            "3015/4096\n",
            "3016/4096\n",
            "3017/4096\n",
            "3018/4096\n",
            "3019/4096\n",
            "3020/4096\n",
            "3021/4096\n",
            "3022/4096\n",
            "3023/4096\n",
            "3024/4096\n",
            "3025/4096\n",
            "3026/4096\n",
            "3027/4096\n",
            "3028/4096\n",
            "3029/4096\n",
            "3030/4096\n",
            "3031/4096\n",
            "3032/4096\n",
            "3033/4096\n",
            "3034/4096\n",
            "3035/4096\n",
            "3036/4096\n",
            "3037/4096\n",
            "3038/4096\n",
            "3039/4096\n",
            "3040/4096\n",
            "3041/4096\n",
            "3042/4096\n",
            "3043/4096\n",
            "3044/4096\n",
            "3045/4096\n",
            "3046/4096\n",
            "3047/4096\n",
            "3048/4096\n",
            "3049/4096\n",
            "3050/4096\n",
            "3051/4096\n",
            "3052/4096\n",
            "3053/4096\n",
            "3054/4096\n",
            "3055/4096\n",
            "3056/4096\n",
            "3057/4096\n",
            "3058/4096\n",
            "3059/4096\n",
            "3060/4096\n",
            "3061/4096\n",
            "3062/4096\n",
            "3063/4096\n",
            "3064/4096\n",
            "3065/4096\n",
            "3066/4096\n",
            "3067/4096\n",
            "3068/4096\n",
            "3069/4096\n",
            "3070/4096\n",
            "3071/4096\n",
            "3072/4096\n",
            "3073/4096\n",
            "3074/4096\n",
            "3075/4096\n",
            "3076/4096\n",
            "3077/4096\n",
            "3078/4096\n",
            "3079/4096\n",
            "3080/4096\n",
            "3081/4096\n",
            "3082/4096\n",
            "3083/4096\n",
            "3084/4096\n",
            "3085/4096\n",
            "3086/4096\n",
            "3087/4096\n",
            "3088/4096\n",
            "3089/4096\n",
            "3090/4096\n",
            "3091/4096\n",
            "3092/4096\n",
            "3093/4096\n",
            "3094/4096\n",
            "3095/4096\n",
            "3096/4096\n",
            "3097/4096\n",
            "3098/4096\n",
            "3099/4096\n",
            "3100/4096\n",
            "3101/4096\n",
            "3102/4096\n",
            "3103/4096\n",
            "3104/4096\n",
            "3105/4096\n",
            "3106/4096\n",
            "3107/4096\n",
            "3108/4096\n",
            "3109/4096\n",
            "3110/4096\n",
            "3111/4096\n",
            "3112/4096\n",
            "3113/4096\n",
            "3114/4096\n",
            "3115/4096\n",
            "3116/4096\n",
            "3117/4096\n",
            "3118/4096\n",
            "3119/4096\n",
            "3120/4096\n",
            "3121/4096\n",
            "3122/4096\n",
            "3123/4096\n",
            "3124/4096\n",
            "3125/4096\n",
            "3126/4096\n",
            "3127/4096\n",
            "3128/4096\n",
            "3129/4096\n",
            "3130/4096\n",
            "3131/4096\n",
            "3132/4096\n",
            "3133/4096\n",
            "3134/4096\n",
            "3135/4096\n",
            "3136/4096\n",
            "3137/4096\n",
            "3138/4096\n",
            "3139/4096\n",
            "3140/4096\n",
            "3141/4096\n",
            "3142/4096\n",
            "3143/4096\n",
            "3144/4096\n",
            "3145/4096\n",
            "3146/4096\n",
            "3147/4096\n",
            "3148/4096\n",
            "3149/4096\n",
            "3150/4096\n",
            "3151/4096\n",
            "3152/4096\n",
            "3153/4096\n",
            "3154/4096\n",
            "3155/4096\n",
            "3156/4096\n",
            "3157/4096\n",
            "3158/4096\n",
            "3159/4096\n",
            "3160/4096\n",
            "3161/4096\n",
            "3162/4096\n",
            "3163/4096\n",
            "3164/4096\n",
            "3165/4096\n",
            "3166/4096\n",
            "3167/4096\n",
            "3168/4096\n",
            "3169/4096\n",
            "3170/4096\n",
            "3171/4096\n",
            "3172/4096\n",
            "3173/4096\n",
            "3174/4096\n",
            "3175/4096\n",
            "3176/4096\n",
            "3177/4096\n",
            "3178/4096\n",
            "3179/4096\n",
            "3180/4096\n",
            "3181/4096\n",
            "3182/4096\n",
            "3183/4096\n",
            "3184/4096\n",
            "3185/4096\n",
            "3186/4096\n",
            "3187/4096\n",
            "3188/4096\n",
            "3189/4096\n",
            "3190/4096\n",
            "3191/4096\n",
            "3192/4096\n",
            "3193/4096\n",
            "3194/4096\n",
            "3195/4096\n",
            "3196/4096\n",
            "3197/4096\n",
            "3198/4096\n",
            "3199/4096\n",
            "3200/4096\n",
            "3201/4096\n",
            "3202/4096\n",
            "3203/4096\n",
            "3204/4096\n",
            "3205/4096\n",
            "3206/4096\n",
            "3207/4096\n",
            "3208/4096\n",
            "3209/4096\n",
            "3210/4096\n",
            "3211/4096\n",
            "3212/4096\n",
            "3213/4096\n",
            "3214/4096\n",
            "3215/4096\n",
            "3216/4096\n",
            "3217/4096\n",
            "3218/4096\n",
            "3219/4096\n",
            "3220/4096\n",
            "3221/4096\n",
            "3222/4096\n",
            "3223/4096\n",
            "3224/4096\n",
            "3225/4096\n",
            "3226/4096\n",
            "3227/4096\n",
            "3228/4096\n",
            "3229/4096\n",
            "3230/4096\n",
            "3231/4096\n",
            "3232/4096\n",
            "3233/4096\n",
            "3234/4096\n",
            "3235/4096\n",
            "3236/4096\n",
            "3237/4096\n",
            "3238/4096\n",
            "3239/4096\n",
            "3240/4096\n",
            "3241/4096\n",
            "3242/4096\n",
            "3243/4096\n",
            "3244/4096\n",
            "3245/4096\n",
            "3246/4096\n",
            "3247/4096\n",
            "3248/4096\n",
            "3249/4096\n",
            "3250/4096\n",
            "3251/4096\n",
            "3252/4096\n",
            "3253/4096\n",
            "3254/4096\n",
            "3255/4096\n",
            "3256/4096\n",
            "3257/4096\n",
            "3258/4096\n",
            "3259/4096\n",
            "3260/4096\n",
            "3261/4096\n",
            "3262/4096\n",
            "3263/4096\n",
            "3264/4096\n",
            "3265/4096\n",
            "3266/4096\n",
            "3267/4096\n",
            "3268/4096\n",
            "3269/4096\n",
            "3270/4096\n",
            "3271/4096\n",
            "3272/4096\n",
            "3273/4096\n",
            "3274/4096\n",
            "3275/4096\n",
            "3276/4096\n",
            "3277/4096\n",
            "3278/4096\n",
            "3279/4096\n",
            "3280/4096\n",
            "3281/4096\n",
            "3282/4096\n",
            "3283/4096\n",
            "3284/4096\n",
            "3285/4096\n",
            "3286/4096\n",
            "3287/4096\n",
            "3288/4096\n",
            "3289/4096\n",
            "3290/4096\n",
            "3291/4096\n",
            "3292/4096\n",
            "3293/4096\n",
            "3294/4096\n",
            "3295/4096\n",
            "3296/4096\n",
            "3297/4096\n",
            "3298/4096\n",
            "3299/4096\n",
            "3300/4096\n",
            "3301/4096\n",
            "3302/4096\n",
            "3303/4096\n",
            "3304/4096\n",
            "3305/4096\n",
            "3306/4096\n",
            "3307/4096\n",
            "3308/4096\n",
            "3309/4096\n",
            "3310/4096\n",
            "3311/4096\n",
            "3312/4096\n",
            "3313/4096\n",
            "3314/4096\n",
            "3315/4096\n",
            "3316/4096\n",
            "3317/4096\n",
            "3318/4096\n",
            "3319/4096\n",
            "3320/4096\n",
            "3321/4096\n",
            "3322/4096\n",
            "3323/4096\n",
            "3324/4096\n",
            "3325/4096\n",
            "3326/4096\n",
            "3327/4096\n",
            "3328/4096\n",
            "3329/4096\n",
            "3330/4096\n",
            "3331/4096\n",
            "3332/4096\n",
            "3333/4096\n",
            "3334/4096\n",
            "3335/4096\n",
            "3336/4096\n",
            "3337/4096\n",
            "3338/4096\n",
            "3339/4096\n",
            "3340/4096\n",
            "3341/4096\n",
            "3342/4096\n",
            "3343/4096\n",
            "3344/4096\n",
            "3345/4096\n",
            "3346/4096\n",
            "3347/4096\n",
            "3348/4096\n",
            "3349/4096\n",
            "3350/4096\n",
            "3351/4096\n",
            "3352/4096\n",
            "3353/4096\n",
            "3354/4096\n",
            "3355/4096\n",
            "3356/4096\n",
            "3357/4096\n",
            "3358/4096\n",
            "3359/4096\n",
            "3360/4096\n",
            "3361/4096\n",
            "3362/4096\n",
            "3363/4096\n",
            "3364/4096\n",
            "3365/4096\n",
            "3366/4096\n",
            "3367/4096\n",
            "3368/4096\n",
            "3369/4096\n",
            "3370/4096\n",
            "3371/4096\n",
            "3372/4096\n",
            "3373/4096\n",
            "3374/4096\n",
            "3375/4096\n",
            "3376/4096\n",
            "3377/4096\n",
            "3378/4096\n",
            "3379/4096\n",
            "3380/4096\n",
            "3381/4096\n",
            "3382/4096\n",
            "3383/4096\n",
            "3384/4096\n",
            "3385/4096\n",
            "3386/4096\n",
            "3387/4096\n",
            "3388/4096\n",
            "3389/4096\n",
            "3390/4096\n",
            "3391/4096\n",
            "3392/4096\n",
            "3393/4096\n",
            "3394/4096\n",
            "3395/4096\n",
            "3396/4096\n",
            "3397/4096\n",
            "3398/4096\n",
            "3399/4096\n",
            "3400/4096\n",
            "3401/4096\n",
            "3402/4096\n",
            "3403/4096\n",
            "3404/4096\n",
            "3405/4096\n",
            "3406/4096\n",
            "3407/4096\n",
            "3408/4096\n",
            "3409/4096\n",
            "3410/4096\n",
            "3411/4096\n",
            "3412/4096\n",
            "3413/4096\n",
            "3414/4096\n",
            "3415/4096\n",
            "3416/4096\n",
            "3417/4096\n",
            "3418/4096\n",
            "3419/4096\n",
            "3420/4096\n",
            "3421/4096\n",
            "3422/4096\n",
            "3423/4096\n",
            "3424/4096\n",
            "3425/4096\n",
            "3426/4096\n",
            "3427/4096\n",
            "3428/4096\n",
            "3429/4096\n",
            "3430/4096\n",
            "3431/4096\n",
            "3432/4096\n",
            "3433/4096\n",
            "3434/4096\n",
            "3435/4096\n",
            "3436/4096\n",
            "3437/4096\n",
            "3438/4096\n",
            "3439/4096\n",
            "3440/4096\n",
            "3441/4096\n",
            "3442/4096\n",
            "3443/4096\n",
            "3444/4096\n",
            "3445/4096\n",
            "3446/4096\n",
            "3447/4096\n",
            "3448/4096\n",
            "3449/4096\n",
            "3450/4096\n",
            "3451/4096\n",
            "3452/4096\n",
            "3453/4096\n",
            "3454/4096\n",
            "3455/4096\n",
            "3456/4096\n",
            "3457/4096\n",
            "3458/4096\n",
            "3459/4096\n",
            "3460/4096\n",
            "3461/4096\n",
            "3462/4096\n",
            "3463/4096\n",
            "3464/4096\n",
            "3465/4096\n",
            "3466/4096\n",
            "3467/4096\n",
            "3468/4096\n",
            "3469/4096\n",
            "3470/4096\n",
            "3471/4096\n",
            "3472/4096\n",
            "3473/4096\n",
            "3474/4096\n",
            "3475/4096\n",
            "3476/4096\n",
            "3477/4096\n",
            "3478/4096\n",
            "3479/4096\n",
            "3480/4096\n",
            "3481/4096\n",
            "3482/4096\n",
            "3483/4096\n",
            "3484/4096\n",
            "3485/4096\n",
            "3486/4096\n",
            "3487/4096\n",
            "3488/4096\n",
            "3489/4096\n",
            "3490/4096\n",
            "3491/4096\n",
            "3492/4096\n",
            "3493/4096\n",
            "3494/4096\n",
            "3495/4096\n",
            "3496/4096\n",
            "3497/4096\n",
            "3498/4096\n",
            "3499/4096\n",
            "3500/4096\n",
            "3501/4096\n",
            "3502/4096\n",
            "3503/4096\n",
            "3504/4096\n",
            "3505/4096\n",
            "3506/4096\n",
            "3507/4096\n",
            "3508/4096\n",
            "3509/4096\n",
            "3510/4096\n",
            "3511/4096\n",
            "3512/4096\n",
            "3513/4096\n",
            "3514/4096\n",
            "3515/4096\n",
            "3516/4096\n",
            "3517/4096\n",
            "3518/4096\n",
            "3519/4096\n",
            "3520/4096\n",
            "3521/4096\n",
            "3522/4096\n",
            "3523/4096\n",
            "3524/4096\n",
            "3525/4096\n",
            "3526/4096\n",
            "3527/4096\n",
            "3528/4096\n",
            "3529/4096\n",
            "3530/4096\n",
            "3531/4096\n",
            "3532/4096\n",
            "3533/4096\n",
            "3534/4096\n",
            "3535/4096\n",
            "3536/4096\n",
            "3537/4096\n",
            "3538/4096\n",
            "3539/4096\n",
            "3540/4096\n",
            "3541/4096\n",
            "3542/4096\n",
            "3543/4096\n",
            "3544/4096\n",
            "3545/4096\n",
            "3546/4096\n",
            "3547/4096\n",
            "3548/4096\n",
            "3549/4096\n",
            "3550/4096\n",
            "3551/4096\n",
            "3552/4096\n",
            "3553/4096\n",
            "3554/4096\n",
            "3555/4096\n",
            "3556/4096\n",
            "3557/4096\n",
            "3558/4096\n",
            "3559/4096\n",
            "3560/4096\n",
            "3561/4096\n",
            "3562/4096\n",
            "3563/4096\n",
            "3564/4096\n",
            "3565/4096\n",
            "3566/4096\n",
            "3567/4096\n",
            "3568/4096\n",
            "3569/4096\n",
            "3570/4096\n",
            "3571/4096\n",
            "3572/4096\n",
            "3573/4096\n",
            "3574/4096\n",
            "3575/4096\n",
            "3576/4096\n",
            "3577/4096\n",
            "3578/4096\n",
            "3579/4096\n",
            "3580/4096\n",
            "3581/4096\n",
            "3582/4096\n",
            "3583/4096\n",
            "3584/4096\n",
            "3585/4096\n",
            "3586/4096\n",
            "3587/4096\n",
            "3588/4096\n",
            "3589/4096\n",
            "3590/4096\n",
            "3591/4096\n",
            "3592/4096\n",
            "3593/4096\n",
            "3594/4096\n",
            "3595/4096\n",
            "3596/4096\n",
            "3597/4096\n",
            "3598/4096\n",
            "3599/4096\n",
            "3600/4096\n",
            "3601/4096\n",
            "3602/4096\n",
            "3603/4096\n",
            "3604/4096\n",
            "3605/4096\n",
            "3606/4096\n",
            "3607/4096\n",
            "3608/4096\n",
            "3609/4096\n",
            "3610/4096\n",
            "3611/4096\n",
            "3612/4096\n",
            "3613/4096\n",
            "3614/4096\n",
            "3615/4096\n",
            "3616/4096\n",
            "3617/4096\n",
            "3618/4096\n",
            "3619/4096\n",
            "3620/4096\n",
            "3621/4096\n",
            "3622/4096\n",
            "3623/4096\n",
            "3624/4096\n",
            "3625/4096\n",
            "3626/4096\n",
            "3627/4096\n",
            "3628/4096\n",
            "3629/4096\n",
            "3630/4096\n",
            "3631/4096\n",
            "3632/4096\n",
            "3633/4096\n",
            "3634/4096\n",
            "3635/4096\n",
            "3636/4096\n",
            "3637/4096\n",
            "3638/4096\n",
            "3639/4096\n",
            "3640/4096\n",
            "3641/4096\n",
            "3642/4096\n",
            "3643/4096\n",
            "3644/4096\n",
            "3645/4096\n",
            "3646/4096\n",
            "3647/4096\n",
            "3648/4096\n",
            "3649/4096\n",
            "3650/4096\n",
            "3651/4096\n",
            "3652/4096\n",
            "3653/4096\n",
            "3654/4096\n",
            "3655/4096\n",
            "3656/4096\n",
            "3657/4096\n",
            "3658/4096\n",
            "3659/4096\n",
            "3660/4096\n",
            "3661/4096\n",
            "3662/4096\n",
            "3663/4096\n",
            "3664/4096\n",
            "3665/4096\n",
            "3666/4096\n",
            "3667/4096\n",
            "3668/4096\n",
            "3669/4096\n",
            "3670/4096\n",
            "3671/4096\n",
            "3672/4096\n",
            "3673/4096\n",
            "3674/4096\n",
            "3675/4096\n",
            "3676/4096\n",
            "3677/4096\n",
            "3678/4096\n",
            "3679/4096\n",
            "3680/4096\n",
            "3681/4096\n",
            "3682/4096\n",
            "3683/4096\n",
            "3684/4096\n",
            "3685/4096\n",
            "3686/4096\n",
            "3687/4096\n",
            "3688/4096\n",
            "3689/4096\n",
            "3690/4096\n",
            "3691/4096\n",
            "3692/4096\n",
            "3693/4096\n",
            "3694/4096\n",
            "3695/4096\n",
            "3696/4096\n",
            "3697/4096\n",
            "3698/4096\n",
            "3699/4096\n",
            "3700/4096\n",
            "3701/4096\n",
            "3702/4096\n",
            "3703/4096\n",
            "3704/4096\n",
            "3705/4096\n",
            "3706/4096\n",
            "3707/4096\n",
            "3708/4096\n",
            "3709/4096\n",
            "3710/4096\n",
            "3711/4096\n",
            "3712/4096\n",
            "3713/4096\n",
            "3714/4096\n",
            "3715/4096\n",
            "3716/4096\n",
            "3717/4096\n",
            "3718/4096\n",
            "3719/4096\n",
            "3720/4096\n",
            "3721/4096\n",
            "3722/4096\n",
            "3723/4096\n",
            "3724/4096\n",
            "3725/4096\n",
            "3726/4096\n",
            "3727/4096\n",
            "3728/4096\n",
            "3729/4096\n",
            "3730/4096\n",
            "3731/4096\n",
            "3732/4096\n",
            "3733/4096\n",
            "3734/4096\n",
            "3735/4096\n",
            "3736/4096\n",
            "3737/4096\n",
            "3738/4096\n",
            "3739/4096\n",
            "3740/4096\n",
            "3741/4096\n",
            "3742/4096\n",
            "3743/4096\n",
            "3744/4096\n",
            "3745/4096\n",
            "3746/4096\n",
            "3747/4096\n",
            "3748/4096\n",
            "3749/4096\n",
            "3750/4096\n",
            "3751/4096\n",
            "3752/4096\n",
            "3753/4096\n",
            "3754/4096\n",
            "3755/4096\n",
            "3756/4096\n",
            "3757/4096\n",
            "3758/4096\n",
            "3759/4096\n",
            "3760/4096\n",
            "3761/4096\n",
            "3762/4096\n",
            "3763/4096\n",
            "3764/4096\n",
            "3765/4096\n",
            "3766/4096\n",
            "3767/4096\n",
            "3768/4096\n",
            "3769/4096\n",
            "3770/4096\n",
            "3771/4096\n",
            "3772/4096\n",
            "3773/4096\n",
            "3774/4096\n",
            "3775/4096\n",
            "3776/4096\n",
            "3777/4096\n",
            "3778/4096\n",
            "3779/4096\n",
            "3780/4096\n",
            "3781/4096\n",
            "3782/4096\n",
            "3783/4096\n",
            "3784/4096\n",
            "3785/4096\n",
            "3786/4096\n",
            "3787/4096\n",
            "3788/4096\n",
            "3789/4096\n",
            "3790/4096\n",
            "3791/4096\n",
            "3792/4096\n",
            "3793/4096\n",
            "3794/4096\n",
            "3795/4096\n",
            "3796/4096\n",
            "3797/4096\n",
            "3798/4096\n",
            "3799/4096\n",
            "3800/4096\n",
            "3801/4096\n",
            "3802/4096\n",
            "3803/4096\n",
            "3804/4096\n",
            "3805/4096\n",
            "3806/4096\n",
            "3807/4096\n",
            "3808/4096\n",
            "3809/4096\n",
            "3810/4096\n",
            "3811/4096\n",
            "3812/4096\n",
            "3813/4096\n",
            "3814/4096\n",
            "3815/4096\n",
            "3816/4096\n",
            "3817/4096\n",
            "3818/4096\n",
            "3819/4096\n",
            "3820/4096\n",
            "3821/4096\n",
            "3822/4096\n",
            "3823/4096\n",
            "3824/4096\n",
            "3825/4096\n",
            "3826/4096\n",
            "3827/4096\n",
            "3828/4096\n",
            "3829/4096\n",
            "3830/4096\n",
            "3831/4096\n",
            "3832/4096\n",
            "3833/4096\n",
            "3834/4096\n",
            "3835/4096\n",
            "3836/4096\n",
            "3837/4096\n",
            "3838/4096\n",
            "3839/4096\n",
            "3840/4096\n",
            "3841/4096\n",
            "3842/4096\n",
            "3843/4096\n",
            "3844/4096\n",
            "3845/4096\n",
            "3846/4096\n",
            "3847/4096\n",
            "3848/4096\n",
            "3849/4096\n",
            "3850/4096\n",
            "3851/4096\n",
            "3852/4096\n",
            "3853/4096\n",
            "3854/4096\n",
            "3855/4096\n",
            "3856/4096\n",
            "3857/4096\n",
            "3858/4096\n",
            "3859/4096\n",
            "3860/4096\n",
            "3861/4096\n",
            "3862/4096\n",
            "3863/4096\n",
            "3864/4096\n",
            "3865/4096\n",
            "3866/4096\n",
            "3867/4096\n",
            "3868/4096\n",
            "3869/4096\n",
            "3870/4096\n",
            "3871/4096\n",
            "3872/4096\n",
            "3873/4096\n",
            "3874/4096\n",
            "3875/4096\n",
            "3876/4096\n",
            "3877/4096\n",
            "3878/4096\n",
            "3879/4096\n",
            "3880/4096\n",
            "3881/4096\n",
            "3882/4096\n",
            "3883/4096\n",
            "3884/4096\n",
            "3885/4096\n",
            "3886/4096\n",
            "3887/4096\n",
            "3888/4096\n",
            "3889/4096\n",
            "3890/4096\n",
            "3891/4096\n",
            "3892/4096\n",
            "3893/4096\n",
            "3894/4096\n",
            "3895/4096\n",
            "3896/4096\n",
            "3897/4096\n",
            "3898/4096\n",
            "3899/4096\n",
            "3900/4096\n",
            "3901/4096\n",
            "3902/4096\n",
            "3903/4096\n",
            "3904/4096\n",
            "3905/4096\n",
            "3906/4096\n",
            "3907/4096\n",
            "3908/4096\n",
            "3909/4096\n",
            "3910/4096\n",
            "3911/4096\n",
            "3912/4096\n",
            "3913/4096\n",
            "3914/4096\n",
            "3915/4096\n",
            "3916/4096\n",
            "3917/4096\n",
            "3918/4096\n",
            "3919/4096\n",
            "3920/4096\n",
            "3921/4096\n",
            "3922/4096\n",
            "3923/4096\n",
            "3924/4096\n",
            "3925/4096\n",
            "3926/4096\n",
            "3927/4096\n",
            "3928/4096\n",
            "3929/4096\n",
            "3930/4096\n",
            "3931/4096\n",
            "3932/4096\n",
            "3933/4096\n",
            "3934/4096\n",
            "3935/4096\n",
            "3936/4096\n",
            "3937/4096\n",
            "3938/4096\n",
            "3939/4096\n",
            "3940/4096\n",
            "3941/4096\n",
            "3942/4096\n",
            "3943/4096\n",
            "3944/4096\n",
            "3945/4096\n",
            "3946/4096\n",
            "3947/4096\n",
            "3948/4096\n",
            "3949/4096\n",
            "3950/4096\n",
            "3951/4096\n",
            "3952/4096\n",
            "3953/4096\n",
            "3954/4096\n",
            "3955/4096\n",
            "3956/4096\n",
            "3957/4096\n",
            "3958/4096\n",
            "3959/4096\n",
            "3960/4096\n",
            "3961/4096\n",
            "3962/4096\n",
            "3963/4096\n",
            "3964/4096\n",
            "3965/4096\n",
            "3966/4096\n",
            "3967/4096\n",
            "3968/4096\n",
            "3969/4096\n",
            "3970/4096\n",
            "3971/4096\n",
            "3972/4096\n",
            "3973/4096\n",
            "3974/4096\n",
            "3975/4096\n",
            "3976/4096\n",
            "3977/4096\n",
            "3978/4096\n",
            "3979/4096\n",
            "3980/4096\n",
            "3981/4096\n",
            "3982/4096\n",
            "3983/4096\n",
            "3984/4096\n",
            "3985/4096\n",
            "3986/4096\n",
            "3987/4096\n",
            "3988/4096\n",
            "3989/4096\n",
            "3990/4096\n",
            "3991/4096\n",
            "3992/4096\n",
            "3993/4096\n",
            "3994/4096\n",
            "3995/4096\n",
            "3996/4096\n",
            "3997/4096\n",
            "3998/4096\n",
            "3999/4096\n",
            "4000/4096\n",
            "4001/4096\n",
            "4002/4096\n",
            "4003/4096\n",
            "4004/4096\n",
            "4005/4096\n",
            "4006/4096\n",
            "4007/4096\n",
            "4008/4096\n",
            "4009/4096\n",
            "4010/4096\n",
            "4011/4096\n",
            "4012/4096\n",
            "4013/4096\n",
            "4014/4096\n",
            "4015/4096\n",
            "4016/4096\n",
            "4017/4096\n",
            "4018/4096\n",
            "4019/4096\n",
            "4020/4096\n",
            "4021/4096\n",
            "4022/4096\n",
            "4023/4096\n",
            "4024/4096\n",
            "4025/4096\n",
            "4026/4096\n",
            "4027/4096\n",
            "4028/4096\n",
            "4029/4096\n",
            "4030/4096\n",
            "4031/4096\n",
            "4032/4096\n",
            "4033/4096\n",
            "4034/4096\n",
            "4035/4096\n",
            "4036/4096\n",
            "4037/4096\n",
            "4038/4096\n",
            "4039/4096\n",
            "4040/4096\n",
            "4041/4096\n",
            "4042/4096\n",
            "4043/4096\n",
            "4044/4096\n",
            "4045/4096\n",
            "4046/4096\n",
            "4047/4096\n",
            "4048/4096\n",
            "4049/4096\n",
            "4050/4096\n",
            "4051/4096\n",
            "4052/4096\n",
            "4053/4096\n",
            "4054/4096\n",
            "4055/4096\n",
            "4056/4096\n",
            "4057/4096\n",
            "4058/4096\n",
            "4059/4096\n",
            "4060/4096\n",
            "4061/4096\n",
            "4062/4096\n",
            "4063/4096\n",
            "4064/4096\n",
            "4065/4096\n",
            "4066/4096\n",
            "4067/4096\n",
            "4068/4096\n",
            "4069/4096\n",
            "4070/4096\n",
            "4071/4096\n",
            "4072/4096\n",
            "4073/4096\n",
            "4074/4096\n",
            "4075/4096\n",
            "4076/4096\n",
            "4077/4096\n",
            "4078/4096\n",
            "4079/4096\n",
            "4080/4096\n",
            "4081/4096\n",
            "4082/4096\n",
            "4083/4096\n",
            "4084/4096\n",
            "4085/4096\n",
            "4086/4096\n",
            "4087/4096\n",
            "4088/4096\n",
            "4089/4096\n",
            "4090/4096\n",
            "4091/4096\n",
            "4092/4096\n",
            "4093/4096\n",
            "4094/4096\n",
            "4095/4096\n",
            "\n",
            "\n",
            "sample 1:\n",
            "0/4096\n",
            "1/4096\n",
            "2/4096\n",
            "3/4096\n",
            "4/4096\n",
            "5/4096\n",
            "6/4096\n",
            "7/4096\n",
            "8/4096\n",
            "9/4096\n",
            "10/4096\n",
            "11/4096\n",
            "12/4096\n",
            "13/4096\n",
            "14/4096\n",
            "15/4096\n",
            "16/4096\n",
            "17/4096\n",
            "18/4096\n",
            "19/4096\n",
            "20/4096\n",
            "21/4096\n",
            "22/4096\n",
            "23/4096\n",
            "24/4096\n",
            "25/4096\n",
            "26/4096\n",
            "27/4096\n",
            "28/4096\n",
            "29/4096\n",
            "30/4096\n",
            "31/4096\n",
            "32/4096\n",
            "33/4096\n",
            "34/4096\n",
            "35/4096\n",
            "36/4096\n",
            "37/4096\n",
            "38/4096\n",
            "39/4096\n",
            "40/4096\n",
            "41/4096\n",
            "42/4096\n",
            "43/4096\n",
            "44/4096\n",
            "45/4096\n",
            "46/4096\n",
            "47/4096\n",
            "48/4096\n",
            "49/4096\n",
            "50/4096\n",
            "51/4096\n",
            "52/4096\n",
            "53/4096\n",
            "54/4096\n",
            "55/4096\n",
            "56/4096\n",
            "57/4096\n",
            "58/4096\n",
            "59/4096\n",
            "60/4096\n",
            "61/4096\n",
            "62/4096\n",
            "63/4096\n",
            "64/4096\n",
            "65/4096\n",
            "66/4096\n",
            "67/4096\n",
            "68/4096\n",
            "69/4096\n",
            "70/4096\n",
            "71/4096\n",
            "72/4096\n",
            "73/4096\n",
            "74/4096\n",
            "75/4096\n",
            "76/4096\n",
            "77/4096\n",
            "78/4096\n",
            "79/4096\n",
            "80/4096\n",
            "81/4096\n",
            "82/4096\n",
            "83/4096\n",
            "84/4096\n",
            "85/4096\n",
            "86/4096\n",
            "87/4096\n",
            "88/4096\n",
            "89/4096\n",
            "90/4096\n",
            "91/4096\n",
            "92/4096\n",
            "93/4096\n",
            "94/4096\n",
            "95/4096\n",
            "96/4096\n",
            "97/4096\n",
            "98/4096\n",
            "99/4096\n",
            "100/4096\n",
            "101/4096\n",
            "102/4096\n",
            "103/4096\n",
            "104/4096\n",
            "105/4096\n",
            "106/4096\n",
            "107/4096\n",
            "108/4096\n",
            "109/4096\n",
            "110/4096\n",
            "111/4096\n",
            "112/4096\n",
            "113/4096\n",
            "114/4096\n",
            "115/4096\n",
            "116/4096\n",
            "117/4096\n",
            "118/4096\n",
            "119/4096\n",
            "120/4096\n",
            "121/4096\n",
            "122/4096\n",
            "123/4096\n",
            "124/4096\n",
            "125/4096\n",
            "126/4096\n",
            "127/4096\n",
            "128/4096\n",
            "129/4096\n",
            "130/4096\n",
            "131/4096\n",
            "132/4096\n",
            "133/4096\n",
            "134/4096\n",
            "135/4096\n",
            "136/4096\n",
            "137/4096\n",
            "138/4096\n",
            "139/4096\n",
            "140/4096\n",
            "141/4096\n",
            "142/4096\n",
            "143/4096\n",
            "144/4096\n",
            "145/4096\n",
            "146/4096\n",
            "147/4096\n",
            "148/4096\n",
            "149/4096\n",
            "150/4096\n",
            "151/4096\n",
            "152/4096\n",
            "153/4096\n",
            "154/4096\n",
            "155/4096\n",
            "156/4096\n",
            "157/4096\n",
            "158/4096\n",
            "159/4096\n",
            "160/4096\n",
            "161/4096\n",
            "162/4096\n",
            "163/4096\n",
            "164/4096\n",
            "165/4096\n",
            "166/4096\n",
            "167/4096\n",
            "168/4096\n",
            "169/4096\n",
            "170/4096\n",
            "171/4096\n",
            "172/4096\n",
            "173/4096\n",
            "174/4096\n",
            "175/4096\n",
            "176/4096\n",
            "177/4096\n",
            "178/4096\n",
            "179/4096\n",
            "180/4096\n",
            "181/4096\n",
            "182/4096\n",
            "183/4096\n",
            "184/4096\n",
            "185/4096\n",
            "186/4096\n",
            "187/4096\n",
            "188/4096\n",
            "189/4096\n",
            "190/4096\n",
            "191/4096\n",
            "192/4096\n",
            "193/4096\n",
            "194/4096\n",
            "195/4096\n",
            "196/4096\n",
            "197/4096\n",
            "198/4096\n",
            "199/4096\n",
            "200/4096\n",
            "201/4096\n",
            "202/4096\n",
            "203/4096\n",
            "204/4096\n",
            "205/4096\n",
            "206/4096\n",
            "207/4096\n",
            "208/4096\n",
            "209/4096\n",
            "210/4096\n",
            "211/4096\n",
            "212/4096\n",
            "213/4096\n",
            "214/4096\n",
            "215/4096\n",
            "216/4096\n",
            "217/4096\n",
            "218/4096\n",
            "219/4096\n",
            "220/4096\n",
            "221/4096\n",
            "222/4096\n",
            "223/4096\n",
            "224/4096\n",
            "225/4096\n",
            "226/4096\n",
            "227/4096\n",
            "228/4096\n",
            "229/4096\n",
            "230/4096\n",
            "231/4096\n",
            "232/4096\n",
            "233/4096\n",
            "234/4096\n",
            "235/4096\n",
            "236/4096\n",
            "237/4096\n",
            "238/4096\n",
            "239/4096\n",
            "240/4096\n",
            "241/4096\n",
            "242/4096\n",
            "243/4096\n",
            "244/4096\n",
            "245/4096\n",
            "246/4096\n",
            "247/4096\n",
            "248/4096\n",
            "249/4096\n",
            "250/4096\n",
            "251/4096\n",
            "252/4096\n",
            "253/4096\n",
            "254/4096\n",
            "255/4096\n",
            "256/4096\n",
            "257/4096\n",
            "258/4096\n",
            "259/4096\n",
            "260/4096\n",
            "261/4096\n",
            "262/4096\n",
            "263/4096\n",
            "264/4096\n",
            "265/4096\n",
            "266/4096\n",
            "267/4096\n",
            "268/4096\n",
            "269/4096\n",
            "270/4096\n",
            "271/4096\n",
            "272/4096\n",
            "273/4096\n",
            "274/4096\n",
            "275/4096\n",
            "276/4096\n",
            "277/4096\n",
            "278/4096\n",
            "279/4096\n",
            "280/4096\n",
            "281/4096\n",
            "282/4096\n",
            "283/4096\n",
            "284/4096\n",
            "285/4096\n",
            "286/4096\n",
            "287/4096\n",
            "288/4096\n",
            "289/4096\n",
            "290/4096\n",
            "291/4096\n",
            "292/4096\n",
            "293/4096\n",
            "294/4096\n",
            "295/4096\n",
            "296/4096\n",
            "297/4096\n",
            "298/4096\n",
            "299/4096\n",
            "300/4096\n",
            "301/4096\n",
            "302/4096\n",
            "303/4096\n",
            "304/4096\n",
            "305/4096\n",
            "306/4096\n",
            "307/4096\n",
            "308/4096\n",
            "309/4096\n",
            "310/4096\n",
            "311/4096\n",
            "312/4096\n",
            "313/4096\n",
            "314/4096\n",
            "315/4096\n",
            "316/4096\n",
            "317/4096\n",
            "318/4096\n",
            "319/4096\n",
            "320/4096\n",
            "321/4096\n",
            "322/4096\n",
            "323/4096\n",
            "324/4096\n",
            "325/4096\n",
            "326/4096\n",
            "327/4096\n",
            "328/4096\n",
            "329/4096\n",
            "330/4096\n",
            "331/4096\n",
            "332/4096\n",
            "333/4096\n",
            "334/4096\n",
            "335/4096\n",
            "336/4096\n",
            "337/4096\n",
            "338/4096\n",
            "339/4096\n",
            "340/4096\n",
            "341/4096\n",
            "342/4096\n",
            "343/4096\n",
            "344/4096\n",
            "345/4096\n",
            "346/4096\n",
            "347/4096\n",
            "348/4096\n",
            "349/4096\n",
            "350/4096\n",
            "351/4096\n",
            "352/4096\n",
            "353/4096\n",
            "354/4096\n",
            "355/4096\n",
            "356/4096\n",
            "357/4096\n",
            "358/4096\n",
            "359/4096\n",
            "360/4096\n",
            "361/4096\n",
            "362/4096\n",
            "363/4096\n",
            "364/4096\n",
            "365/4096\n",
            "366/4096\n",
            "367/4096\n",
            "368/4096\n",
            "369/4096\n",
            "370/4096\n",
            "371/4096\n",
            "372/4096\n",
            "373/4096\n",
            "374/4096\n",
            "375/4096\n",
            "376/4096\n",
            "377/4096\n",
            "378/4096\n",
            "379/4096\n",
            "380/4096\n",
            "381/4096\n",
            "382/4096\n",
            "383/4096\n",
            "384/4096\n",
            "385/4096\n",
            "386/4096\n",
            "387/4096\n",
            "388/4096\n",
            "389/4096\n",
            "390/4096\n",
            "391/4096\n",
            "392/4096\n",
            "393/4096\n",
            "394/4096\n",
            "395/4096\n",
            "396/4096\n",
            "397/4096\n",
            "398/4096\n",
            "399/4096\n",
            "400/4096\n",
            "401/4096\n",
            "402/4096\n",
            "403/4096\n",
            "404/4096\n",
            "405/4096\n",
            "406/4096\n",
            "407/4096\n",
            "408/4096\n",
            "409/4096\n",
            "410/4096\n",
            "411/4096\n",
            "412/4096\n",
            "413/4096\n",
            "414/4096\n",
            "415/4096\n",
            "416/4096\n",
            "417/4096\n",
            "418/4096\n",
            "419/4096\n",
            "420/4096\n",
            "421/4096\n",
            "422/4096\n",
            "423/4096\n",
            "424/4096\n",
            "425/4096\n",
            "426/4096\n",
            "427/4096\n",
            "428/4096\n",
            "429/4096\n",
            "430/4096\n",
            "431/4096\n",
            "432/4096\n",
            "433/4096\n",
            "434/4096\n",
            "435/4096\n",
            "436/4096\n",
            "437/4096\n",
            "438/4096\n",
            "439/4096\n",
            "440/4096\n",
            "441/4096\n",
            "442/4096\n",
            "443/4096\n",
            "444/4096\n",
            "445/4096\n",
            "446/4096\n",
            "447/4096\n",
            "448/4096\n",
            "449/4096\n",
            "450/4096\n",
            "451/4096\n",
            "452/4096\n",
            "453/4096\n",
            "454/4096\n",
            "455/4096\n",
            "456/4096\n",
            "457/4096\n",
            "458/4096\n",
            "459/4096\n",
            "460/4096\n",
            "461/4096\n",
            "462/4096\n",
            "463/4096\n",
            "464/4096\n",
            "465/4096\n",
            "466/4096\n",
            "467/4096\n",
            "468/4096\n",
            "469/4096\n",
            "470/4096\n",
            "471/4096\n",
            "472/4096\n",
            "473/4096\n",
            "474/4096\n",
            "475/4096\n",
            "476/4096\n",
            "477/4096\n",
            "478/4096\n",
            "479/4096\n",
            "480/4096\n",
            "481/4096\n",
            "482/4096\n",
            "483/4096\n",
            "484/4096\n",
            "485/4096\n",
            "486/4096\n",
            "487/4096\n",
            "488/4096\n",
            "489/4096\n",
            "490/4096\n",
            "491/4096\n",
            "492/4096\n",
            "493/4096\n",
            "494/4096\n",
            "495/4096\n",
            "496/4096\n",
            "497/4096\n",
            "498/4096\n",
            "499/4096\n",
            "500/4096\n",
            "501/4096\n",
            "502/4096\n",
            "503/4096\n",
            "504/4096\n",
            "505/4096\n",
            "506/4096\n",
            "507/4096\n",
            "508/4096\n",
            "509/4096\n",
            "510/4096\n",
            "511/4096\n",
            "512/4096\n",
            "513/4096\n",
            "514/4096\n",
            "515/4096\n",
            "516/4096\n",
            "517/4096\n",
            "518/4096\n",
            "519/4096\n",
            "520/4096\n",
            "521/4096\n",
            "522/4096\n",
            "523/4096\n",
            "524/4096\n",
            "525/4096\n",
            "526/4096\n",
            "527/4096\n",
            "528/4096\n",
            "529/4096\n",
            "530/4096\n",
            "531/4096\n",
            "532/4096\n",
            "533/4096\n",
            "534/4096\n",
            "535/4096\n",
            "536/4096\n",
            "537/4096\n",
            "538/4096\n",
            "539/4096\n",
            "540/4096\n",
            "541/4096\n",
            "542/4096\n",
            "543/4096\n",
            "544/4096\n",
            "545/4096\n",
            "546/4096\n",
            "547/4096\n",
            "548/4096\n",
            "549/4096\n",
            "550/4096\n",
            "551/4096\n",
            "552/4096\n",
            "553/4096\n",
            "554/4096\n",
            "555/4096\n",
            "556/4096\n",
            "557/4096\n",
            "558/4096\n",
            "559/4096\n",
            "560/4096\n",
            "561/4096\n",
            "562/4096\n",
            "563/4096\n",
            "564/4096\n",
            "565/4096\n",
            "566/4096\n",
            "567/4096\n",
            "568/4096\n",
            "569/4096\n",
            "570/4096\n",
            "571/4096\n",
            "572/4096\n",
            "573/4096\n",
            "574/4096\n",
            "575/4096\n",
            "576/4096\n",
            "577/4096\n",
            "578/4096\n",
            "579/4096\n",
            "580/4096\n",
            "581/4096\n",
            "582/4096\n",
            "583/4096\n",
            "584/4096\n",
            "585/4096\n",
            "586/4096\n",
            "587/4096\n",
            "588/4096\n",
            "589/4096\n",
            "590/4096\n",
            "591/4096\n",
            "592/4096\n",
            "593/4096\n",
            "594/4096\n",
            "595/4096\n",
            "596/4096\n",
            "597/4096\n",
            "598/4096\n",
            "599/4096\n",
            "600/4096\n",
            "601/4096\n",
            "602/4096\n",
            "603/4096\n",
            "604/4096\n",
            "605/4096\n",
            "606/4096\n",
            "607/4096\n",
            "608/4096\n",
            "609/4096\n",
            "610/4096\n",
            "611/4096\n",
            "612/4096\n",
            "613/4096\n",
            "614/4096\n",
            "615/4096\n",
            "616/4096\n",
            "617/4096\n",
            "618/4096\n",
            "619/4096\n",
            "620/4096\n",
            "621/4096\n",
            "622/4096\n",
            "623/4096\n",
            "624/4096\n",
            "625/4096\n",
            "626/4096\n",
            "627/4096\n",
            "628/4096\n",
            "629/4096\n",
            "630/4096\n",
            "631/4096\n",
            "632/4096\n",
            "633/4096\n",
            "634/4096\n",
            "635/4096\n",
            "636/4096\n",
            "637/4096\n",
            "638/4096\n",
            "639/4096\n",
            "640/4096\n",
            "641/4096\n",
            "642/4096\n",
            "643/4096\n",
            "644/4096\n",
            "645/4096\n",
            "646/4096\n",
            "647/4096\n",
            "648/4096\n",
            "649/4096\n",
            "650/4096\n",
            "651/4096\n",
            "652/4096\n",
            "653/4096\n",
            "654/4096\n",
            "655/4096\n",
            "656/4096\n",
            "657/4096\n",
            "658/4096\n",
            "659/4096\n",
            "660/4096\n",
            "661/4096\n",
            "662/4096\n",
            "663/4096\n",
            "664/4096\n",
            "665/4096\n",
            "666/4096\n",
            "667/4096\n",
            "668/4096\n",
            "669/4096\n",
            "670/4096\n",
            "671/4096\n",
            "672/4096\n",
            "673/4096\n",
            "674/4096\n",
            "675/4096\n",
            "676/4096\n",
            "677/4096\n",
            "678/4096\n",
            "679/4096\n",
            "680/4096\n",
            "681/4096\n",
            "682/4096\n",
            "683/4096\n",
            "684/4096\n",
            "685/4096\n",
            "686/4096\n",
            "687/4096\n",
            "688/4096\n",
            "689/4096\n",
            "690/4096\n",
            "691/4096\n",
            "692/4096\n",
            "693/4096\n",
            "694/4096\n",
            "695/4096\n",
            "696/4096\n",
            "697/4096\n",
            "698/4096\n",
            "699/4096\n",
            "700/4096\n",
            "701/4096\n",
            "702/4096\n",
            "703/4096\n",
            "704/4096\n",
            "705/4096\n",
            "706/4096\n",
            "707/4096\n",
            "708/4096\n",
            "709/4096\n",
            "710/4096\n",
            "711/4096\n",
            "712/4096\n",
            "713/4096\n",
            "714/4096\n",
            "715/4096\n",
            "716/4096\n",
            "717/4096\n",
            "718/4096\n",
            "719/4096\n",
            "720/4096\n",
            "721/4096\n",
            "722/4096\n",
            "723/4096\n",
            "724/4096\n",
            "725/4096\n",
            "726/4096\n",
            "727/4096\n",
            "728/4096\n",
            "729/4096\n",
            "730/4096\n",
            "731/4096\n",
            "732/4096\n",
            "733/4096\n",
            "734/4096\n",
            "735/4096\n",
            "736/4096\n",
            "737/4096\n",
            "738/4096\n",
            "739/4096\n",
            "740/4096\n",
            "741/4096\n",
            "742/4096\n",
            "743/4096\n",
            "744/4096\n",
            "745/4096\n",
            "746/4096\n",
            "747/4096\n",
            "748/4096\n",
            "749/4096\n",
            "750/4096\n",
            "751/4096\n",
            "752/4096\n",
            "753/4096\n",
            "754/4096\n",
            "755/4096\n",
            "756/4096\n",
            "757/4096\n",
            "758/4096\n",
            "759/4096\n",
            "760/4096\n",
            "761/4096\n",
            "762/4096\n",
            "763/4096\n",
            "764/4096\n",
            "765/4096\n",
            "766/4096\n",
            "767/4096\n",
            "768/4096\n",
            "769/4096\n",
            "770/4096\n",
            "771/4096\n",
            "772/4096\n",
            "773/4096\n",
            "774/4096\n",
            "775/4096\n",
            "776/4096\n",
            "777/4096\n",
            "778/4096\n",
            "779/4096\n",
            "780/4096\n",
            "781/4096\n",
            "782/4096\n",
            "783/4096\n",
            "784/4096\n",
            "785/4096\n",
            "786/4096\n",
            "787/4096\n",
            "788/4096\n",
            "789/4096\n",
            "790/4096\n",
            "791/4096\n",
            "792/4096\n",
            "793/4096\n",
            "794/4096\n",
            "795/4096\n",
            "796/4096\n",
            "797/4096\n",
            "798/4096\n",
            "799/4096\n",
            "800/4096\n",
            "801/4096\n",
            "802/4096\n",
            "803/4096\n",
            "804/4096\n",
            "805/4096\n",
            "806/4096\n",
            "807/4096\n",
            "808/4096\n",
            "809/4096\n",
            "810/4096\n",
            "811/4096\n",
            "812/4096\n",
            "813/4096\n",
            "814/4096\n",
            "815/4096\n",
            "816/4096\n",
            "817/4096\n",
            "818/4096\n",
            "819/4096\n",
            "820/4096\n",
            "821/4096\n",
            "822/4096\n",
            "823/4096\n",
            "824/4096\n",
            "825/4096\n",
            "826/4096\n",
            "827/4096\n",
            "828/4096\n",
            "829/4096\n",
            "830/4096\n",
            "831/4096\n",
            "832/4096\n",
            "833/4096\n",
            "834/4096\n",
            "835/4096\n",
            "836/4096\n",
            "837/4096\n",
            "838/4096\n",
            "839/4096\n",
            "840/4096\n",
            "841/4096\n",
            "842/4096\n",
            "843/4096\n",
            "844/4096\n",
            "845/4096\n",
            "846/4096\n",
            "847/4096\n",
            "848/4096\n",
            "849/4096\n",
            "850/4096\n",
            "851/4096\n",
            "852/4096\n",
            "853/4096\n",
            "854/4096\n",
            "855/4096\n",
            "856/4096\n",
            "857/4096\n",
            "858/4096\n",
            "859/4096\n",
            "860/4096\n",
            "861/4096\n",
            "862/4096\n",
            "863/4096\n",
            "864/4096\n",
            "865/4096\n",
            "866/4096\n",
            "867/4096\n",
            "868/4096\n",
            "869/4096\n",
            "870/4096\n",
            "871/4096\n",
            "872/4096\n",
            "873/4096\n",
            "874/4096\n",
            "875/4096\n",
            "876/4096\n",
            "877/4096\n",
            "878/4096\n",
            "879/4096\n",
            "880/4096\n",
            "881/4096\n",
            "882/4096\n",
            "883/4096\n",
            "884/4096\n",
            "885/4096\n",
            "886/4096\n",
            "887/4096\n",
            "888/4096\n",
            "889/4096\n",
            "890/4096\n",
            "891/4096\n",
            "892/4096\n",
            "893/4096\n",
            "894/4096\n",
            "895/4096\n",
            "896/4096\n",
            "897/4096\n",
            "898/4096\n",
            "899/4096\n",
            "900/4096\n",
            "901/4096\n",
            "902/4096\n",
            "903/4096\n",
            "904/4096\n",
            "905/4096\n",
            "906/4096\n",
            "907/4096\n",
            "908/4096\n",
            "909/4096\n",
            "910/4096\n",
            "911/4096\n",
            "912/4096\n",
            "913/4096\n",
            "914/4096\n",
            "915/4096\n",
            "916/4096\n",
            "917/4096\n",
            "918/4096\n",
            "919/4096\n",
            "920/4096\n",
            "921/4096\n",
            "922/4096\n",
            "923/4096\n",
            "924/4096\n",
            "925/4096\n",
            "926/4096\n",
            "927/4096\n",
            "928/4096\n",
            "929/4096\n",
            "930/4096\n",
            "931/4096\n",
            "932/4096\n",
            "933/4096\n",
            "934/4096\n",
            "935/4096\n",
            "936/4096\n",
            "937/4096\n",
            "938/4096\n",
            "939/4096\n",
            "940/4096\n",
            "941/4096\n",
            "942/4096\n",
            "943/4096\n",
            "944/4096\n",
            "945/4096\n",
            "946/4096\n",
            "947/4096\n",
            "948/4096\n",
            "949/4096\n",
            "950/4096\n",
            "951/4096\n",
            "952/4096\n",
            "953/4096\n",
            "954/4096\n",
            "955/4096\n",
            "956/4096\n",
            "957/4096\n",
            "958/4096\n",
            "959/4096\n",
            "960/4096\n",
            "961/4096\n",
            "962/4096\n",
            "963/4096\n",
            "964/4096\n",
            "965/4096\n",
            "966/4096\n",
            "967/4096\n",
            "968/4096\n",
            "969/4096\n",
            "970/4096\n",
            "971/4096\n",
            "972/4096\n",
            "973/4096\n",
            "974/4096\n",
            "975/4096\n",
            "976/4096\n",
            "977/4096\n",
            "978/4096\n",
            "979/4096\n",
            "980/4096\n",
            "981/4096\n",
            "982/4096\n",
            "983/4096\n",
            "984/4096\n",
            "985/4096\n",
            "986/4096\n",
            "987/4096\n",
            "988/4096\n",
            "989/4096\n",
            "990/4096\n",
            "991/4096\n",
            "992/4096\n",
            "993/4096\n",
            "994/4096\n",
            "995/4096\n",
            "996/4096\n",
            "997/4096\n",
            "998/4096\n",
            "999/4096\n",
            "1000/4096\n",
            "1001/4096\n",
            "1002/4096\n",
            "1003/4096\n",
            "1004/4096\n",
            "1005/4096\n",
            "1006/4096\n",
            "1007/4096\n",
            "1008/4096\n",
            "1009/4096\n",
            "1010/4096\n",
            "1011/4096\n",
            "1012/4096\n",
            "1013/4096\n",
            "1014/4096\n",
            "1015/4096\n",
            "1016/4096\n",
            "1017/4096\n",
            "1018/4096\n",
            "1019/4096\n",
            "1020/4096\n",
            "1021/4096\n",
            "1022/4096\n",
            "1023/4096\n",
            "1024/4096\n",
            "1025/4096\n",
            "1026/4096\n",
            "1027/4096\n",
            "1028/4096\n",
            "1029/4096\n",
            "1030/4096\n",
            "1031/4096\n",
            "1032/4096\n",
            "1033/4096\n",
            "1034/4096\n",
            "1035/4096\n",
            "1036/4096\n",
            "1037/4096\n",
            "1038/4096\n",
            "1039/4096\n",
            "1040/4096\n",
            "1041/4096\n",
            "1042/4096\n",
            "1043/4096\n",
            "1044/4096\n",
            "1045/4096\n",
            "1046/4096\n",
            "1047/4096\n",
            "1048/4096\n",
            "1049/4096\n",
            "1050/4096\n",
            "1051/4096\n",
            "1052/4096\n",
            "1053/4096\n",
            "1054/4096\n",
            "1055/4096\n",
            "1056/4096\n",
            "1057/4096\n",
            "1058/4096\n",
            "1059/4096\n",
            "1060/4096\n",
            "1061/4096\n",
            "1062/4096\n",
            "1063/4096\n",
            "1064/4096\n",
            "1065/4096\n",
            "1066/4096\n",
            "1067/4096\n",
            "1068/4096\n",
            "1069/4096\n",
            "1070/4096\n",
            "1071/4096\n",
            "1072/4096\n",
            "1073/4096\n",
            "1074/4096\n",
            "1075/4096\n",
            "1076/4096\n",
            "1077/4096\n",
            "1078/4096\n",
            "1079/4096\n",
            "1080/4096\n",
            "1081/4096\n",
            "1082/4096\n",
            "1083/4096\n",
            "1084/4096\n",
            "1085/4096\n",
            "1086/4096\n",
            "1087/4096\n",
            "1088/4096\n",
            "1089/4096\n",
            "1090/4096\n",
            "1091/4096\n",
            "1092/4096\n",
            "1093/4096\n",
            "1094/4096\n",
            "1095/4096\n",
            "1096/4096\n",
            "1097/4096\n",
            "1098/4096\n",
            "1099/4096\n",
            "1100/4096\n",
            "1101/4096\n",
            "1102/4096\n",
            "1103/4096\n",
            "1104/4096\n",
            "1105/4096\n",
            "1106/4096\n",
            "1107/4096\n",
            "1108/4096\n",
            "1109/4096\n",
            "1110/4096\n",
            "1111/4096\n",
            "1112/4096\n",
            "1113/4096\n",
            "1114/4096\n",
            "1115/4096\n",
            "1116/4096\n",
            "1117/4096\n",
            "1118/4096\n",
            "1119/4096\n",
            "1120/4096\n",
            "1121/4096\n",
            "1122/4096\n",
            "1123/4096\n",
            "1124/4096\n",
            "1125/4096\n",
            "1126/4096\n",
            "1127/4096\n",
            "1128/4096\n",
            "1129/4096\n",
            "1130/4096\n",
            "1131/4096\n",
            "1132/4096\n",
            "1133/4096\n",
            "1134/4096\n",
            "1135/4096\n",
            "1136/4096\n",
            "1137/4096\n",
            "1138/4096\n",
            "1139/4096\n",
            "1140/4096\n",
            "1141/4096\n",
            "1142/4096\n",
            "1143/4096\n",
            "1144/4096\n",
            "1145/4096\n",
            "1146/4096\n",
            "1147/4096\n",
            "1148/4096\n",
            "1149/4096\n",
            "1150/4096\n",
            "1151/4096\n",
            "1152/4096\n",
            "1153/4096\n",
            "1154/4096\n",
            "1155/4096\n",
            "1156/4096\n",
            "1157/4096\n",
            "1158/4096\n",
            "1159/4096\n",
            "1160/4096\n",
            "1161/4096\n",
            "1162/4096\n",
            "1163/4096\n",
            "1164/4096\n",
            "1165/4096\n",
            "1166/4096\n",
            "1167/4096\n",
            "1168/4096\n",
            "1169/4096\n",
            "1170/4096\n",
            "1171/4096\n",
            "1172/4096\n",
            "1173/4096\n",
            "1174/4096\n",
            "1175/4096\n",
            "1176/4096\n",
            "1177/4096\n",
            "1178/4096\n",
            "1179/4096\n",
            "1180/4096\n",
            "1181/4096\n",
            "1182/4096\n",
            "1183/4096\n",
            "1184/4096\n",
            "1185/4096\n",
            "1186/4096\n",
            "1187/4096\n",
            "1188/4096\n",
            "1189/4096\n",
            "1190/4096\n",
            "1191/4096\n",
            "1192/4096\n",
            "1193/4096\n",
            "1194/4096\n",
            "1195/4096\n",
            "1196/4096\n",
            "1197/4096\n",
            "1198/4096\n",
            "1199/4096\n",
            "1200/4096\n",
            "1201/4096\n",
            "1202/4096\n",
            "1203/4096\n",
            "1204/4096\n",
            "1205/4096\n",
            "1206/4096\n",
            "1207/4096\n",
            "1208/4096\n",
            "1209/4096\n",
            "1210/4096\n",
            "1211/4096\n",
            "1212/4096\n",
            "1213/4096\n",
            "1214/4096\n",
            "1215/4096\n",
            "1216/4096\n",
            "1217/4096\n",
            "1218/4096\n",
            "1219/4096\n",
            "1220/4096\n",
            "1221/4096\n",
            "1222/4096\n",
            "1223/4096\n",
            "1224/4096\n",
            "1225/4096\n",
            "1226/4096\n",
            "1227/4096\n",
            "1228/4096\n",
            "1229/4096\n",
            "1230/4096\n",
            "1231/4096\n",
            "1232/4096\n",
            "1233/4096\n",
            "1234/4096\n",
            "1235/4096\n",
            "1236/4096\n",
            "1237/4096\n",
            "1238/4096\n",
            "1239/4096\n",
            "1240/4096\n",
            "1241/4096\n",
            "1242/4096\n",
            "1243/4096\n",
            "1244/4096\n",
            "1245/4096\n",
            "1246/4096\n",
            "1247/4096\n",
            "1248/4096\n",
            "1249/4096\n",
            "1250/4096\n",
            "1251/4096\n",
            "1252/4096\n",
            "1253/4096\n",
            "1254/4096\n",
            "1255/4096\n",
            "1256/4096\n",
            "1257/4096\n",
            "1258/4096\n",
            "1259/4096\n",
            "1260/4096\n",
            "1261/4096\n",
            "1262/4096\n",
            "1263/4096\n",
            "1264/4096\n",
            "1265/4096\n",
            "1266/4096\n",
            "1267/4096\n",
            "1268/4096\n",
            "1269/4096\n",
            "1270/4096\n",
            "1271/4096\n",
            "1272/4096\n",
            "1273/4096\n",
            "1274/4096\n",
            "1275/4096\n",
            "1276/4096\n",
            "1277/4096\n",
            "1278/4096\n",
            "1279/4096\n",
            "1280/4096\n",
            "1281/4096\n",
            "1282/4096\n",
            "1283/4096\n",
            "1284/4096\n",
            "1285/4096\n",
            "1286/4096\n",
            "1287/4096\n",
            "1288/4096\n",
            "1289/4096\n",
            "1290/4096\n",
            "1291/4096\n",
            "1292/4096\n",
            "1293/4096\n",
            "1294/4096\n",
            "1295/4096\n",
            "1296/4096\n",
            "1297/4096\n",
            "1298/4096\n",
            "1299/4096\n",
            "1300/4096\n",
            "1301/4096\n",
            "1302/4096\n",
            "1303/4096\n",
            "1304/4096\n",
            "1305/4096\n",
            "1306/4096\n",
            "1307/4096\n",
            "1308/4096\n",
            "1309/4096\n",
            "1310/4096\n",
            "1311/4096\n",
            "1312/4096\n",
            "1313/4096\n",
            "1314/4096\n",
            "1315/4096\n",
            "1316/4096\n",
            "1317/4096\n",
            "1318/4096\n",
            "1319/4096\n",
            "1320/4096\n",
            "1321/4096\n",
            "1322/4096\n",
            "1323/4096\n",
            "1324/4096\n",
            "1325/4096\n",
            "1326/4096\n",
            "1327/4096\n",
            "1328/4096\n",
            "1329/4096\n",
            "1330/4096\n",
            "1331/4096\n",
            "1332/4096\n",
            "1333/4096\n",
            "1334/4096\n",
            "1335/4096\n",
            "1336/4096\n",
            "1337/4096\n",
            "1338/4096\n",
            "1339/4096\n",
            "1340/4096\n",
            "1341/4096\n",
            "1342/4096\n",
            "1343/4096\n",
            "1344/4096\n",
            "1345/4096\n",
            "1346/4096\n",
            "1347/4096\n",
            "1348/4096\n",
            "1349/4096\n",
            "1350/4096\n",
            "1351/4096\n",
            "1352/4096\n",
            "1353/4096\n",
            "1354/4096\n",
            "1355/4096\n",
            "1356/4096\n",
            "1357/4096\n",
            "1358/4096\n",
            "1359/4096\n",
            "1360/4096\n",
            "1361/4096\n",
            "1362/4096\n",
            "1363/4096\n",
            "1364/4096\n",
            "1365/4096\n",
            "1366/4096\n",
            "1367/4096\n",
            "1368/4096\n",
            "1369/4096\n",
            "1370/4096\n",
            "1371/4096\n",
            "1372/4096\n",
            "1373/4096\n",
            "1374/4096\n",
            "1375/4096\n",
            "1376/4096\n",
            "1377/4096\n",
            "1378/4096\n",
            "1379/4096\n",
            "1380/4096\n",
            "1381/4096\n",
            "1382/4096\n",
            "1383/4096\n",
            "1384/4096\n",
            "1385/4096\n",
            "1386/4096\n",
            "1387/4096\n",
            "1388/4096\n",
            "1389/4096\n",
            "1390/4096\n",
            "1391/4096\n",
            "1392/4096\n",
            "1393/4096\n",
            "1394/4096\n",
            "1395/4096\n",
            "1396/4096\n",
            "1397/4096\n",
            "1398/4096\n",
            "1399/4096\n",
            "1400/4096\n",
            "1401/4096\n",
            "1402/4096\n",
            "1403/4096\n",
            "1404/4096\n",
            "1405/4096\n",
            "1406/4096\n",
            "1407/4096\n",
            "1408/4096\n",
            "1409/4096\n",
            "1410/4096\n",
            "1411/4096\n",
            "1412/4096\n",
            "1413/4096\n",
            "1414/4096\n",
            "1415/4096\n",
            "1416/4096\n",
            "1417/4096\n",
            "1418/4096\n",
            "1419/4096\n",
            "1420/4096\n",
            "1421/4096\n",
            "1422/4096\n",
            "1423/4096\n",
            "1424/4096\n",
            "1425/4096\n",
            "1426/4096\n",
            "1427/4096\n",
            "1428/4096\n",
            "1429/4096\n",
            "1430/4096\n",
            "1431/4096\n",
            "1432/4096\n",
            "1433/4096\n",
            "1434/4096\n",
            "1435/4096\n",
            "1436/4096\n",
            "1437/4096\n",
            "1438/4096\n",
            "1439/4096\n",
            "1440/4096\n",
            "1441/4096\n",
            "1442/4096\n",
            "1443/4096\n",
            "1444/4096\n",
            "1445/4096\n",
            "1446/4096\n",
            "1447/4096\n",
            "1448/4096\n",
            "1449/4096\n",
            "1450/4096\n",
            "1451/4096\n",
            "1452/4096\n",
            "1453/4096\n",
            "1454/4096\n",
            "1455/4096\n",
            "1456/4096\n",
            "1457/4096\n",
            "1458/4096\n",
            "1459/4096\n",
            "1460/4096\n",
            "1461/4096\n",
            "1462/4096\n",
            "1463/4096\n",
            "1464/4096\n",
            "1465/4096\n",
            "1466/4096\n",
            "1467/4096\n",
            "1468/4096\n",
            "1469/4096\n",
            "1470/4096\n",
            "1471/4096\n",
            "1472/4096\n",
            "1473/4096\n",
            "1474/4096\n",
            "1475/4096\n",
            "1476/4096\n",
            "1477/4096\n",
            "1478/4096\n",
            "1479/4096\n",
            "1480/4096\n",
            "1481/4096\n",
            "1482/4096\n",
            "1483/4096\n",
            "1484/4096\n",
            "1485/4096\n",
            "1486/4096\n",
            "1487/4096\n",
            "1488/4096\n",
            "1489/4096\n",
            "1490/4096\n",
            "1491/4096\n",
            "1492/4096\n",
            "1493/4096\n",
            "1494/4096\n",
            "1495/4096\n",
            "1496/4096\n",
            "1497/4096\n",
            "1498/4096\n",
            "1499/4096\n",
            "1500/4096\n",
            "1501/4096\n",
            "1502/4096\n",
            "1503/4096\n",
            "1504/4096\n",
            "1505/4096\n",
            "1506/4096\n",
            "1507/4096\n",
            "1508/4096\n",
            "1509/4096\n",
            "1510/4096\n",
            "1511/4096\n",
            "1512/4096\n",
            "1513/4096\n",
            "1514/4096\n",
            "1515/4096\n",
            "1516/4096\n",
            "1517/4096\n",
            "1518/4096\n",
            "1519/4096\n",
            "1520/4096\n",
            "1521/4096\n",
            "1522/4096\n",
            "1523/4096\n",
            "1524/4096\n",
            "1525/4096\n",
            "1526/4096\n",
            "1527/4096\n",
            "1528/4096\n",
            "1529/4096\n",
            "1530/4096\n",
            "1531/4096\n",
            "1532/4096\n",
            "1533/4096\n",
            "1534/4096\n",
            "1535/4096\n",
            "1536/4096\n",
            "1537/4096\n",
            "1538/4096\n",
            "1539/4096\n",
            "1540/4096\n",
            "1541/4096\n",
            "1542/4096\n",
            "1543/4096\n",
            "1544/4096\n",
            "1545/4096\n",
            "1546/4096\n",
            "1547/4096\n",
            "1548/4096\n",
            "1549/4096\n",
            "1550/4096\n",
            "1551/4096\n",
            "1552/4096\n",
            "1553/4096\n",
            "1554/4096\n",
            "1555/4096\n",
            "1556/4096\n",
            "1557/4096\n",
            "1558/4096\n",
            "1559/4096\n",
            "1560/4096\n",
            "1561/4096\n",
            "1562/4096\n",
            "1563/4096\n",
            "1564/4096\n",
            "1565/4096\n",
            "1566/4096\n",
            "1567/4096\n",
            "1568/4096\n",
            "1569/4096\n",
            "1570/4096\n",
            "1571/4096\n",
            "1572/4096\n",
            "1573/4096\n",
            "1574/4096\n",
            "1575/4096\n",
            "1576/4096\n",
            "1577/4096\n",
            "1578/4096\n",
            "1579/4096\n",
            "1580/4096\n",
            "1581/4096\n",
            "1582/4096\n",
            "1583/4096\n",
            "1584/4096\n",
            "1585/4096\n",
            "1586/4096\n",
            "1587/4096\n",
            "1588/4096\n",
            "1589/4096\n",
            "1590/4096\n",
            "1591/4096\n",
            "1592/4096\n",
            "1593/4096\n",
            "1594/4096\n",
            "1595/4096\n",
            "1596/4096\n",
            "1597/4096\n",
            "1598/4096\n",
            "1599/4096\n",
            "1600/4096\n",
            "1601/4096\n",
            "1602/4096\n",
            "1603/4096\n",
            "1604/4096\n",
            "1605/4096\n",
            "1606/4096\n",
            "1607/4096\n",
            "1608/4096\n",
            "1609/4096\n",
            "1610/4096\n",
            "1611/4096\n",
            "1612/4096\n",
            "1613/4096\n",
            "1614/4096\n",
            "1615/4096\n",
            "1616/4096\n",
            "1617/4096\n",
            "1618/4096\n",
            "1619/4096\n",
            "1620/4096\n",
            "1621/4096\n",
            "1622/4096\n",
            "1623/4096\n",
            "1624/4096\n",
            "1625/4096\n",
            "1626/4096\n",
            "1627/4096\n",
            "1628/4096\n",
            "1629/4096\n",
            "1630/4096\n",
            "1631/4096\n",
            "1632/4096\n",
            "1633/4096\n",
            "1634/4096\n",
            "1635/4096\n",
            "1636/4096\n",
            "1637/4096\n",
            "1638/4096\n",
            "1639/4096\n",
            "1640/4096\n",
            "1641/4096\n",
            "1642/4096\n",
            "1643/4096\n",
            "1644/4096\n",
            "1645/4096\n",
            "1646/4096\n",
            "1647/4096\n",
            "1648/4096\n",
            "1649/4096\n",
            "1650/4096\n",
            "1651/4096\n",
            "1652/4096\n",
            "1653/4096\n",
            "1654/4096\n",
            "1655/4096\n",
            "1656/4096\n",
            "1657/4096\n",
            "1658/4096\n",
            "1659/4096\n",
            "1660/4096\n",
            "1661/4096\n",
            "1662/4096\n",
            "1663/4096\n",
            "1664/4096\n",
            "1665/4096\n",
            "1666/4096\n",
            "1667/4096\n",
            "1668/4096\n",
            "1669/4096\n",
            "1670/4096\n",
            "1671/4096\n",
            "1672/4096\n",
            "1673/4096\n",
            "1674/4096\n",
            "1675/4096\n",
            "1676/4096\n",
            "1677/4096\n",
            "1678/4096\n",
            "1679/4096\n",
            "1680/4096\n",
            "1681/4096\n",
            "1682/4096\n",
            "1683/4096\n",
            "1684/4096\n",
            "1685/4096\n",
            "1686/4096\n",
            "1687/4096\n",
            "1688/4096\n",
            "1689/4096\n",
            "1690/4096\n",
            "1691/4096\n",
            "1692/4096\n",
            "1693/4096\n",
            "1694/4096\n",
            "1695/4096\n",
            "1696/4096\n",
            "1697/4096\n",
            "1698/4096\n",
            "1699/4096\n",
            "1700/4096\n",
            "1701/4096\n",
            "1702/4096\n",
            "1703/4096\n",
            "1704/4096\n",
            "1705/4096\n",
            "1706/4096\n",
            "1707/4096\n",
            "1708/4096\n",
            "1709/4096\n",
            "1710/4096\n",
            "1711/4096\n",
            "1712/4096\n",
            "1713/4096\n",
            "1714/4096\n",
            "1715/4096\n",
            "1716/4096\n",
            "1717/4096\n",
            "1718/4096\n",
            "1719/4096\n",
            "1720/4096\n",
            "1721/4096\n",
            "1722/4096\n",
            "1723/4096\n",
            "1724/4096\n",
            "1725/4096\n",
            "1726/4096\n",
            "1727/4096\n",
            "1728/4096\n",
            "1729/4096\n",
            "1730/4096\n",
            "1731/4096\n",
            "1732/4096\n",
            "1733/4096\n",
            "1734/4096\n",
            "1735/4096\n",
            "1736/4096\n",
            "1737/4096\n",
            "1738/4096\n",
            "1739/4096\n",
            "1740/4096\n",
            "1741/4096\n",
            "1742/4096\n",
            "1743/4096\n",
            "1744/4096\n",
            "1745/4096\n",
            "1746/4096\n",
            "1747/4096\n",
            "1748/4096\n",
            "1749/4096\n",
            "1750/4096\n",
            "1751/4096\n",
            "1752/4096\n",
            "1753/4096\n",
            "1754/4096\n",
            "1755/4096\n",
            "1756/4096\n",
            "1757/4096\n",
            "1758/4096\n",
            "1759/4096\n",
            "1760/4096\n",
            "1761/4096\n",
            "1762/4096\n",
            "1763/4096\n",
            "1764/4096\n",
            "1765/4096\n",
            "1766/4096\n",
            "1767/4096\n",
            "1768/4096\n",
            "1769/4096\n",
            "1770/4096\n",
            "1771/4096\n",
            "1772/4096\n",
            "1773/4096\n",
            "1774/4096\n",
            "1775/4096\n",
            "1776/4096\n",
            "1777/4096\n",
            "1778/4096\n",
            "1779/4096\n",
            "1780/4096\n",
            "1781/4096\n",
            "1782/4096\n",
            "1783/4096\n",
            "1784/4096\n",
            "1785/4096\n",
            "1786/4096\n",
            "1787/4096\n",
            "1788/4096\n",
            "1789/4096\n",
            "1790/4096\n",
            "1791/4096\n",
            "1792/4096\n",
            "1793/4096\n",
            "1794/4096\n",
            "1795/4096\n",
            "1796/4096\n",
            "1797/4096\n",
            "1798/4096\n",
            "1799/4096\n",
            "1800/4096\n",
            "1801/4096\n",
            "1802/4096\n",
            "1803/4096\n",
            "1804/4096\n",
            "1805/4096\n",
            "1806/4096\n",
            "1807/4096\n",
            "1808/4096\n",
            "1809/4096\n",
            "1810/4096\n",
            "1811/4096\n",
            "1812/4096\n",
            "1813/4096\n",
            "1814/4096\n",
            "1815/4096\n",
            "1816/4096\n",
            "1817/4096\n",
            "1818/4096\n",
            "1819/4096\n",
            "1820/4096\n",
            "1821/4096\n",
            "1822/4096\n",
            "1823/4096\n",
            "1824/4096\n",
            "1825/4096\n",
            "1826/4096\n",
            "1827/4096\n",
            "1828/4096\n",
            "1829/4096\n",
            "1830/4096\n",
            "1831/4096\n",
            "1832/4096\n",
            "1833/4096\n",
            "1834/4096\n",
            "1835/4096\n",
            "1836/4096\n",
            "1837/4096\n",
            "1838/4096\n",
            "1839/4096\n",
            "1840/4096\n",
            "1841/4096\n",
            "1842/4096\n",
            "1843/4096\n",
            "1844/4096\n",
            "1845/4096\n",
            "1846/4096\n",
            "1847/4096\n",
            "1848/4096\n",
            "1849/4096\n",
            "1850/4096\n",
            "1851/4096\n",
            "1852/4096\n",
            "1853/4096\n",
            "1854/4096\n",
            "1855/4096\n",
            "1856/4096\n",
            "1857/4096\n",
            "1858/4096\n",
            "1859/4096\n",
            "1860/4096\n",
            "1861/4096\n",
            "1862/4096\n",
            "1863/4096\n",
            "1864/4096\n",
            "1865/4096\n",
            "1866/4096\n",
            "1867/4096\n",
            "1868/4096\n",
            "1869/4096\n",
            "1870/4096\n",
            "1871/4096\n",
            "1872/4096\n",
            "1873/4096\n",
            "1874/4096\n",
            "1875/4096\n",
            "1876/4096\n",
            "1877/4096\n",
            "1878/4096\n",
            "1879/4096\n",
            "1880/4096\n",
            "1881/4096\n",
            "1882/4096\n",
            "1883/4096\n",
            "1884/4096\n",
            "1885/4096\n",
            "1886/4096\n",
            "1887/4096\n",
            "1888/4096\n",
            "1889/4096\n",
            "1890/4096\n",
            "1891/4096\n",
            "1892/4096\n",
            "1893/4096\n",
            "1894/4096\n",
            "1895/4096\n",
            "1896/4096\n",
            "1897/4096\n",
            "1898/4096\n",
            "1899/4096\n",
            "1900/4096\n",
            "1901/4096\n",
            "1902/4096\n",
            "1903/4096\n",
            "1904/4096\n",
            "1905/4096\n",
            "1906/4096\n",
            "1907/4096\n",
            "1908/4096\n",
            "1909/4096\n",
            "1910/4096\n",
            "1911/4096\n",
            "1912/4096\n",
            "1913/4096\n",
            "1914/4096\n",
            "1915/4096\n",
            "1916/4096\n",
            "1917/4096\n",
            "1918/4096\n",
            "1919/4096\n",
            "1920/4096\n",
            "1921/4096\n",
            "1922/4096\n",
            "1923/4096\n",
            "1924/4096\n",
            "1925/4096\n",
            "1926/4096\n",
            "1927/4096\n",
            "1928/4096\n",
            "1929/4096\n",
            "1930/4096\n",
            "1931/4096\n",
            "1932/4096\n",
            "1933/4096\n",
            "1934/4096\n",
            "1935/4096\n",
            "1936/4096\n",
            "1937/4096\n",
            "1938/4096\n",
            "1939/4096\n",
            "1940/4096\n",
            "1941/4096\n",
            "1942/4096\n",
            "1943/4096\n",
            "1944/4096\n",
            "1945/4096\n",
            "1946/4096\n",
            "1947/4096\n",
            "1948/4096\n",
            "1949/4096\n",
            "1950/4096\n",
            "1951/4096\n",
            "1952/4096\n",
            "1953/4096\n",
            "1954/4096\n",
            "1955/4096\n",
            "1956/4096\n",
            "1957/4096\n",
            "1958/4096\n",
            "1959/4096\n",
            "1960/4096\n",
            "1961/4096\n",
            "1962/4096\n",
            "1963/4096\n",
            "1964/4096\n",
            "1965/4096\n",
            "1966/4096\n",
            "1967/4096\n",
            "1968/4096\n",
            "1969/4096\n",
            "1970/4096\n",
            "1971/4096\n",
            "1972/4096\n",
            "1973/4096\n",
            "1974/4096\n",
            "1975/4096\n",
            "1976/4096\n",
            "1977/4096\n",
            "1978/4096\n",
            "1979/4096\n",
            "1980/4096\n",
            "1981/4096\n",
            "1982/4096\n",
            "1983/4096\n",
            "1984/4096\n",
            "1985/4096\n",
            "1986/4096\n",
            "1987/4096\n",
            "1988/4096\n",
            "1989/4096\n",
            "1990/4096\n",
            "1991/4096\n",
            "1992/4096\n",
            "1993/4096\n",
            "1994/4096\n",
            "1995/4096\n",
            "1996/4096\n",
            "1997/4096\n",
            "1998/4096\n",
            "1999/4096\n",
            "2000/4096\n",
            "2001/4096\n",
            "2002/4096\n",
            "2003/4096\n",
            "2004/4096\n",
            "2005/4096\n",
            "2006/4096\n",
            "2007/4096\n",
            "2008/4096\n",
            "2009/4096\n",
            "2010/4096\n",
            "2011/4096\n",
            "2012/4096\n",
            "2013/4096\n",
            "2014/4096\n",
            "2015/4096\n",
            "2016/4096\n",
            "2017/4096\n",
            "2018/4096\n",
            "2019/4096\n",
            "2020/4096\n",
            "2021/4096\n",
            "2022/4096\n",
            "2023/4096\n",
            "2024/4096\n",
            "2025/4096\n",
            "2026/4096\n",
            "2027/4096\n",
            "2028/4096\n",
            "2029/4096\n",
            "2030/4096\n",
            "2031/4096\n",
            "2032/4096\n",
            "2033/4096\n",
            "2034/4096\n",
            "2035/4096\n",
            "2036/4096\n",
            "2037/4096\n",
            "2038/4096\n",
            "2039/4096\n",
            "2040/4096\n",
            "2041/4096\n",
            "2042/4096\n",
            "2043/4096\n",
            "2044/4096\n",
            "2045/4096\n",
            "2046/4096\n",
            "2047/4096\n",
            "2048/4096\n",
            "2049/4096\n",
            "2050/4096\n",
            "2051/4096\n",
            "2052/4096\n",
            "2053/4096\n",
            "2054/4096\n",
            "2055/4096\n",
            "2056/4096\n",
            "2057/4096\n",
            "2058/4096\n",
            "2059/4096\n",
            "2060/4096\n",
            "2061/4096\n",
            "2062/4096\n",
            "2063/4096\n",
            "2064/4096\n",
            "2065/4096\n",
            "2066/4096\n",
            "2067/4096\n",
            "2068/4096\n",
            "2069/4096\n",
            "2070/4096\n",
            "2071/4096\n",
            "2072/4096\n",
            "2073/4096\n",
            "2074/4096\n",
            "2075/4096\n",
            "2076/4096\n",
            "2077/4096\n",
            "2078/4096\n",
            "2079/4096\n",
            "2080/4096\n",
            "2081/4096\n",
            "2082/4096\n",
            "2083/4096\n",
            "2084/4096\n",
            "2085/4096\n",
            "2086/4096\n",
            "2087/4096\n",
            "2088/4096\n",
            "2089/4096\n",
            "2090/4096\n",
            "2091/4096\n",
            "2092/4096\n",
            "2093/4096\n",
            "2094/4096\n",
            "2095/4096\n",
            "2096/4096\n",
            "2097/4096\n",
            "2098/4096\n",
            "2099/4096\n",
            "2100/4096\n",
            "2101/4096\n",
            "2102/4096\n",
            "2103/4096\n",
            "2104/4096\n",
            "2105/4096\n",
            "2106/4096\n",
            "2107/4096\n",
            "2108/4096\n",
            "2109/4096\n",
            "2110/4096\n",
            "2111/4096\n",
            "2112/4096\n",
            "2113/4096\n",
            "2114/4096\n",
            "2115/4096\n",
            "2116/4096\n",
            "2117/4096\n",
            "2118/4096\n",
            "2119/4096\n",
            "2120/4096\n",
            "2121/4096\n",
            "2122/4096\n",
            "2123/4096\n",
            "2124/4096\n",
            "2125/4096\n",
            "2126/4096\n",
            "2127/4096\n",
            "2128/4096\n",
            "2129/4096\n",
            "2130/4096\n",
            "2131/4096\n",
            "2132/4096\n",
            "2133/4096\n",
            "2134/4096\n",
            "2135/4096\n",
            "2136/4096\n",
            "2137/4096\n",
            "2138/4096\n",
            "2139/4096\n",
            "2140/4096\n",
            "2141/4096\n",
            "2142/4096\n",
            "2143/4096\n",
            "2144/4096\n",
            "2145/4096\n",
            "2146/4096\n",
            "2147/4096\n",
            "2148/4096\n",
            "2149/4096\n",
            "2150/4096\n",
            "2151/4096\n",
            "2152/4096\n",
            "2153/4096\n",
            "2154/4096\n",
            "2155/4096\n",
            "2156/4096\n",
            "2157/4096\n",
            "2158/4096\n",
            "2159/4096\n",
            "2160/4096\n",
            "2161/4096\n",
            "2162/4096\n",
            "2163/4096\n",
            "2164/4096\n",
            "2165/4096\n",
            "2166/4096\n",
            "2167/4096\n",
            "2168/4096\n",
            "2169/4096\n",
            "2170/4096\n",
            "2171/4096\n",
            "2172/4096\n",
            "2173/4096\n",
            "2174/4096\n",
            "2175/4096\n",
            "2176/4096\n",
            "2177/4096\n",
            "2178/4096\n",
            "2179/4096\n",
            "2180/4096\n",
            "2181/4096\n",
            "2182/4096\n",
            "2183/4096\n",
            "2184/4096\n",
            "2185/4096\n",
            "2186/4096\n",
            "2187/4096\n",
            "2188/4096\n",
            "2189/4096\n",
            "2190/4096\n",
            "2191/4096\n",
            "2192/4096\n",
            "2193/4096\n",
            "2194/4096\n",
            "2195/4096\n",
            "2196/4096\n",
            "2197/4096\n",
            "2198/4096\n",
            "2199/4096\n",
            "2200/4096\n",
            "2201/4096\n",
            "2202/4096\n",
            "2203/4096\n",
            "2204/4096\n",
            "2205/4096\n",
            "2206/4096\n",
            "2207/4096\n",
            "2208/4096\n",
            "2209/4096\n",
            "2210/4096\n",
            "2211/4096\n",
            "2212/4096\n",
            "2213/4096\n",
            "2214/4096\n",
            "2215/4096\n",
            "2216/4096\n",
            "2217/4096\n",
            "2218/4096\n",
            "2219/4096\n",
            "2220/4096\n",
            "2221/4096\n",
            "2222/4096\n",
            "2223/4096\n",
            "2224/4096\n",
            "2225/4096\n",
            "2226/4096\n",
            "2227/4096\n",
            "2228/4096\n",
            "2229/4096\n",
            "2230/4096\n",
            "2231/4096\n",
            "2232/4096\n",
            "2233/4096\n",
            "2234/4096\n",
            "2235/4096\n",
            "2236/4096\n",
            "2237/4096\n",
            "2238/4096\n",
            "2239/4096\n",
            "2240/4096\n",
            "2241/4096\n",
            "2242/4096\n",
            "2243/4096\n",
            "2244/4096\n",
            "2245/4096\n",
            "2246/4096\n",
            "2247/4096\n",
            "2248/4096\n",
            "2249/4096\n",
            "2250/4096\n",
            "2251/4096\n",
            "2252/4096\n",
            "2253/4096\n",
            "2254/4096\n",
            "2255/4096\n",
            "2256/4096\n",
            "2257/4096\n",
            "2258/4096\n",
            "2259/4096\n",
            "2260/4096\n",
            "2261/4096\n",
            "2262/4096\n",
            "2263/4096\n",
            "2264/4096\n",
            "2265/4096\n",
            "2266/4096\n",
            "2267/4096\n",
            "2268/4096\n",
            "2269/4096\n",
            "2270/4096\n",
            "2271/4096\n",
            "2272/4096\n",
            "2273/4096\n",
            "2274/4096\n",
            "2275/4096\n",
            "2276/4096\n",
            "2277/4096\n",
            "2278/4096\n",
            "2279/4096\n",
            "2280/4096\n",
            "2281/4096\n",
            "2282/4096\n",
            "2283/4096\n",
            "2284/4096\n",
            "2285/4096\n",
            "2286/4096\n",
            "2287/4096\n",
            "2288/4096\n",
            "2289/4096\n",
            "2290/4096\n",
            "2291/4096\n",
            "2292/4096\n",
            "2293/4096\n",
            "2294/4096\n",
            "2295/4096\n",
            "2296/4096\n",
            "2297/4096\n",
            "2298/4096\n",
            "2299/4096\n",
            "2300/4096\n",
            "2301/4096\n",
            "2302/4096\n",
            "2303/4096\n",
            "2304/4096\n",
            "2305/4096\n",
            "2306/4096\n",
            "2307/4096\n",
            "2308/4096\n",
            "2309/4096\n",
            "2310/4096\n",
            "2311/4096\n",
            "2312/4096\n",
            "2313/4096\n",
            "2314/4096\n",
            "2315/4096\n",
            "2316/4096\n",
            "2317/4096\n",
            "2318/4096\n",
            "2319/4096\n",
            "2320/4096\n",
            "2321/4096\n",
            "2322/4096\n",
            "2323/4096\n",
            "2324/4096\n",
            "2325/4096\n",
            "2326/4096\n",
            "2327/4096\n",
            "2328/4096\n",
            "2329/4096\n",
            "2330/4096\n",
            "2331/4096\n",
            "2332/4096\n",
            "2333/4096\n",
            "2334/4096\n",
            "2335/4096\n",
            "2336/4096\n",
            "2337/4096\n",
            "2338/4096\n",
            "2339/4096\n",
            "2340/4096\n",
            "2341/4096\n",
            "2342/4096\n",
            "2343/4096\n",
            "2344/4096\n",
            "2345/4096\n",
            "2346/4096\n",
            "2347/4096\n",
            "2348/4096\n",
            "2349/4096\n",
            "2350/4096\n",
            "2351/4096\n",
            "2352/4096\n",
            "2353/4096\n",
            "2354/4096\n",
            "2355/4096\n",
            "2356/4096\n",
            "2357/4096\n",
            "2358/4096\n",
            "2359/4096\n",
            "2360/4096\n",
            "2361/4096\n",
            "2362/4096\n",
            "2363/4096\n",
            "2364/4096\n",
            "2365/4096\n",
            "2366/4096\n",
            "2367/4096\n",
            "2368/4096\n",
            "2369/4096\n",
            "2370/4096\n",
            "2371/4096\n",
            "2372/4096\n",
            "2373/4096\n",
            "2374/4096\n",
            "2375/4096\n",
            "2376/4096\n",
            "2377/4096\n",
            "2378/4096\n",
            "2379/4096\n",
            "2380/4096\n",
            "2381/4096\n",
            "2382/4096\n",
            "2383/4096\n",
            "2384/4096\n",
            "2385/4096\n",
            "2386/4096\n",
            "2387/4096\n",
            "2388/4096\n",
            "2389/4096\n",
            "2390/4096\n",
            "2391/4096\n",
            "2392/4096\n",
            "2393/4096\n",
            "2394/4096\n",
            "2395/4096\n",
            "2396/4096\n",
            "2397/4096\n",
            "2398/4096\n",
            "2399/4096\n",
            "2400/4096\n",
            "2401/4096\n",
            "2402/4096\n",
            "2403/4096\n",
            "2404/4096\n",
            "2405/4096\n",
            "2406/4096\n",
            "2407/4096\n",
            "2408/4096\n",
            "2409/4096\n",
            "2410/4096\n",
            "2411/4096\n",
            "2412/4096\n",
            "2413/4096\n",
            "2414/4096\n",
            "2415/4096\n",
            "2416/4096\n",
            "2417/4096\n",
            "2418/4096\n",
            "2419/4096\n",
            "2420/4096\n",
            "2421/4096\n",
            "2422/4096\n",
            "2423/4096\n",
            "2424/4096\n",
            "2425/4096\n",
            "2426/4096\n",
            "2427/4096\n",
            "2428/4096\n",
            "2429/4096\n",
            "2430/4096\n",
            "2431/4096\n",
            "2432/4096\n",
            "2433/4096\n",
            "2434/4096\n",
            "2435/4096\n",
            "2436/4096\n",
            "2437/4096\n",
            "2438/4096\n",
            "2439/4096\n",
            "2440/4096\n",
            "2441/4096\n",
            "2442/4096\n",
            "2443/4096\n",
            "2444/4096\n",
            "2445/4096\n",
            "2446/4096\n",
            "2447/4096\n",
            "2448/4096\n",
            "2449/4096\n",
            "2450/4096\n",
            "2451/4096\n",
            "2452/4096\n",
            "2453/4096\n",
            "2454/4096\n",
            "2455/4096\n",
            "2456/4096\n",
            "2457/4096\n",
            "2458/4096\n",
            "2459/4096\n",
            "2460/4096\n",
            "2461/4096\n",
            "2462/4096\n",
            "2463/4096\n",
            "2464/4096\n",
            "2465/4096\n",
            "2466/4096\n",
            "2467/4096\n",
            "2468/4096\n",
            "2469/4096\n",
            "2470/4096\n",
            "2471/4096\n",
            "2472/4096\n",
            "2473/4096\n",
            "2474/4096\n",
            "2475/4096\n",
            "2476/4096\n",
            "2477/4096\n",
            "2478/4096\n",
            "2479/4096\n",
            "2480/4096\n",
            "2481/4096\n",
            "2482/4096\n",
            "2483/4096\n",
            "2484/4096\n",
            "2485/4096\n",
            "2486/4096\n",
            "2487/4096\n",
            "2488/4096\n",
            "2489/4096\n",
            "2490/4096\n",
            "2491/4096\n",
            "2492/4096\n",
            "2493/4096\n",
            "2494/4096\n",
            "2495/4096\n",
            "2496/4096\n",
            "2497/4096\n",
            "2498/4096\n",
            "2499/4096\n",
            "2500/4096\n",
            "2501/4096\n",
            "2502/4096\n",
            "2503/4096\n",
            "2504/4096\n",
            "2505/4096\n",
            "2506/4096\n",
            "2507/4096\n",
            "2508/4096\n",
            "2509/4096\n",
            "2510/4096\n",
            "2511/4096\n",
            "2512/4096\n",
            "2513/4096\n",
            "2514/4096\n",
            "2515/4096\n",
            "2516/4096\n",
            "2517/4096\n",
            "2518/4096\n",
            "2519/4096\n",
            "2520/4096\n",
            "2521/4096\n",
            "2522/4096\n",
            "2523/4096\n",
            "2524/4096\n",
            "2525/4096\n",
            "2526/4096\n",
            "2527/4096\n",
            "2528/4096\n",
            "2529/4096\n",
            "2530/4096\n",
            "2531/4096\n",
            "2532/4096\n",
            "2533/4096\n",
            "2534/4096\n",
            "2535/4096\n",
            "2536/4096\n",
            "2537/4096\n",
            "2538/4096\n",
            "2539/4096\n",
            "2540/4096\n",
            "2541/4096\n",
            "2542/4096\n",
            "2543/4096\n",
            "2544/4096\n",
            "2545/4096\n",
            "2546/4096\n",
            "2547/4096\n",
            "2548/4096\n",
            "2549/4096\n",
            "2550/4096\n",
            "2551/4096\n",
            "2552/4096\n",
            "2553/4096\n",
            "2554/4096\n",
            "2555/4096\n",
            "2556/4096\n",
            "2557/4096\n",
            "2558/4096\n",
            "2559/4096\n",
            "2560/4096\n",
            "2561/4096\n",
            "2562/4096\n",
            "2563/4096\n",
            "2564/4096\n",
            "2565/4096\n",
            "2566/4096\n",
            "2567/4096\n",
            "2568/4096\n",
            "2569/4096\n",
            "2570/4096\n",
            "2571/4096\n",
            "2572/4096\n",
            "2573/4096\n",
            "2574/4096\n",
            "2575/4096\n",
            "2576/4096\n",
            "2577/4096\n",
            "2578/4096\n",
            "2579/4096\n",
            "2580/4096\n",
            "2581/4096\n",
            "2582/4096\n",
            "2583/4096\n",
            "2584/4096\n",
            "2585/4096\n",
            "2586/4096\n",
            "2587/4096\n",
            "2588/4096\n",
            "2589/4096\n",
            "2590/4096\n",
            "2591/4096\n",
            "2592/4096\n",
            "2593/4096\n",
            "2594/4096\n",
            "2595/4096\n",
            "2596/4096\n",
            "2597/4096\n",
            "2598/4096\n",
            "2599/4096\n",
            "2600/4096\n",
            "2601/4096\n",
            "2602/4096\n",
            "2603/4096\n",
            "2604/4096\n",
            "2605/4096\n",
            "2606/4096\n",
            "2607/4096\n",
            "2608/4096\n",
            "2609/4096\n",
            "2610/4096\n",
            "2611/4096\n",
            "2612/4096\n",
            "2613/4096\n",
            "2614/4096\n",
            "2615/4096\n",
            "2616/4096\n",
            "2617/4096\n",
            "2618/4096\n",
            "2619/4096\n",
            "2620/4096\n",
            "2621/4096\n",
            "2622/4096\n",
            "2623/4096\n",
            "2624/4096\n",
            "2625/4096\n",
            "2626/4096\n",
            "2627/4096\n",
            "2628/4096\n",
            "2629/4096\n",
            "2630/4096\n",
            "2631/4096\n",
            "2632/4096\n",
            "2633/4096\n",
            "2634/4096\n",
            "2635/4096\n",
            "2636/4096\n",
            "2637/4096\n",
            "2638/4096\n",
            "2639/4096\n",
            "2640/4096\n",
            "2641/4096\n",
            "2642/4096\n",
            "2643/4096\n",
            "2644/4096\n",
            "2645/4096\n",
            "2646/4096\n",
            "2647/4096\n",
            "2648/4096\n",
            "2649/4096\n",
            "2650/4096\n",
            "2651/4096\n",
            "2652/4096\n",
            "2653/4096\n",
            "2654/4096\n",
            "2655/4096\n",
            "2656/4096\n",
            "2657/4096\n",
            "2658/4096\n",
            "2659/4096\n",
            "2660/4096\n",
            "2661/4096\n",
            "2662/4096\n",
            "2663/4096\n",
            "2664/4096\n",
            "2665/4096\n",
            "2666/4096\n",
            "2667/4096\n",
            "2668/4096\n",
            "2669/4096\n",
            "2670/4096\n",
            "2671/4096\n",
            "2672/4096\n",
            "2673/4096\n",
            "2674/4096\n",
            "2675/4096\n",
            "2676/4096\n",
            "2677/4096\n",
            "2678/4096\n",
            "2679/4096\n",
            "2680/4096\n",
            "2681/4096\n",
            "2682/4096\n",
            "2683/4096\n",
            "2684/4096\n",
            "2685/4096\n",
            "2686/4096\n",
            "2687/4096\n",
            "2688/4096\n",
            "2689/4096\n",
            "2690/4096\n",
            "2691/4096\n",
            "2692/4096\n",
            "2693/4096\n",
            "2694/4096\n",
            "2695/4096\n",
            "2696/4096\n",
            "2697/4096\n",
            "2698/4096\n",
            "2699/4096\n",
            "2700/4096\n",
            "2701/4096\n",
            "2702/4096\n",
            "2703/4096\n",
            "2704/4096\n",
            "2705/4096\n",
            "2706/4096\n",
            "2707/4096\n",
            "2708/4096\n",
            "2709/4096\n",
            "2710/4096\n",
            "2711/4096\n",
            "2712/4096\n",
            "2713/4096\n",
            "2714/4096\n",
            "2715/4096\n",
            "2716/4096\n",
            "2717/4096\n",
            "2718/4096\n",
            "2719/4096\n",
            "2720/4096\n",
            "2721/4096\n",
            "2722/4096\n",
            "2723/4096\n",
            "2724/4096\n",
            "2725/4096\n",
            "2726/4096\n",
            "2727/4096\n",
            "2728/4096\n",
            "2729/4096\n",
            "2730/4096\n",
            "2731/4096\n",
            "2732/4096\n",
            "2733/4096\n",
            "2734/4096\n",
            "2735/4096\n",
            "2736/4096\n",
            "2737/4096\n",
            "2738/4096\n",
            "2739/4096\n",
            "2740/4096\n",
            "2741/4096\n",
            "2742/4096\n",
            "2743/4096\n",
            "2744/4096\n",
            "2745/4096\n",
            "2746/4096\n",
            "2747/4096\n",
            "2748/4096\n",
            "2749/4096\n",
            "2750/4096\n",
            "2751/4096\n",
            "2752/4096\n",
            "2753/4096\n",
            "2754/4096\n",
            "2755/4096\n",
            "2756/4096\n",
            "2757/4096\n",
            "2758/4096\n",
            "2759/4096\n",
            "2760/4096\n",
            "2761/4096\n",
            "2762/4096\n",
            "2763/4096\n",
            "2764/4096\n",
            "2765/4096\n",
            "2766/4096\n",
            "2767/4096\n",
            "2768/4096\n",
            "2769/4096\n",
            "2770/4096\n",
            "2771/4096\n",
            "2772/4096\n",
            "2773/4096\n",
            "2774/4096\n",
            "2775/4096\n",
            "2776/4096\n",
            "2777/4096\n",
            "2778/4096\n",
            "2779/4096\n",
            "2780/4096\n",
            "2781/4096\n",
            "2782/4096\n",
            "2783/4096\n",
            "2784/4096\n",
            "2785/4096\n",
            "2786/4096\n",
            "2787/4096\n",
            "2788/4096\n",
            "2789/4096\n",
            "2790/4096\n",
            "2791/4096\n",
            "2792/4096\n",
            "2793/4096\n",
            "2794/4096\n",
            "2795/4096\n",
            "2796/4096\n",
            "2797/4096\n",
            "2798/4096\n",
            "2799/4096\n",
            "2800/4096\n",
            "2801/4096\n",
            "2802/4096\n",
            "2803/4096\n",
            "2804/4096\n",
            "2805/4096\n",
            "2806/4096\n",
            "2807/4096\n",
            "2808/4096\n",
            "2809/4096\n",
            "2810/4096\n",
            "2811/4096\n",
            "2812/4096\n",
            "2813/4096\n",
            "2814/4096\n",
            "2815/4096\n",
            "2816/4096\n",
            "2817/4096\n",
            "2818/4096\n",
            "2819/4096\n",
            "2820/4096\n",
            "2821/4096\n",
            "2822/4096\n",
            "2823/4096\n",
            "2824/4096\n",
            "2825/4096\n",
            "2826/4096\n",
            "2827/4096\n",
            "2828/4096\n",
            "2829/4096\n",
            "2830/4096\n",
            "2831/4096\n",
            "2832/4096\n",
            "2833/4096\n",
            "2834/4096\n",
            "2835/4096\n",
            "2836/4096\n",
            "2837/4096\n",
            "2838/4096\n",
            "2839/4096\n",
            "2840/4096\n",
            "2841/4096\n",
            "2842/4096\n",
            "2843/4096\n",
            "2844/4096\n",
            "2845/4096\n",
            "2846/4096\n",
            "2847/4096\n",
            "2848/4096\n",
            "2849/4096\n",
            "2850/4096\n",
            "2851/4096\n",
            "2852/4096\n",
            "2853/4096\n",
            "2854/4096\n",
            "2855/4096\n",
            "2856/4096\n",
            "2857/4096\n",
            "2858/4096\n",
            "2859/4096\n",
            "2860/4096\n",
            "2861/4096\n",
            "2862/4096\n",
            "2863/4096\n",
            "2864/4096\n",
            "2865/4096\n",
            "2866/4096\n",
            "2867/4096\n",
            "2868/4096\n",
            "2869/4096\n",
            "2870/4096\n",
            "2871/4096\n",
            "2872/4096\n",
            "2873/4096\n",
            "2874/4096\n",
            "2875/4096\n",
            "2876/4096\n",
            "2877/4096\n",
            "2878/4096\n",
            "2879/4096\n",
            "2880/4096\n",
            "2881/4096\n",
            "2882/4096\n",
            "2883/4096\n",
            "2884/4096\n",
            "2885/4096\n",
            "2886/4096\n",
            "2887/4096\n",
            "2888/4096\n",
            "2889/4096\n",
            "2890/4096\n",
            "2891/4096\n",
            "2892/4096\n",
            "2893/4096\n",
            "2894/4096\n",
            "2895/4096\n",
            "2896/4096\n",
            "2897/4096\n",
            "2898/4096\n",
            "2899/4096\n",
            "2900/4096\n",
            "2901/4096\n",
            "2902/4096\n",
            "2903/4096\n",
            "2904/4096\n",
            "2905/4096\n",
            "2906/4096\n",
            "2907/4096\n",
            "2908/4096\n",
            "2909/4096\n",
            "2910/4096\n",
            "2911/4096\n",
            "2912/4096\n",
            "2913/4096\n",
            "2914/4096\n",
            "2915/4096\n",
            "2916/4096\n",
            "2917/4096\n",
            "2918/4096\n",
            "2919/4096\n",
            "2920/4096\n",
            "2921/4096\n",
            "2922/4096\n",
            "2923/4096\n",
            "2924/4096\n",
            "2925/4096\n",
            "2926/4096\n",
            "2927/4096\n",
            "2928/4096\n",
            "2929/4096\n",
            "2930/4096\n",
            "2931/4096\n",
            "2932/4096\n",
            "2933/4096\n",
            "2934/4096\n",
            "2935/4096\n",
            "2936/4096\n",
            "2937/4096\n",
            "2938/4096\n",
            "2939/4096\n",
            "2940/4096\n",
            "2941/4096\n",
            "2942/4096\n",
            "2943/4096\n",
            "2944/4096\n",
            "2945/4096\n",
            "2946/4096\n",
            "2947/4096\n",
            "2948/4096\n",
            "2949/4096\n",
            "2950/4096\n",
            "2951/4096\n",
            "2952/4096\n",
            "2953/4096\n",
            "2954/4096\n",
            "2955/4096\n",
            "2956/4096\n",
            "2957/4096\n",
            "2958/4096\n",
            "2959/4096\n",
            "2960/4096\n",
            "2961/4096\n",
            "2962/4096\n",
            "2963/4096\n",
            "2964/4096\n",
            "2965/4096\n",
            "2966/4096\n",
            "2967/4096\n",
            "2968/4096\n",
            "2969/4096\n",
            "2970/4096\n",
            "2971/4096\n",
            "2972/4096\n",
            "2973/4096\n",
            "2974/4096\n",
            "2975/4096\n",
            "2976/4096\n",
            "2977/4096\n",
            "2978/4096\n",
            "2979/4096\n",
            "2980/4096\n",
            "2981/4096\n",
            "2982/4096\n",
            "2983/4096\n",
            "2984/4096\n",
            "2985/4096\n",
            "2986/4096\n",
            "2987/4096\n",
            "2988/4096\n",
            "2989/4096\n",
            "2990/4096\n",
            "2991/4096\n",
            "2992/4096\n",
            "2993/4096\n",
            "2994/4096\n",
            "2995/4096\n",
            "2996/4096\n",
            "2997/4096\n",
            "2998/4096\n",
            "2999/4096\n",
            "3000/4096\n",
            "3001/4096\n",
            "3002/4096\n",
            "3003/4096\n",
            "3004/4096\n",
            "3005/4096\n",
            "3006/4096\n",
            "3007/4096\n",
            "3008/4096\n",
            "3009/4096\n",
            "3010/4096\n",
            "3011/4096\n",
            "3012/4096\n",
            "3013/4096\n",
            "3014/4096\n",
            "3015/4096\n",
            "3016/4096\n",
            "3017/4096\n",
            "3018/4096\n",
            "3019/4096\n",
            "3020/4096\n",
            "3021/4096\n",
            "3022/4096\n",
            "3023/4096\n",
            "3024/4096\n",
            "3025/4096\n",
            "3026/4096\n",
            "3027/4096\n",
            "3028/4096\n",
            "3029/4096\n",
            "3030/4096\n",
            "3031/4096\n",
            "3032/4096\n",
            "3033/4096\n",
            "3034/4096\n",
            "3035/4096\n",
            "3036/4096\n",
            "3037/4096\n",
            "3038/4096\n",
            "3039/4096\n",
            "3040/4096\n",
            "3041/4096\n",
            "3042/4096\n",
            "3043/4096\n",
            "3044/4096\n",
            "3045/4096\n",
            "3046/4096\n",
            "3047/4096\n",
            "3048/4096\n",
            "3049/4096\n",
            "3050/4096\n",
            "3051/4096\n",
            "3052/4096\n",
            "3053/4096\n",
            "3054/4096\n",
            "3055/4096\n",
            "3056/4096\n",
            "3057/4096\n",
            "3058/4096\n",
            "3059/4096\n",
            "3060/4096\n",
            "3061/4096\n",
            "3062/4096\n",
            "3063/4096\n",
            "3064/4096\n",
            "3065/4096\n",
            "3066/4096\n",
            "3067/4096\n",
            "3068/4096\n",
            "3069/4096\n",
            "3070/4096\n",
            "3071/4096\n",
            "3072/4096\n",
            "3073/4096\n",
            "3074/4096\n",
            "3075/4096\n",
            "3076/4096\n",
            "3077/4096\n",
            "3078/4096\n",
            "3079/4096\n",
            "3080/4096\n",
            "3081/4096\n",
            "3082/4096\n",
            "3083/4096\n",
            "3084/4096\n",
            "3085/4096\n",
            "3086/4096\n",
            "3087/4096\n",
            "3088/4096\n",
            "3089/4096\n",
            "3090/4096\n",
            "3091/4096\n",
            "3092/4096\n",
            "3093/4096\n",
            "3094/4096\n",
            "3095/4096\n",
            "3096/4096\n",
            "3097/4096\n",
            "3098/4096\n",
            "3099/4096\n",
            "3100/4096\n",
            "3101/4096\n",
            "3102/4096\n",
            "3103/4096\n",
            "3104/4096\n",
            "3105/4096\n",
            "3106/4096\n",
            "3107/4096\n",
            "3108/4096\n",
            "3109/4096\n",
            "3110/4096\n",
            "3111/4096\n",
            "3112/4096\n",
            "3113/4096\n",
            "3114/4096\n",
            "3115/4096\n",
            "3116/4096\n",
            "3117/4096\n",
            "3118/4096\n",
            "3119/4096\n",
            "3120/4096\n",
            "3121/4096\n",
            "3122/4096\n",
            "3123/4096\n",
            "3124/4096\n",
            "3125/4096\n",
            "3126/4096\n",
            "3127/4096\n",
            "3128/4096\n",
            "3129/4096\n",
            "3130/4096\n",
            "3131/4096\n",
            "3132/4096\n",
            "3133/4096\n",
            "3134/4096\n",
            "3135/4096\n",
            "3136/4096\n",
            "3137/4096\n",
            "3138/4096\n",
            "3139/4096\n",
            "3140/4096\n",
            "3141/4096\n",
            "3142/4096\n",
            "3143/4096\n",
            "3144/4096\n",
            "3145/4096\n",
            "3146/4096\n",
            "3147/4096\n",
            "3148/4096\n",
            "3149/4096\n",
            "3150/4096\n",
            "3151/4096\n",
            "3152/4096\n",
            "3153/4096\n",
            "3154/4096\n",
            "3155/4096\n",
            "3156/4096\n",
            "3157/4096\n",
            "3158/4096\n",
            "3159/4096\n",
            "3160/4096\n",
            "3161/4096\n",
            "3162/4096\n",
            "3163/4096\n",
            "3164/4096\n",
            "3165/4096\n",
            "3166/4096\n",
            "3167/4096\n",
            "3168/4096\n",
            "3169/4096\n",
            "3170/4096\n",
            "3171/4096\n",
            "3172/4096\n",
            "3173/4096\n",
            "3174/4096\n",
            "3175/4096\n",
            "3176/4096\n",
            "3177/4096\n",
            "3178/4096\n",
            "3179/4096\n",
            "3180/4096\n",
            "3181/4096\n",
            "3182/4096\n",
            "3183/4096\n",
            "3184/4096\n",
            "3185/4096\n",
            "3186/4096\n",
            "3187/4096\n",
            "3188/4096\n",
            "3189/4096\n",
            "3190/4096\n",
            "3191/4096\n",
            "3192/4096\n",
            "3193/4096\n",
            "3194/4096\n",
            "3195/4096\n",
            "3196/4096\n",
            "3197/4096\n",
            "3198/4096\n",
            "3199/4096\n",
            "3200/4096\n",
            "3201/4096\n",
            "3202/4096\n",
            "3203/4096\n",
            "3204/4096\n",
            "3205/4096\n",
            "3206/4096\n",
            "3207/4096\n",
            "3208/4096\n",
            "3209/4096\n",
            "3210/4096\n",
            "3211/4096\n",
            "3212/4096\n",
            "3213/4096\n",
            "3214/4096\n",
            "3215/4096\n",
            "3216/4096\n",
            "3217/4096\n",
            "3218/4096\n",
            "3219/4096\n",
            "3220/4096\n",
            "3221/4096\n",
            "3222/4096\n",
            "3223/4096\n",
            "3224/4096\n",
            "3225/4096\n",
            "3226/4096\n",
            "3227/4096\n",
            "3228/4096\n",
            "3229/4096\n",
            "3230/4096\n",
            "3231/4096\n",
            "3232/4096\n",
            "3233/4096\n",
            "3234/4096\n",
            "3235/4096\n",
            "3236/4096\n",
            "3237/4096\n",
            "3238/4096\n",
            "3239/4096\n",
            "3240/4096\n",
            "3241/4096\n",
            "3242/4096\n",
            "3243/4096\n",
            "3244/4096\n",
            "3245/4096\n",
            "3246/4096\n",
            "3247/4096\n",
            "3248/4096\n",
            "3249/4096\n",
            "3250/4096\n",
            "3251/4096\n",
            "3252/4096\n",
            "3253/4096\n",
            "3254/4096\n",
            "3255/4096\n",
            "3256/4096\n",
            "3257/4096\n",
            "3258/4096\n",
            "3259/4096\n",
            "3260/4096\n",
            "3261/4096\n",
            "3262/4096\n",
            "3263/4096\n",
            "3264/4096\n",
            "3265/4096\n",
            "3266/4096\n",
            "3267/4096\n",
            "3268/4096\n",
            "3269/4096\n",
            "3270/4096\n",
            "3271/4096\n",
            "3272/4096\n",
            "3273/4096\n",
            "3274/4096\n",
            "3275/4096\n",
            "3276/4096\n",
            "3277/4096\n",
            "3278/4096\n",
            "3279/4096\n",
            "3280/4096\n",
            "3281/4096\n",
            "3282/4096\n",
            "3283/4096\n",
            "3284/4096\n",
            "3285/4096\n",
            "3286/4096\n",
            "3287/4096\n",
            "3288/4096\n",
            "3289/4096\n",
            "3290/4096\n",
            "3291/4096\n",
            "3292/4096\n",
            "3293/4096\n",
            "3294/4096\n",
            "3295/4096\n",
            "3296/4096\n",
            "3297/4096\n",
            "3298/4096\n",
            "3299/4096\n",
            "3300/4096\n",
            "3301/4096\n",
            "3302/4096\n",
            "3303/4096\n",
            "3304/4096\n",
            "3305/4096\n",
            "3306/4096\n",
            "3307/4096\n",
            "3308/4096\n",
            "3309/4096\n",
            "3310/4096\n",
            "3311/4096\n",
            "3312/4096\n",
            "3313/4096\n",
            "3314/4096\n",
            "3315/4096\n",
            "3316/4096\n",
            "3317/4096\n",
            "3318/4096\n",
            "3319/4096\n",
            "3320/4096\n",
            "3321/4096\n",
            "3322/4096\n",
            "3323/4096\n",
            "3324/4096\n",
            "3325/4096\n",
            "3326/4096\n",
            "3327/4096\n",
            "3328/4096\n",
            "3329/4096\n",
            "3330/4096\n",
            "3331/4096\n",
            "3332/4096\n",
            "3333/4096\n",
            "3334/4096\n",
            "3335/4096\n",
            "3336/4096\n",
            "3337/4096\n",
            "3338/4096\n",
            "3339/4096\n",
            "3340/4096\n",
            "3341/4096\n",
            "3342/4096\n",
            "3343/4096\n",
            "3344/4096\n",
            "3345/4096\n",
            "3346/4096\n",
            "3347/4096\n",
            "3348/4096\n",
            "3349/4096\n",
            "3350/4096\n",
            "3351/4096\n",
            "3352/4096\n",
            "3353/4096\n",
            "3354/4096\n",
            "3355/4096\n",
            "3356/4096\n",
            "3357/4096\n",
            "3358/4096\n",
            "3359/4096\n",
            "3360/4096\n",
            "3361/4096\n",
            "3362/4096\n",
            "3363/4096\n",
            "3364/4096\n",
            "3365/4096\n",
            "3366/4096\n",
            "3367/4096\n",
            "3368/4096\n",
            "3369/4096\n",
            "3370/4096\n",
            "3371/4096\n",
            "3372/4096\n",
            "3373/4096\n",
            "3374/4096\n",
            "3375/4096\n",
            "3376/4096\n",
            "3377/4096\n",
            "3378/4096\n",
            "3379/4096\n",
            "3380/4096\n",
            "3381/4096\n",
            "3382/4096\n",
            "3383/4096\n",
            "3384/4096\n",
            "3385/4096\n",
            "3386/4096\n",
            "3387/4096\n",
            "3388/4096\n",
            "3389/4096\n",
            "3390/4096\n",
            "3391/4096\n",
            "3392/4096\n",
            "3393/4096\n",
            "3394/4096\n",
            "3395/4096\n",
            "3396/4096\n",
            "3397/4096\n",
            "3398/4096\n",
            "3399/4096\n",
            "3400/4096\n",
            "3401/4096\n",
            "3402/4096\n",
            "3403/4096\n",
            "3404/4096\n",
            "3405/4096\n",
            "3406/4096\n",
            "3407/4096\n",
            "3408/4096\n",
            "3409/4096\n",
            "3410/4096\n",
            "3411/4096\n",
            "3412/4096\n",
            "3413/4096\n",
            "3414/4096\n",
            "3415/4096\n",
            "3416/4096\n",
            "3417/4096\n",
            "3418/4096\n",
            "3419/4096\n",
            "3420/4096\n",
            "3421/4096\n",
            "3422/4096\n",
            "3423/4096\n",
            "3424/4096\n",
            "3425/4096\n",
            "3426/4096\n",
            "3427/4096\n",
            "3428/4096\n",
            "3429/4096\n",
            "3430/4096\n",
            "3431/4096\n",
            "3432/4096\n",
            "3433/4096\n",
            "3434/4096\n",
            "3435/4096\n",
            "3436/4096\n",
            "3437/4096\n",
            "3438/4096\n",
            "3439/4096\n",
            "3440/4096\n",
            "3441/4096\n",
            "3442/4096\n",
            "3443/4096\n",
            "3444/4096\n",
            "3445/4096\n",
            "3446/4096\n",
            "3447/4096\n",
            "3448/4096\n",
            "3449/4096\n",
            "3450/4096\n",
            "3451/4096\n",
            "3452/4096\n",
            "3453/4096\n",
            "3454/4096\n",
            "3455/4096\n",
            "3456/4096\n",
            "3457/4096\n",
            "3458/4096\n",
            "3459/4096\n",
            "3460/4096\n",
            "3461/4096\n",
            "3462/4096\n",
            "3463/4096\n",
            "3464/4096\n",
            "3465/4096\n",
            "3466/4096\n",
            "3467/4096\n",
            "3468/4096\n",
            "3469/4096\n",
            "3470/4096\n",
            "3471/4096\n",
            "3472/4096\n",
            "3473/4096\n",
            "3474/4096\n",
            "3475/4096\n",
            "3476/4096\n",
            "3477/4096\n",
            "3478/4096\n",
            "3479/4096\n",
            "3480/4096\n",
            "3481/4096\n",
            "3482/4096\n",
            "3483/4096\n",
            "3484/4096\n",
            "3485/4096\n",
            "3486/4096\n",
            "3487/4096\n",
            "3488/4096\n",
            "3489/4096\n",
            "3490/4096\n",
            "3491/4096\n",
            "3492/4096\n",
            "3493/4096\n",
            "3494/4096\n",
            "3495/4096\n",
            "3496/4096\n",
            "3497/4096\n",
            "3498/4096\n",
            "3499/4096\n",
            "3500/4096\n",
            "3501/4096\n",
            "3502/4096\n",
            "3503/4096\n",
            "3504/4096\n",
            "3505/4096\n",
            "3506/4096\n",
            "3507/4096\n",
            "3508/4096\n",
            "3509/4096\n",
            "3510/4096\n",
            "3511/4096\n",
            "3512/4096\n",
            "3513/4096\n",
            "3514/4096\n",
            "3515/4096\n",
            "3516/4096\n",
            "3517/4096\n",
            "3518/4096\n",
            "3519/4096\n",
            "3520/4096\n",
            "3521/4096\n",
            "3522/4096\n",
            "3523/4096\n",
            "3524/4096\n",
            "3525/4096\n",
            "3526/4096\n",
            "3527/4096\n",
            "3528/4096\n",
            "3529/4096\n",
            "3530/4096\n",
            "3531/4096\n",
            "3532/4096\n",
            "3533/4096\n",
            "3534/4096\n",
            "3535/4096\n",
            "3536/4096\n",
            "3537/4096\n",
            "3538/4096\n",
            "3539/4096\n",
            "3540/4096\n",
            "3541/4096\n",
            "3542/4096\n",
            "3543/4096\n",
            "3544/4096\n",
            "3545/4096\n",
            "3546/4096\n",
            "3547/4096\n",
            "3548/4096\n",
            "3549/4096\n",
            "3550/4096\n",
            "3551/4096\n",
            "3552/4096\n",
            "3553/4096\n",
            "3554/4096\n",
            "3555/4096\n",
            "3556/4096\n",
            "3557/4096\n",
            "3558/4096\n",
            "3559/4096\n",
            "3560/4096\n",
            "3561/4096\n",
            "3562/4096\n",
            "3563/4096\n",
            "3564/4096\n",
            "3565/4096\n",
            "3566/4096\n",
            "3567/4096\n",
            "3568/4096\n",
            "3569/4096\n",
            "3570/4096\n",
            "3571/4096\n",
            "3572/4096\n",
            "3573/4096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM--hyEQPhFs"
      },
      "source": [
        "seqs = np.array(seqs)\r\n",
        "print(seqs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jidPhgKqPknP"
      },
      "source": [
        "samples_name = f'{len(seqs)}_samples_i.npy'\r\n",
        "np.save(samples_name, seqs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_3jWfqXilOJ"
      },
      "source": [
        "print(seqs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82aZ6YHEbBxo"
      },
      "source": [
        "files.download(samples_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wpLgeMiLJSif",
        "outputId": "006c815d-e456-4a12-ee26-8e4e94000262"
      },
      "source": [
        "files.download('trained_midi_512.h5')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5593d020-f5c6-498d-b500-46d8de66e4c1\", \"trained_midi_512.h5\", 17850624)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGv_d3bzZB9a"
      },
      "source": [
        "Or try to input some text and see continuation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "_iX7hcrFtsrW"
      },
      "source": [
        "while True:\n",
        "    prompt = \"%s words: \" % n_input\n",
        "\n",
        "    try:\n",
        "      sentence = input(prompt)\n",
        "    except KeyboardInterrupt:\n",
        "      break\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "    words = sentence.split(' ')\n",
        "    if len(words) != n_input:\n",
        "        continue\n",
        "    try:\n",
        "        symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
        "    except:\n",
        "        print(\"Word not in dictionary\")\n",
        "        continue\n",
        "\n",
        "    sentence = gen_long(model, symbols_in_keys)\n",
        "    print(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKy-0EotsrX"
      },
      "source": [
        "## 7. Excercice \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYXY5jfMAi6x"
      },
      "source": [
        "* Run with 5-7 input words instead of 3.\n",
        "* increase number of training iterations, since convergance will take much longer (training as well!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7-p8ClctsrY"
      },
      "source": [
        "## 8. Further reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjhwEgdKtsrZ"
      },
      "source": [
        "[Illustrated Guide to Recurrent Neural Networks](https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9)\n",
        "\n",
        "[Illustrated Guide to LSTMs and GRUs: A step by step explanation](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)"
      ]
    }
  ]
}